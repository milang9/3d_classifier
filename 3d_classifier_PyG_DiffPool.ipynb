{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
        "outputId": "34b04cc1-d6b5-482d-e863-e28dd7c6cf70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch Version 1.10.2\n",
            "Cuda is available: True\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "#install PyG in google colab\n",
        "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "#!pip install forgi\n",
        "#!tar -xf data.tar.xz\n",
        "\n",
        "import numpy as np\n",
        "import torch as th\n",
        "from torch_geometric.loader import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyg_classifier.data import CGDataset\n",
        "\n",
        "\n",
        "print(\"Pytorch Version\", th.__version__)\n",
        "print(\"Cuda is available:\", th.cuda.is_available())\n",
        "\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n2IxR1AxZdYn",
      "metadata": {
        "id": "n2IxR1AxZdYn"
      },
      "source": [
        "TODO:\n",
        "*  figure out how PyG returns graph level predictions (shape of prediction doesnt match shape of labels per batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "16475321",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dense/Diffpool Model\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.nn as tgnn\n",
        "import torch_geometric.utils as pygu\n",
        "import math\n",
        "\n",
        "class GNN(th.nn.Module):\n",
        "    def __init__(self, in_c, hidden_c, out_c, normalize=False, lin=True):\n",
        "        super(GNN, self).__init__()\n",
        "    \n",
        "        self.conv = th.nn.ModuleList()\n",
        "        self.bn = th.nn.ModuleList()\n",
        "\n",
        "        self.conv.append(tgnn.DenseGCNConv(in_c, hidden_c, normalize))\n",
        "        self.bn.append(th.nn.BatchNorm1d(hidden_c))\n",
        "\n",
        "        self.conv.append(tgnn.DenseGCNConv(hidden_c, hidden_c, normalize))\n",
        "        self.bn.append(th.nn.BatchNorm1d(hidden_c))\n",
        "\n",
        "        self.conv.append(tgnn.DenseGCNConv(hidden_c, out_c, normalize))\n",
        "        self.bn.append(th.nn.BatchNorm1d(out_c))\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        #batch_size, num_nodes, in_channels = x.size()\n",
        "        \n",
        "        for step in range(len(self.conv)):\n",
        "            #print(x.shape)\n",
        "            #x = self.bn[step](F.elu(self.conv[step](x, adj, mask)))\n",
        "            x = F.elu(self.conv[step](x, adj, mask))\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "#Coarse Grain RNA Classifier Model\n",
        "class Diff_CG_Classifier(th.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Diff_CG_Classifier, self).__init__()\n",
        "        num_nodes = math.ceil(0.25 * 50)\n",
        "\n",
        "        self.gcn_pool1 = GNN(18, 64, num_nodes)\n",
        "        self.gcn_embed1 = GNN(18, 64, 64)\n",
        "\n",
        "        num_nodes = math.ceil(0.25 * num_nodes)\n",
        "        self.gcn_pool2 = GNN(64, 64, num_nodes)\n",
        "        self.gcn_embed2 = GNN(64, 64, 64, lin=False)\n",
        "\n",
        "        num_nodes = math.ceil(0.25 * num_nodes)\n",
        "        self.gcn_pool3 = GNN(64, 64, num_nodes)\n",
        "        self.gcn_embed3 = GNN(64, 64, 64, lin=False)\n",
        "\n",
        "        self.gcn_embed4 = GNN(64, 64, 64, lin=False)\n",
        "        \n",
        "        self.classify = th.nn.Sequential(\n",
        "            th.nn.Linear(64, 512),\n",
        "            th.nn.ELU(),\n",
        "            th.nn.Linear(512, 512),\n",
        "            th.nn.ELU(),\n",
        "            th.nn.Linear(512, 512),\n",
        "            th.nn.ELU(),\n",
        "            th.nn.Linear(512, 512),\n",
        "            th.nn.ELU(),\n",
        "            th.nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n",
        "        batch = data.batch\n",
        "        adj = data.adj #pygu.to_dense_adj(edge_index=edge_index, batch=batch)\n",
        "\n",
        "        s = self.gcn_pool1(x, adj)\n",
        "        x = self.gcn_embed1(x, adj)\n",
        "\n",
        "        x, adj, l1, e1 = tgnn.dense_diff_pool(x, adj, s)\n",
        "\n",
        "        s = self.gcn_pool2(x, adj)\n",
        "        x = self.gcn_embed2(x, adj)\n",
        "\n",
        "        x, adj, l2, e2 = tgnn.dense_diff_pool(x, adj, s)\n",
        "\n",
        "        s = self.gcn_pool3(x, adj)\n",
        "        x = self.gcn_embed3(x, adj)\n",
        "\n",
        "        x, adj, l2, e2 = tgnn.dense_diff_pool(x, adj, s)\n",
        "\n",
        "        x = self.gcn_embed4(x, adj)\n",
        "\n",
        "        #x = tgnn.global_mean_pool(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        x = self.classify(x)\n",
        "\n",
        "        return x, l1 + l2, e1 + e2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "j4O333bvAQ1V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4O333bvAQ1V",
        "outputId": "07169a87-9bfa-438b-9a8b-f05735d81fb7"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() missing 1 required positional argument: 'data_name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/milan/MS_Arbeit/3d_classifier/3d_classifier_PyG_DiffPool.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/milan/MS_Arbeit/3d_classifier/3d_classifier_PyG_DiffPool.ipynb#ch0000004?line=2'>3</a>\u001b[0m training_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/train_set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/milan/MS_Arbeit/3d_classifier/3d_classifier_PyG_DiffPool.ipynb#ch0000004?line=3'>4</a>\u001b[0m rmsd_list \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/truncated_train_rmsd.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/milan/MS_Arbeit/3d_classifier/3d_classifier_PyG_DiffPool.ipynb#ch0000004?line=5'>6</a>\u001b[0m training_dataset \u001b[39m=\u001b[39m CGDataset(training_dir, rmsd_list, transform\u001b[39m=\u001b[39;49mT\u001b[39m.\u001b[39;49mToDense(\u001b[39m64\u001b[39;49m))\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'data_name'"
          ]
        }
      ],
      "source": [
        "#Training Set\n",
        "import torch_geometric.transforms as T\n",
        "training_dir = \"data/train_set\"\n",
        "rmsd_list = \"data/truncated_train_rmsd.txt\"\n",
        "\n",
        "training_dataset = CGDataset(training_dir, rmsd_list, transform=T.ToDense(64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "bq8dpernrILf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq8dpernrILf",
        "outputId": "18654cbb-a816-490f-fc60-015f5c432b3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#Validation Set\n",
        "val_dir = \"data/val_set\"\n",
        "val_rmsd = \"data/val_rmsd_list.txt\"\n",
        "\n",
        "val_dataset = CGDataset(val_dir, val_rmsd, transform=T.ToDense(64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8f96d73c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CGDataset(760)\n",
            "Data(x=[12, 18], edge_index=[2, 24], y=[1])\n",
            "torch.Size([11769, 18])\n",
            "True\n",
            "760\n",
            "12\n",
            "tensor([6.5820])\n",
            "24\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
            "         [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
            "         [1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]])\n",
            "torch.Size([12, 18])\n"
          ]
        }
      ],
      "source": [
        "import torch_geometric.utils as pygu\n",
        "print(training_dataset)\n",
        "print(training_dataset[0])\n",
        "print(training_dataset.data.x.shape)\n",
        "print(training_dataset.data.is_undirected())\n",
        "print(len(training_dataset))\n",
        "print(training_dataset[0].num_nodes)\n",
        "print(training_dataset[0].y)\n",
        "print(training_dataset[0].num_edges)\n",
        "print(pygu.to_dense_adj(training_dataset[0].edge_index))#to_scipy_sparse_matrix(training_dataset[0].edge_index))\n",
        "print(training_dataset[0].x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "2943be90-6647-4c26-b967-a2563a142877",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "2943be90-6647-4c26-b967-a2563a142877",
        "outputId": "9636ec89-031d-4ab8-b8a0-3b21c105f5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Training loss 9.7110, Validation loss 14.8070, learning rate: 0.00100\n",
            "prediction loss: 0.1776, entropy regularization 2.2009\n",
            "Epoch 5: Training loss 4.4381, Validation loss 16.5512, learning rate: 0.00100\n",
            "prediction loss: 0.1552, entropy regularization 2.1532\n",
            "Epoch 10: Training loss 3.1474, Validation loss 17.7333, learning rate: 0.00100\n",
            "prediction loss: 0.1291, entropy regularization 2.1955\n",
            "Epoch 15: Training loss 2.4838, Validation loss 17.1231, learning rate: 0.00100\n",
            "prediction loss: 0.1387, entropy regularization 2.1718\n",
            "Epoch 20: Training loss 2.3454, Validation loss 17.5648, learning rate: 0.00100\n",
            "prediction loss: 0.1649, entropy regularization 2.1792\n",
            "Epoch 25: Training loss 1.9730, Validation loss 17.6408, learning rate: 0.00099\n",
            "prediction loss: 0.1379, entropy regularization 2.1409\n",
            "Epoch 30: Training loss 1.7750, Validation loss 17.6310, learning rate: 0.00099\n",
            "prediction loss: 0.1501, entropy regularization 2.1640\n",
            "Epoch 35: Training loss 1.8602, Validation loss 18.5348, learning rate: 0.00099\n",
            "prediction loss: 0.1532, entropy regularization 2.1052\n",
            "Epoch 40: Training loss 1.5340, Validation loss 17.9625, learning rate: 0.00098\n",
            "prediction loss: 0.1505, entropy regularization 2.0992\n",
            "Epoch 45: Training loss 1.3935, Validation loss 18.4893, learning rate: 0.00098\n",
            "prediction loss: 0.1671, entropy regularization 2.0977\n",
            "Epoch 50: Training loss 1.4994, Validation loss 18.1940, learning rate: 0.00097\n",
            "prediction loss: 0.1463, entropy regularization 2.0968\n",
            "Epoch 55: Training loss 1.4533, Validation loss 17.3177, learning rate: 0.00097\n",
            "prediction loss: 0.1580, entropy regularization 2.1353\n",
            "Epoch 60: Training loss 1.0464, Validation loss 18.5747, learning rate: 0.00096\n",
            "prediction loss: 0.1566, entropy regularization 2.1065\n",
            "Epoch 65: Training loss 0.9771, Validation loss 17.1313, learning rate: 0.00096\n",
            "prediction loss: 0.1493, entropy regularization 2.1013\n",
            "Epoch 70: Training loss 1.1737, Validation loss 17.4635, learning rate: 0.00095\n",
            "prediction loss: 0.1291, entropy regularization 2.1077\n",
            "Epoch 75: Training loss 0.9102, Validation loss 18.0387, learning rate: 0.00094\n",
            "prediction loss: 0.1435, entropy regularization 2.0629\n",
            "Epoch 80: Training loss 0.7001, Validation loss 18.7900, learning rate: 0.00094\n",
            "prediction loss: 0.1675, entropy regularization 2.0709\n",
            "Epoch 85: Training loss 0.7666, Validation loss 19.1609, learning rate: 0.00093\n",
            "prediction loss: 0.1752, entropy regularization 2.0496\n",
            "Epoch 90: Training loss 0.8852, Validation loss 18.0958, learning rate: 0.00092\n",
            "prediction loss: 0.1604, entropy regularization 2.0956\n",
            "Epoch 95: Training loss 0.7107, Validation loss 18.3199, learning rate: 0.00091\n",
            "prediction loss: 0.1445, entropy regularization 2.0559\n",
            "Epoch 100: Training loss 0.5250, Validation loss 19.1696, learning rate: 0.00090\n",
            "prediction loss: 0.1471, entropy regularization 2.0217\n",
            "Epoch 105: Training loss 0.5878, Validation loss 18.6338, learning rate: 0.00089\n",
            "prediction loss: 0.1676, entropy regularization 2.0473\n",
            "Epoch 110: Training loss 0.5059, Validation loss 19.0165, learning rate: 0.00088\n",
            "prediction loss: 0.1469, entropy regularization 2.0597\n",
            "Epoch 115: Training loss 0.4120, Validation loss 18.9839, learning rate: 0.00087\n",
            "prediction loss: 0.1611, entropy regularization 2.0193\n",
            "Epoch 120: Training loss 0.3450, Validation loss 18.7557, learning rate: 0.00086\n",
            "prediction loss: 0.1595, entropy regularization 2.0141\n",
            "Epoch 125: Training loss 0.4297, Validation loss 18.8338, learning rate: 0.00085\n",
            "prediction loss: 0.1503, entropy regularization 1.9732\n",
            "Epoch 130: Training loss 0.2700, Validation loss 18.7773, learning rate: 0.00084\n",
            "prediction loss: 0.1335, entropy regularization 1.9897\n",
            "Epoch 135: Training loss 0.3209, Validation loss 18.8893, learning rate: 0.00083\n",
            "prediction loss: 0.1385, entropy regularization 1.9793\n",
            "Epoch 140: Training loss 0.2975, Validation loss 19.1718, learning rate: 0.00082\n",
            "prediction loss: 0.1626, entropy regularization 1.9836\n",
            "Epoch 145: Training loss 0.2914, Validation loss 19.7533, learning rate: 0.00080\n",
            "prediction loss: 0.1504, entropy regularization 1.9958\n",
            "Epoch 150: Training loss 0.4106, Validation loss 19.2032, learning rate: 0.00079\n",
            "prediction loss: 0.1483, entropy regularization 1.9724\n",
            "Epoch 155: Training loss 0.2462, Validation loss 19.0660, learning rate: 0.00078\n",
            "prediction loss: 0.1517, entropy regularization 1.9497\n",
            "Epoch 160: Training loss 0.2215, Validation loss 19.1270, learning rate: 0.00077\n",
            "prediction loss: 0.1587, entropy regularization 1.9607\n",
            "Epoch 165: Training loss 0.2692, Validation loss 19.0582, learning rate: 0.00075\n",
            "prediction loss: 0.1391, entropy regularization 2.0035\n",
            "Epoch 170: Training loss 0.1862, Validation loss 18.9608, learning rate: 0.00074\n",
            "prediction loss: 0.1314, entropy regularization 1.9897\n",
            "Epoch 175: Training loss 0.1705, Validation loss 19.0283, learning rate: 0.00072\n",
            "prediction loss: 0.1541, entropy regularization 1.9998\n",
            "Epoch 180: Training loss 0.1982, Validation loss 19.0478, learning rate: 0.00071\n",
            "prediction loss: 0.1372, entropy regularization 1.9854\n",
            "Epoch 185: Training loss 0.1931, Validation loss 18.9391, learning rate: 0.00070\n",
            "prediction loss: 0.1363, entropy regularization 1.9714\n",
            "Epoch 190: Training loss 0.1453, Validation loss 19.3406, learning rate: 0.00068\n",
            "prediction loss: 0.1589, entropy regularization 1.9683\n",
            "Epoch 195: Training loss 0.3097, Validation loss 19.0518, learning rate: 0.00067\n",
            "prediction loss: 0.1492, entropy regularization 1.9996\n",
            "Epoch 200: Training loss 0.1403, Validation loss 19.5334, learning rate: 0.00065\n",
            "prediction loss: 0.1665, entropy regularization 1.9996\n",
            "Epoch 205: Training loss 0.1760, Validation loss 19.3542, learning rate: 0.00064\n",
            "prediction loss: 0.1514, entropy regularization 1.9319\n",
            "Epoch 210: Training loss 0.0946, Validation loss 19.4203, learning rate: 0.00062\n",
            "prediction loss: 0.1717, entropy regularization 1.9771\n",
            "Epoch 215: Training loss 0.0588, Validation loss 19.7632, learning rate: 0.00061\n",
            "prediction loss: 0.1496, entropy regularization 1.9801\n",
            "Epoch 220: Training loss 0.1241, Validation loss 20.0055, learning rate: 0.00059\n",
            "prediction loss: 0.1431, entropy regularization 1.9517\n",
            "Epoch 225: Training loss 0.1665, Validation loss 19.3334, learning rate: 0.00058\n",
            "prediction loss: 0.1560, entropy regularization 1.9703\n",
            "Epoch 230: Training loss 0.0789, Validation loss 19.6064, learning rate: 0.00056\n",
            "prediction loss: 0.1515, entropy regularization 1.9578\n",
            "Epoch 235: Training loss 0.0773, Validation loss 19.8356, learning rate: 0.00054\n",
            "prediction loss: 0.1523, entropy regularization 1.9759\n",
            "Epoch 240: Training loss 0.0656, Validation loss 19.6370, learning rate: 0.00053\n",
            "prediction loss: 0.1368, entropy regularization 2.0037\n",
            "Epoch 245: Training loss 0.0373, Validation loss 19.7487, learning rate: 0.00051\n",
            "prediction loss: 0.1452, entropy regularization 1.9608\n",
            "Epoch 250: Training loss 0.0908, Validation loss 19.7855, learning rate: 0.00050\n",
            "prediction loss: 0.1524, entropy regularization 1.9535\n",
            "Epoch 255: Training loss 0.0422, Validation loss 19.9834, learning rate: 0.00048\n",
            "prediction loss: 0.1528, entropy regularization 1.9634\n",
            "Epoch 260: Training loss 0.0336, Validation loss 19.7686, learning rate: 0.00047\n",
            "prediction loss: 0.1651, entropy regularization 1.9746\n",
            "Epoch 265: Training loss 0.0356, Validation loss 19.8289, learning rate: 0.00045\n",
            "prediction loss: 0.1463, entropy regularization 1.9718\n",
            "Epoch 270: Training loss 0.0287, Validation loss 19.8441, learning rate: 0.00043\n",
            "prediction loss: 0.1577, entropy regularization 1.9686\n",
            "Epoch 275: Training loss 0.0273, Validation loss 19.8560, learning rate: 0.00042\n",
            "prediction loss: 0.1510, entropy regularization 1.9318\n",
            "Epoch 280: Training loss 0.0170, Validation loss 19.8551, learning rate: 0.00040\n",
            "prediction loss: 0.1561, entropy regularization 1.9876\n",
            "Epoch 285: Training loss 0.0142, Validation loss 19.9285, learning rate: 0.00039\n",
            "prediction loss: 0.1538, entropy regularization 1.9607\n",
            "Epoch 290: Training loss 0.0080, Validation loss 19.8565, learning rate: 0.00037\n",
            "prediction loss: 0.1547, entropy regularization 1.9747\n",
            "Epoch 295: Training loss 0.0105, Validation loss 19.8312, learning rate: 0.00036\n",
            "prediction loss: 0.1232, entropy regularization 1.9637\n",
            "Epoch 300: Training loss 0.0073, Validation loss 19.8115, learning rate: 0.00034\n",
            "prediction loss: 0.1710, entropy regularization 1.9589\n",
            "Epoch 305: Training loss 0.0074, Validation loss 19.8066, learning rate: 0.00033\n",
            "prediction loss: 0.1406, entropy regularization 1.9398\n",
            "Epoch 310: Training loss 0.0059, Validation loss 19.8001, learning rate: 0.00031\n",
            "prediction loss: 0.1316, entropy regularization 1.9768\n",
            "Epoch 315: Training loss 0.0098, Validation loss 19.7896, learning rate: 0.00030\n",
            "prediction loss: 0.1375, entropy regularization 1.9529\n",
            "Epoch 320: Training loss 0.0071, Validation loss 19.8450, learning rate: 0.00028\n",
            "prediction loss: 0.1405, entropy regularization 1.9369\n",
            "Epoch 325: Training loss 0.0067, Validation loss 19.7944, learning rate: 0.00027\n",
            "prediction loss: 0.1514, entropy regularization 1.9971\n",
            "Epoch 330: Training loss 0.0051, Validation loss 19.8153, learning rate: 0.00026\n",
            "prediction loss: 0.1424, entropy regularization 1.9693\n",
            "Epoch 335: Training loss 0.0037, Validation loss 19.8098, learning rate: 0.00024\n",
            "prediction loss: 0.1581, entropy regularization 1.9609\n",
            "Epoch 340: Training loss 0.0042, Validation loss 19.8129, learning rate: 0.00023\n",
            "prediction loss: 0.1571, entropy regularization 1.9850\n",
            "Epoch 345: Training loss 0.0050, Validation loss 19.8448, learning rate: 0.00022\n",
            "prediction loss: 0.1469, entropy regularization 1.9117\n",
            "Epoch 350: Training loss 0.0040, Validation loss 19.7965, learning rate: 0.00020\n",
            "prediction loss: 0.1572, entropy regularization 1.9526\n",
            "Epoch 355: Training loss 0.0036, Validation loss 19.8021, learning rate: 0.00019\n",
            "prediction loss: 0.1211, entropy regularization 1.9376\n",
            "Epoch 360: Training loss 0.0031, Validation loss 19.7989, learning rate: 0.00018\n",
            "prediction loss: 0.1524, entropy regularization 1.9877\n",
            "Epoch 365: Training loss 0.0030, Validation loss 19.8207, learning rate: 0.00017\n",
            "prediction loss: 0.1381, entropy regularization 1.9541\n",
            "Epoch 370: Training loss 0.0036, Validation loss 19.8395, learning rate: 0.00016\n",
            "prediction loss: 0.1383, entropy regularization 1.9611\n",
            "Epoch 375: Training loss 0.0029, Validation loss 19.8163, learning rate: 0.00014\n",
            "prediction loss: 0.1473, entropy regularization 1.9402\n",
            "Epoch 380: Training loss 0.0032, Validation loss 19.8137, learning rate: 0.00013\n",
            "prediction loss: 0.1482, entropy regularization 1.9733\n",
            "Epoch 385: Training loss 0.0023, Validation loss 19.8063, learning rate: 0.00012\n",
            "prediction loss: 0.1426, entropy regularization 1.9983\n",
            "Epoch 390: Training loss 0.0025, Validation loss 19.8092, learning rate: 0.00011\n",
            "prediction loss: 0.1385, entropy regularization 1.9886\n",
            "Epoch 395: Training loss 0.0026, Validation loss 19.8288, learning rate: 0.00010\n",
            "prediction loss: 0.1380, entropy regularization 1.9816\n",
            "Epoch 400: Training loss 0.0029, Validation loss 19.8186, learning rate: 0.00009\n",
            "prediction loss: 0.1555, entropy regularization 1.9417\n",
            "Epoch 405: Training loss 0.0018, Validation loss 19.8255, learning rate: 0.00008\n",
            "prediction loss: 0.1673, entropy regularization 1.9546\n",
            "Epoch 410: Training loss 0.0014, Validation loss 19.8214, learning rate: 0.00008\n",
            "prediction loss: 0.1597, entropy regularization 1.9687\n",
            "Epoch 415: Training loss 0.0031, Validation loss 19.8294, learning rate: 0.00007\n",
            "prediction loss: 0.1348, entropy regularization 1.9894\n",
            "Epoch 420: Training loss 0.0028, Validation loss 19.8273, learning rate: 0.00006\n",
            "prediction loss: 0.1498, entropy regularization 1.9598\n",
            "Epoch 425: Training loss 0.0016, Validation loss 19.8256, learning rate: 0.00005\n",
            "prediction loss: 0.1563, entropy regularization 1.9641\n",
            "Epoch 430: Training loss 0.0014, Validation loss 19.8282, learning rate: 0.00005\n",
            "prediction loss: 0.1407, entropy regularization 1.9801\n",
            "Epoch 435: Training loss 0.0020, Validation loss 19.8241, learning rate: 0.00004\n",
            "prediction loss: 0.1324, entropy regularization 1.9512\n",
            "Epoch 440: Training loss 0.0015, Validation loss 19.8279, learning rate: 0.00003\n",
            "prediction loss: 0.1282, entropy regularization 1.9414\n",
            "Epoch 445: Training loss 0.0011, Validation loss 19.8290, learning rate: 0.00003\n",
            "prediction loss: 0.1559, entropy regularization 1.9198\n",
            "Epoch 450: Training loss 0.0014, Validation loss 19.8350, learning rate: 0.00002\n",
            "prediction loss: 0.1481, entropy regularization 1.9631\n",
            "Epoch 455: Training loss 0.0011, Validation loss 19.8346, learning rate: 0.00002\n",
            "prediction loss: 0.1656, entropy regularization 1.9669\n",
            "Epoch 460: Training loss 0.0010, Validation loss 19.8306, learning rate: 0.00001\n",
            "prediction loss: 0.1350, entropy regularization 1.9240\n",
            "Epoch 465: Training loss 0.0010, Validation loss 19.8332, learning rate: 0.00001\n",
            "prediction loss: 0.1738, entropy regularization 1.9693\n",
            "Epoch 470: Training loss 0.0010, Validation loss 19.8342, learning rate: 0.00001\n",
            "prediction loss: 0.1621, entropy regularization 1.9459\n",
            "Epoch 475: Training loss 0.0010, Validation loss 19.8332, learning rate: 0.00001\n",
            "prediction loss: 0.1864, entropy regularization 1.9800\n",
            "Epoch 480: Training loss 0.0009, Validation loss 19.8327, learning rate: 0.00000\n",
            "prediction loss: 0.1524, entropy regularization 1.9613\n",
            "Epoch 485: Training loss 0.0009, Validation loss 19.8325, learning rate: 0.00000\n",
            "prediction loss: 0.1564, entropy regularization 1.9799\n",
            "Epoch 490: Training loss 0.0009, Validation loss 19.8329, learning rate: 0.00000\n",
            "prediction loss: 0.1372, entropy regularization 1.9478\n",
            "Epoch 495: Training loss 0.0009, Validation loss 19.8328, learning rate: 0.00000\n",
            "prediction loss: 0.1380, entropy regularization 1.9861\n",
            "Epoch 500: Training loss 1.2960, Validation loss 15.9150, learning rate: 0.00100\n",
            "prediction loss: 0.1273, entropy regularization 1.9772\n",
            "Epoch 505: Training loss 3.4722, Validation loss 18.6522, learning rate: 0.00100\n",
            "prediction loss: 0.2620, entropy regularization 1.7356\n",
            "Epoch 510: Training loss 2.9482, Validation loss 17.1133, learning rate: 0.00100\n",
            "prediction loss: 0.2581, entropy regularization 1.5528\n",
            "Epoch 515: Training loss 2.1632, Validation loss 17.7088, learning rate: 0.00100\n",
            "prediction loss: 0.2495, entropy regularization 1.4364\n",
            "Epoch 520: Training loss 1.9693, Validation loss 17.5897, learning rate: 0.00100\n",
            "prediction loss: 0.2614, entropy regularization 1.4901\n",
            "Epoch 525: Training loss 1.4801, Validation loss 16.8358, learning rate: 0.00099\n",
            "prediction loss: 0.2537, entropy regularization 1.4960\n",
            "Epoch 530: Training loss 1.2246, Validation loss 17.1794, learning rate: 0.00099\n",
            "prediction loss: 0.2525, entropy regularization 1.5293\n",
            "Epoch 535: Training loss 1.0047, Validation loss 16.9680, learning rate: 0.00099\n",
            "prediction loss: 0.2579, entropy regularization 1.4733\n",
            "Epoch 540: Training loss 1.1422, Validation loss 16.8991, learning rate: 0.00098\n",
            "prediction loss: 0.2487, entropy regularization 1.4998\n",
            "Epoch 545: Training loss 0.8448, Validation loss 16.8215, learning rate: 0.00098\n",
            "prediction loss: 0.2621, entropy regularization 1.5180\n",
            "Epoch 550: Training loss 1.0664, Validation loss 18.6839, learning rate: 0.00097\n",
            "prediction loss: 0.2431, entropy regularization 1.4646\n",
            "Epoch 555: Training loss 3.1862, Validation loss 16.8654, learning rate: 0.00097\n",
            "prediction loss: 0.2548, entropy regularization 1.4058\n",
            "Epoch 560: Training loss 1.6494, Validation loss 17.5331, learning rate: 0.00096\n",
            "prediction loss: 0.2567, entropy regularization 1.3707\n",
            "Epoch 565: Training loss 1.6137, Validation loss 17.7252, learning rate: 0.00096\n",
            "prediction loss: 0.2527, entropy regularization 1.3812\n",
            "Epoch 570: Training loss 1.3022, Validation loss 17.9522, learning rate: 0.00095\n",
            "prediction loss: 0.2566, entropy regularization 1.3964\n",
            "Epoch 575: Training loss 0.9287, Validation loss 18.0450, learning rate: 0.00094\n",
            "prediction loss: 0.2504, entropy regularization 1.3955\n",
            "Epoch 580: Training loss 0.9743, Validation loss 17.6321, learning rate: 0.00094\n",
            "prediction loss: 0.2476, entropy regularization 1.4079\n",
            "Epoch 585: Training loss 0.6916, Validation loss 17.9568, learning rate: 0.00093\n",
            "prediction loss: 0.2542, entropy regularization 1.3820\n",
            "Epoch 590: Training loss 0.6629, Validation loss 17.9261, learning rate: 0.00092\n",
            "prediction loss: 0.2533, entropy regularization 1.3898\n",
            "Epoch 595: Training loss 0.5639, Validation loss 18.3420, learning rate: 0.00091\n",
            "prediction loss: 0.2535, entropy regularization 1.4031\n",
            "Epoch 600: Training loss 0.6057, Validation loss 18.6324, learning rate: 0.00090\n",
            "prediction loss: 0.2641, entropy regularization 1.3996\n",
            "Epoch 605: Training loss 0.4951, Validation loss 17.6356, learning rate: 0.00089\n",
            "prediction loss: 0.2396, entropy regularization 1.4508\n",
            "Epoch 610: Training loss 0.4528, Validation loss 18.3308, learning rate: 0.00088\n",
            "prediction loss: 0.2475, entropy regularization 1.4177\n",
            "Epoch 615: Training loss 0.4229, Validation loss 18.4359, learning rate: 0.00087\n",
            "prediction loss: 0.2540, entropy regularization 1.4171\n",
            "Epoch 620: Training loss 0.4874, Validation loss 17.9563, learning rate: 0.00086\n",
            "prediction loss: 0.2437, entropy regularization 1.4433\n",
            "Epoch 625: Training loss 0.4054, Validation loss 18.7050, learning rate: 0.00085\n",
            "prediction loss: 0.2489, entropy regularization 1.4331\n",
            "Epoch 630: Training loss 0.3988, Validation loss 18.3599, learning rate: 0.00084\n",
            "prediction loss: 0.2707, entropy regularization 1.4037\n",
            "Epoch 635: Training loss 0.3316, Validation loss 18.5258, learning rate: 0.00083\n",
            "prediction loss: 0.2549, entropy regularization 1.4169\n",
            "Epoch 640: Training loss 0.2495, Validation loss 18.3911, learning rate: 0.00082\n",
            "prediction loss: 0.2541, entropy regularization 1.4339\n",
            "Epoch 645: Training loss 0.3145, Validation loss 18.3563, learning rate: 0.00080\n",
            "prediction loss: 0.2601, entropy regularization 1.4288\n",
            "Epoch 650: Training loss 0.2362, Validation loss 18.3828, learning rate: 0.00079\n",
            "prediction loss: 0.2463, entropy regularization 1.4368\n",
            "Epoch 655: Training loss 0.2350, Validation loss 18.4088, learning rate: 0.00078\n",
            "prediction loss: 0.2597, entropy regularization 1.4198\n",
            "Epoch 660: Training loss 0.2202, Validation loss 18.3049, learning rate: 0.00077\n",
            "prediction loss: 0.2542, entropy regularization 1.4243\n",
            "Epoch 665: Training loss 0.1964, Validation loss 18.2347, learning rate: 0.00075\n",
            "prediction loss: 0.2584, entropy regularization 1.4220\n",
            "Epoch 670: Training loss 0.2072, Validation loss 18.3279, learning rate: 0.00074\n",
            "prediction loss: 0.2516, entropy regularization 1.4380\n",
            "Epoch 675: Training loss 0.2403, Validation loss 18.4404, learning rate: 0.00072\n",
            "prediction loss: 0.2651, entropy regularization 1.4095\n",
            "Epoch 680: Training loss 0.1459, Validation loss 18.5633, learning rate: 0.00071\n",
            "prediction loss: 0.2679, entropy regularization 1.4113\n",
            "Epoch 685: Training loss 0.1519, Validation loss 18.6046, learning rate: 0.00070\n",
            "prediction loss: 0.2642, entropy regularization 1.4173\n",
            "Epoch 690: Training loss 0.1164, Validation loss 18.8648, learning rate: 0.00068\n",
            "prediction loss: 0.2557, entropy regularization 1.4385\n",
            "Epoch 695: Training loss 0.1058, Validation loss 18.4450, learning rate: 0.00067\n",
            "prediction loss: 0.2473, entropy regularization 1.4475\n",
            "Epoch 700: Training loss 0.1635, Validation loss 18.4763, learning rate: 0.00065\n",
            "prediction loss: 0.2620, entropy regularization 1.4163\n",
            "Epoch 705: Training loss 0.1654, Validation loss 18.7963, learning rate: 0.00064\n",
            "prediction loss: 0.2517, entropy regularization 1.4538\n",
            "Epoch 710: Training loss 0.0962, Validation loss 18.4775, learning rate: 0.00062\n",
            "prediction loss: 0.2506, entropy regularization 1.4641\n",
            "Epoch 715: Training loss 0.0879, Validation loss 18.7515, learning rate: 0.00061\n",
            "prediction loss: 0.2606, entropy regularization 1.4333\n",
            "Epoch 720: Training loss 0.1128, Validation loss 18.6881, learning rate: 0.00059\n",
            "prediction loss: 0.2473, entropy regularization 1.4396\n",
            "Epoch 725: Training loss 0.1060, Validation loss 18.9629, learning rate: 0.00058\n",
            "prediction loss: 0.2442, entropy regularization 1.4442\n",
            "Epoch 730: Training loss 0.0782, Validation loss 18.9256, learning rate: 0.00056\n",
            "prediction loss: 0.2719, entropy regularization 1.4287\n",
            "Epoch 735: Training loss 0.0994, Validation loss 18.6570, learning rate: 0.00054\n",
            "prediction loss: 0.2481, entropy regularization 1.4473\n",
            "Epoch 740: Training loss 0.0785, Validation loss 18.5982, learning rate: 0.00053\n",
            "prediction loss: 0.2452, entropy regularization 1.4656\n",
            "Epoch 745: Training loss 0.0566, Validation loss 18.8970, learning rate: 0.00051\n",
            "prediction loss: 0.2508, entropy regularization 1.4391\n",
            "Epoch 750: Training loss 0.0445, Validation loss 18.9407, learning rate: 0.00050\n",
            "prediction loss: 0.2425, entropy regularization 1.4619\n",
            "Epoch 755: Training loss 0.0534, Validation loss 18.7677, learning rate: 0.00048\n",
            "prediction loss: 0.2571, entropy regularization 1.4516\n",
            "Epoch 760: Training loss 0.0315, Validation loss 18.8803, learning rate: 0.00047\n",
            "prediction loss: 0.2817, entropy regularization 1.4024\n",
            "Epoch 765: Training loss 0.0301, Validation loss 18.9060, learning rate: 0.00045\n",
            "prediction loss: 0.2683, entropy regularization 1.4218\n",
            "Epoch 770: Training loss 0.0435, Validation loss 18.9338, learning rate: 0.00043\n",
            "prediction loss: 0.2597, entropy regularization 1.4566\n",
            "Epoch 775: Training loss 0.0310, Validation loss 18.9084, learning rate: 0.00042\n",
            "prediction loss: 0.2592, entropy regularization 1.4381\n",
            "Epoch 780: Training loss 0.0234, Validation loss 18.8083, learning rate: 0.00040\n",
            "prediction loss: 0.2603, entropy regularization 1.4461\n",
            "Epoch 785: Training loss 0.0341, Validation loss 18.7669, learning rate: 0.00039\n",
            "prediction loss: 0.2555, entropy regularization 1.4409\n",
            "Epoch 790: Training loss 0.0174, Validation loss 18.8441, learning rate: 0.00037\n",
            "prediction loss: 0.2611, entropy regularization 1.4406\n",
            "Epoch 795: Training loss 0.0184, Validation loss 18.9971, learning rate: 0.00036\n",
            "prediction loss: 0.2608, entropy regularization 1.4483\n",
            "Epoch 800: Training loss 0.0120, Validation loss 18.8027, learning rate: 0.00034\n",
            "prediction loss: 0.2503, entropy regularization 1.4537\n",
            "Epoch 805: Training loss 0.0158, Validation loss 18.8110, learning rate: 0.00033\n",
            "prediction loss: 0.2473, entropy regularization 1.4647\n",
            "Epoch 810: Training loss 0.0146, Validation loss 18.9337, learning rate: 0.00031\n",
            "prediction loss: 0.2393, entropy regularization 1.4694\n",
            "Epoch 815: Training loss 0.0085, Validation loss 18.8453, learning rate: 0.00030\n",
            "prediction loss: 0.2546, entropy regularization 1.4367\n",
            "Epoch 820: Training loss 0.0098, Validation loss 18.9169, learning rate: 0.00028\n",
            "prediction loss: 0.2617, entropy regularization 1.4326\n",
            "Epoch 825: Training loss 0.0076, Validation loss 18.8602, learning rate: 0.00027\n",
            "prediction loss: 0.2531, entropy regularization 1.4679\n",
            "Epoch 830: Training loss 0.0067, Validation loss 18.9031, learning rate: 0.00026\n",
            "prediction loss: 0.2685, entropy regularization 1.4366\n",
            "Epoch 835: Training loss 0.0044, Validation loss 18.9309, learning rate: 0.00024\n",
            "prediction loss: 0.2663, entropy regularization 1.4344\n",
            "Epoch 840: Training loss 0.0036, Validation loss 18.9095, learning rate: 0.00023\n",
            "prediction loss: 0.2530, entropy regularization 1.4491\n",
            "Epoch 845: Training loss 0.0048, Validation loss 18.9432, learning rate: 0.00022\n",
            "prediction loss: 0.2528, entropy regularization 1.4658\n",
            "Epoch 850: Training loss 0.0056, Validation loss 18.9340, learning rate: 0.00020\n",
            "prediction loss: 0.2596, entropy regularization 1.4419\n",
            "Epoch 855: Training loss 0.0035, Validation loss 18.9336, learning rate: 0.00019\n",
            "prediction loss: 0.2603, entropy regularization 1.4493\n",
            "Epoch 860: Training loss 0.0067, Validation loss 18.9273, learning rate: 0.00018\n",
            "prediction loss: 0.2303, entropy regularization 1.4866\n",
            "Epoch 865: Training loss 0.0041, Validation loss 18.9502, learning rate: 0.00017\n",
            "prediction loss: 0.2528, entropy regularization 1.4566\n",
            "Epoch 870: Training loss 0.0031, Validation loss 18.9486, learning rate: 0.00016\n",
            "prediction loss: 0.2662, entropy regularization 1.4346\n",
            "Epoch 875: Training loss 0.0037, Validation loss 18.9487, learning rate: 0.00014\n",
            "prediction loss: 0.2528, entropy regularization 1.4645\n",
            "Epoch 880: Training loss 0.0034, Validation loss 18.9522, learning rate: 0.00013\n",
            "prediction loss: 0.2565, entropy regularization 1.4540\n",
            "Epoch 885: Training loss 0.0027, Validation loss 18.9304, learning rate: 0.00012\n",
            "prediction loss: 0.2537, entropy regularization 1.4489\n",
            "Epoch 890: Training loss 0.0033, Validation loss 18.9414, learning rate: 0.00011\n",
            "prediction loss: 0.2554, entropy regularization 1.4509\n",
            "Epoch 895: Training loss 0.0030, Validation loss 18.9324, learning rate: 0.00010\n",
            "prediction loss: 0.2474, entropy regularization 1.4700\n",
            "Epoch 900: Training loss 0.0027, Validation loss 18.9558, learning rate: 0.00009\n",
            "prediction loss: 0.2464, entropy regularization 1.4549\n",
            "Epoch 905: Training loss 0.0022, Validation loss 18.9532, learning rate: 0.00008\n",
            "prediction loss: 0.2571, entropy regularization 1.4615\n",
            "Epoch 910: Training loss 0.0024, Validation loss 18.9506, learning rate: 0.00008\n",
            "prediction loss: 0.2662, entropy regularization 1.4400\n",
            "Epoch 915: Training loss 0.0023, Validation loss 18.9484, learning rate: 0.00007\n",
            "prediction loss: 0.2743, entropy regularization 1.4339\n",
            "Epoch 920: Training loss 0.0022, Validation loss 18.9591, learning rate: 0.00006\n",
            "prediction loss: 0.2567, entropy regularization 1.4420\n",
            "Epoch 925: Training loss 0.0021, Validation loss 18.9572, learning rate: 0.00005\n",
            "prediction loss: 0.2629, entropy regularization 1.4549\n",
            "Epoch 930: Training loss 0.0022, Validation loss 18.9577, learning rate: 0.00005\n",
            "prediction loss: 0.2643, entropy regularization 1.4448\n",
            "Epoch 935: Training loss 0.0021, Validation loss 18.9520, learning rate: 0.00004\n",
            "prediction loss: 0.2717, entropy regularization 1.4243\n",
            "Epoch 940: Training loss 0.0021, Validation loss 18.9558, learning rate: 0.00003\n",
            "prediction loss: 0.2404, entropy regularization 1.4631\n",
            "Epoch 945: Training loss 0.0019, Validation loss 18.9522, learning rate: 0.00003\n",
            "prediction loss: 0.2661, entropy regularization 1.4359\n",
            "Epoch 950: Training loss 0.0019, Validation loss 18.9520, learning rate: 0.00002\n",
            "prediction loss: 0.2650, entropy regularization 1.4366\n",
            "Epoch 955: Training loss 0.0020, Validation loss 18.9571, learning rate: 0.00002\n",
            "prediction loss: 0.2595, entropy regularization 1.4495\n",
            "Epoch 960: Training loss 0.0020, Validation loss 18.9558, learning rate: 0.00001\n",
            "prediction loss: 0.2662, entropy regularization 1.4385\n",
            "Epoch 965: Training loss 0.0019, Validation loss 18.9557, learning rate: 0.00001\n",
            "prediction loss: 0.2518, entropy regularization 1.4484\n",
            "Epoch 970: Training loss 0.0019, Validation loss 18.9565, learning rate: 0.00001\n",
            "prediction loss: 0.2526, entropy regularization 1.4589\n",
            "Epoch 975: Training loss 0.0019, Validation loss 18.9565, learning rate: 0.00001\n",
            "prediction loss: 0.2562, entropy regularization 1.4553\n",
            "Epoch 980: Training loss 0.0018, Validation loss 18.9572, learning rate: 0.00000\n",
            "prediction loss: 0.2613, entropy regularization 1.4516\n",
            "Epoch 985: Training loss 0.0018, Validation loss 18.9570, learning rate: 0.00000\n",
            "prediction loss: 0.2552, entropy regularization 1.4461\n",
            "Epoch 990: Training loss 0.0018, Validation loss 18.9572, learning rate: 0.00000\n",
            "prediction loss: 0.2675, entropy regularization 1.4452\n",
            "Epoch 995: Training loss 0.0018, Validation loss 18.9571, learning rate: 0.00000\n",
            "prediction loss: 0.2680, entropy regularization 1.4378\n",
            "Epoch 1000: Training loss 1.5977, Validation loss 17.6199, learning rate: 0.00100\n",
            "prediction loss: 0.2471, entropy regularization 1.4661\n",
            "Epoch 1005: Training loss 3.7306, Validation loss 16.3149, learning rate: 0.00100\n",
            "prediction loss: 0.1581, entropy regularization 1.2434\n",
            "Epoch 1010: Training loss 2.9044, Validation loss 17.3745, learning rate: 0.00100\n",
            "prediction loss: 0.2023, entropy regularization 1.0975\n",
            "Epoch 1015: Training loss 2.3884, Validation loss 16.0773, learning rate: 0.00100\n",
            "prediction loss: 0.1932, entropy regularization 1.0630\n",
            "Epoch 1020: Training loss 1.8946, Validation loss 17.5363, learning rate: 0.00100\n",
            "prediction loss: 0.1679, entropy regularization 1.0173\n",
            "Epoch 1025: Training loss 1.7284, Validation loss 17.9421, learning rate: 0.00099\n",
            "prediction loss: 0.1858, entropy regularization 0.9724\n",
            "Epoch 1030: Training loss 1.5951, Validation loss 18.1077, learning rate: 0.00099\n",
            "prediction loss: 0.1919, entropy regularization 0.9592\n",
            "Epoch 1035: Training loss 1.4247, Validation loss 17.9923, learning rate: 0.00099\n",
            "prediction loss: 0.1745, entropy regularization 0.9192\n",
            "Epoch 1040: Training loss 1.1728, Validation loss 17.1210, learning rate: 0.00098\n",
            "prediction loss: 0.1698, entropy regularization 0.9204\n",
            "Epoch 1045: Training loss 1.3391, Validation loss 17.2599, learning rate: 0.00098\n",
            "prediction loss: 0.1675, entropy regularization 0.9361\n",
            "Epoch 1050: Training loss 1.2757, Validation loss 17.1274, learning rate: 0.00097\n",
            "prediction loss: 0.1577, entropy regularization 1.0108\n",
            "Epoch 1055: Training loss 1.0532, Validation loss 17.3235, learning rate: 0.00097\n",
            "prediction loss: 0.1472, entropy regularization 0.9475\n",
            "Epoch 1060: Training loss 0.9633, Validation loss 17.2646, learning rate: 0.00096\n",
            "prediction loss: 0.2096, entropy regularization 0.9114\n",
            "Epoch 1065: Training loss 0.9408, Validation loss 17.0309, learning rate: 0.00096\n",
            "prediction loss: 0.1768, entropy regularization 0.9101\n",
            "Epoch 1070: Training loss 0.9112, Validation loss 17.2468, learning rate: 0.00095\n",
            "prediction loss: 0.1801, entropy regularization 0.9244\n",
            "Epoch 1075: Training loss 0.8633, Validation loss 18.1735, learning rate: 0.00094\n",
            "prediction loss: 0.2057, entropy regularization 0.9118\n",
            "Epoch 1080: Training loss 0.9530, Validation loss 18.2427, learning rate: 0.00094\n",
            "prediction loss: 0.1745, entropy regularization 0.9167\n",
            "Epoch 1085: Training loss 0.7244, Validation loss 17.3894, learning rate: 0.00093\n",
            "prediction loss: 0.2048, entropy regularization 0.8646\n",
            "Epoch 1090: Training loss 0.6852, Validation loss 17.1667, learning rate: 0.00092\n",
            "prediction loss: 0.1821, entropy regularization 0.8669\n",
            "Epoch 1095: Training loss 0.6976, Validation loss 16.6570, learning rate: 0.00091\n",
            "prediction loss: 0.1993, entropy regularization 0.8394\n",
            "Epoch 1100: Training loss 1.0800, Validation loss 16.5876, learning rate: 0.00090\n",
            "prediction loss: 0.1936, entropy regularization 0.7970\n",
            "Epoch 1105: Training loss 0.7174, Validation loss 17.1209, learning rate: 0.00089\n",
            "prediction loss: 0.2154, entropy regularization 0.8038\n",
            "Epoch 1110: Training loss 0.6449, Validation loss 17.3000, learning rate: 0.00088\n",
            "prediction loss: 0.1812, entropy regularization 0.7794\n",
            "Epoch 1115: Training loss 0.5913, Validation loss 17.3046, learning rate: 0.00087\n",
            "prediction loss: 0.2153, entropy regularization 0.7972\n",
            "Epoch 1120: Training loss 0.5458, Validation loss 16.8449, learning rate: 0.00086\n",
            "prediction loss: 0.1642, entropy regularization 0.7940\n",
            "Epoch 1125: Training loss 0.5066, Validation loss 17.7537, learning rate: 0.00085\n",
            "prediction loss: 0.1826, entropy regularization 0.7687\n",
            "Epoch 1130: Training loss 0.5790, Validation loss 17.1836, learning rate: 0.00084\n",
            "prediction loss: 0.1937, entropy regularization 0.7434\n",
            "Epoch 1135: Training loss 0.4534, Validation loss 16.7974, learning rate: 0.00083\n",
            "prediction loss: 0.1588, entropy regularization 0.7282\n",
            "Epoch 1140: Training loss 0.3523, Validation loss 17.5074, learning rate: 0.00082\n",
            "prediction loss: 0.1858, entropy regularization 0.7420\n",
            "Epoch 1145: Training loss 0.4762, Validation loss 17.0301, learning rate: 0.00080\n",
            "prediction loss: 0.1661, entropy regularization 0.7421\n",
            "Epoch 1150: Training loss 0.4029, Validation loss 17.3710, learning rate: 0.00079\n",
            "prediction loss: 0.1876, entropy regularization 0.7416\n",
            "Epoch 1155: Training loss 0.4756, Validation loss 17.4471, learning rate: 0.00078\n",
            "prediction loss: 0.2121, entropy regularization 0.7459\n",
            "Epoch 1160: Training loss 0.3331, Validation loss 17.4576, learning rate: 0.00077\n",
            "prediction loss: 0.2030, entropy regularization 0.7417\n",
            "Epoch 1165: Training loss 0.3154, Validation loss 17.4274, learning rate: 0.00075\n",
            "prediction loss: 0.1930, entropy regularization 0.7284\n",
            "Epoch 1170: Training loss 0.3087, Validation loss 17.5041, learning rate: 0.00074\n",
            "prediction loss: 0.1846, entropy regularization 0.7411\n",
            "Epoch 1175: Training loss 0.2658, Validation loss 16.9954, learning rate: 0.00072\n",
            "prediction loss: 0.2254, entropy regularization 0.7187\n",
            "Epoch 1180: Training loss 0.2748, Validation loss 17.0974, learning rate: 0.00071\n",
            "prediction loss: 0.2162, entropy regularization 0.7118\n",
            "Epoch 1185: Training loss 0.2320, Validation loss 16.9391, learning rate: 0.00070\n",
            "prediction loss: 0.2125, entropy regularization 0.7199\n",
            "Epoch 1190: Training loss 0.2376, Validation loss 17.1795, learning rate: 0.00068\n",
            "prediction loss: 0.1831, entropy regularization 0.7152\n",
            "Epoch 1195: Training loss 0.3824, Validation loss 16.7836, learning rate: 0.00067\n",
            "prediction loss: 0.2073, entropy regularization 0.7253\n",
            "Epoch 1200: Training loss 0.2262, Validation loss 16.8939, learning rate: 0.00065\n",
            "prediction loss: 0.1812, entropy regularization 0.7189\n",
            "Epoch 1205: Training loss 0.2324, Validation loss 16.5072, learning rate: 0.00064\n",
            "prediction loss: 0.1780, entropy regularization 0.6992\n",
            "Epoch 1210: Training loss 0.2428, Validation loss 16.9660, learning rate: 0.00062\n",
            "prediction loss: 0.1989, entropy regularization 0.7126\n",
            "Epoch 1215: Training loss 0.1958, Validation loss 16.6548, learning rate: 0.00061\n",
            "prediction loss: 0.2066, entropy regularization 0.6928\n",
            "Epoch 1220: Training loss 0.2667, Validation loss 16.8014, learning rate: 0.00059\n",
            "prediction loss: 0.1889, entropy regularization 0.7180\n",
            "Epoch 1225: Training loss 0.2543, Validation loss 16.6486, learning rate: 0.00058\n",
            "prediction loss: 0.2057, entropy regularization 0.7059\n",
            "Epoch 1230: Training loss 0.2590, Validation loss 16.3287, learning rate: 0.00056\n",
            "prediction loss: 0.1804, entropy regularization 0.7147\n",
            "Epoch 1235: Training loss 0.1955, Validation loss 16.4573, learning rate: 0.00054\n",
            "prediction loss: 0.1749, entropy regularization 0.7118\n",
            "Epoch 1240: Training loss 0.1425, Validation loss 16.6267, learning rate: 0.00053\n",
            "prediction loss: 0.1614, entropy regularization 0.7098\n",
            "Epoch 1245: Training loss 0.1252, Validation loss 16.5752, learning rate: 0.00051\n",
            "prediction loss: 0.1396, entropy regularization 0.7257\n",
            "Epoch 1250: Training loss 0.1115, Validation loss 16.6453, learning rate: 0.00050\n",
            "prediction loss: 0.1719, entropy regularization 0.7179\n",
            "Epoch 1255: Training loss 0.1147, Validation loss 16.6089, learning rate: 0.00048\n",
            "prediction loss: 0.1592, entropy regularization 0.7153\n",
            "Epoch 1260: Training loss 0.1104, Validation loss 16.6976, learning rate: 0.00047\n",
            "prediction loss: 0.1681, entropy regularization 0.7244\n",
            "Epoch 1265: Training loss 0.1073, Validation loss 16.6272, learning rate: 0.00045\n",
            "prediction loss: 0.1700, entropy regularization 0.7185\n",
            "Epoch 1270: Training loss 0.0850, Validation loss 16.5540, learning rate: 0.00043\n",
            "prediction loss: 0.1579, entropy regularization 0.7160\n",
            "Epoch 1275: Training loss 0.0917, Validation loss 16.5870, learning rate: 0.00042\n",
            "prediction loss: 0.1737, entropy regularization 0.7138\n",
            "Epoch 1280: Training loss 0.0866, Validation loss 16.5173, learning rate: 0.00040\n",
            "prediction loss: 0.1601, entropy regularization 0.7275\n",
            "Epoch 1285: Training loss 0.0852, Validation loss 16.5788, learning rate: 0.00039\n",
            "prediction loss: 0.1648, entropy regularization 0.7189\n",
            "Epoch 1290: Training loss 0.1275, Validation loss 16.4698, learning rate: 0.00037\n",
            "prediction loss: 0.1864, entropy regularization 0.6968\n",
            "Epoch 1295: Training loss 0.0888, Validation loss 16.5523, learning rate: 0.00036\n",
            "prediction loss: 0.1377, entropy regularization 0.7256\n",
            "Epoch 1300: Training loss 0.0727, Validation loss 16.7460, learning rate: 0.00034\n",
            "prediction loss: 0.1721, entropy regularization 0.7187\n",
            "Epoch 1305: Training loss 0.1188, Validation loss 16.5128, learning rate: 0.00033\n",
            "prediction loss: 0.1460, entropy regularization 0.7406\n",
            "Epoch 1310: Training loss 0.0597, Validation loss 16.4916, learning rate: 0.00031\n",
            "prediction loss: 0.1609, entropy regularization 0.7397\n",
            "Epoch 1315: Training loss 0.0431, Validation loss 16.5459, learning rate: 0.00030\n",
            "prediction loss: 0.2273, entropy regularization 0.7121\n",
            "Epoch 1320: Training loss 0.0406, Validation loss 16.6152, learning rate: 0.00028\n",
            "prediction loss: 0.1898, entropy regularization 0.7289\n",
            "Epoch 1325: Training loss 0.0425, Validation loss 16.6238, learning rate: 0.00027\n",
            "prediction loss: 0.1822, entropy regularization 0.7238\n",
            "Epoch 1330: Training loss 0.0375, Validation loss 16.5635, learning rate: 0.00026\n",
            "prediction loss: 0.1815, entropy regularization 0.7265\n",
            "Epoch 1335: Training loss 0.0310, Validation loss 16.6562, learning rate: 0.00024\n",
            "prediction loss: 0.1665, entropy regularization 0.7361\n",
            "Epoch 1340: Training loss 0.0305, Validation loss 16.5972, learning rate: 0.00023\n",
            "prediction loss: 0.1833, entropy regularization 0.7251\n",
            "Epoch 1345: Training loss 0.0310, Validation loss 16.5783, learning rate: 0.00022\n",
            "prediction loss: 0.2257, entropy regularization 0.7133\n",
            "Epoch 1350: Training loss 0.0303, Validation loss 16.6058, learning rate: 0.00020\n",
            "prediction loss: 0.2127, entropy regularization 0.7126\n",
            "Epoch 1355: Training loss 0.0243, Validation loss 16.5772, learning rate: 0.00019\n",
            "prediction loss: 0.1886, entropy regularization 0.7160\n",
            "Epoch 1360: Training loss 0.0220, Validation loss 16.5832, learning rate: 0.00018\n",
            "prediction loss: 0.1841, entropy regularization 0.7384\n",
            "Epoch 1365: Training loss 0.0229, Validation loss 16.6356, learning rate: 0.00017\n",
            "prediction loss: 0.1935, entropy regularization 0.7200\n",
            "Epoch 1370: Training loss 0.0238, Validation loss 16.6434, learning rate: 0.00016\n",
            "prediction loss: 0.1605, entropy regularization 0.7350\n",
            "Epoch 1375: Training loss 0.0207, Validation loss 16.6303, learning rate: 0.00014\n",
            "prediction loss: 0.2078, entropy regularization 0.7143\n",
            "Epoch 1380: Training loss 0.0184, Validation loss 16.5720, learning rate: 0.00013\n",
            "prediction loss: 0.1835, entropy regularization 0.7346\n",
            "Epoch 1385: Training loss 0.0187, Validation loss 16.5525, learning rate: 0.00012\n",
            "prediction loss: 0.1963, entropy regularization 0.7295\n",
            "Epoch 1390: Training loss 0.0182, Validation loss 16.5943, learning rate: 0.00011\n",
            "prediction loss: 0.1888, entropy regularization 0.7297\n",
            "Epoch 1395: Training loss 0.0168, Validation loss 16.6007, learning rate: 0.00010\n",
            "prediction loss: 0.1797, entropy regularization 0.7443\n",
            "Epoch 1400: Training loss 0.0158, Validation loss 16.6119, learning rate: 0.00009\n",
            "prediction loss: 0.2030, entropy regularization 0.7203\n",
            "Epoch 1405: Training loss 0.0150, Validation loss 16.6266, learning rate: 0.00008\n",
            "prediction loss: 0.1748, entropy regularization 0.7472\n",
            "Epoch 1410: Training loss 0.0162, Validation loss 16.5810, learning rate: 0.00008\n",
            "prediction loss: 0.1630, entropy regularization 0.7322\n",
            "Epoch 1415: Training loss 0.0144, Validation loss 16.6041, learning rate: 0.00007\n",
            "prediction loss: 0.1836, entropy regularization 0.7160\n",
            "Epoch 1420: Training loss 0.0145, Validation loss 16.6205, learning rate: 0.00006\n",
            "prediction loss: 0.1761, entropy regularization 0.7128\n",
            "Epoch 1425: Training loss 0.0137, Validation loss 16.5989, learning rate: 0.00005\n",
            "prediction loss: 0.1625, entropy regularization 0.7355\n",
            "Epoch 1430: Training loss 0.0141, Validation loss 16.5930, learning rate: 0.00005\n",
            "prediction loss: 0.1879, entropy regularization 0.7318\n",
            "Epoch 1435: Training loss 0.0131, Validation loss 16.5782, learning rate: 0.00004\n",
            "prediction loss: 0.1716, entropy regularization 0.7425\n",
            "Epoch 1440: Training loss 0.0126, Validation loss 16.5976, learning rate: 0.00003\n",
            "prediction loss: 0.1992, entropy regularization 0.7128\n",
            "Epoch 1445: Training loss 0.0125, Validation loss 16.5752, learning rate: 0.00003\n",
            "prediction loss: 0.1920, entropy regularization 0.7329\n",
            "Epoch 1450: Training loss 0.0130, Validation loss 16.5878, learning rate: 0.00002\n",
            "prediction loss: 0.2173, entropy regularization 0.7198\n",
            "Epoch 1455: Training loss 0.0122, Validation loss 16.5842, learning rate: 0.00002\n",
            "prediction loss: 0.1897, entropy regularization 0.7198\n",
            "Epoch 1460: Training loss 0.0122, Validation loss 16.5841, learning rate: 0.00001\n",
            "prediction loss: 0.1878, entropy regularization 0.7399\n",
            "Epoch 1465: Training loss 0.0123, Validation loss 16.5859, learning rate: 0.00001\n",
            "prediction loss: 0.1787, entropy regularization 0.7368\n",
            "Epoch 1470: Training loss 0.0120, Validation loss 16.5830, learning rate: 0.00001\n",
            "prediction loss: 0.1781, entropy regularization 0.7363\n",
            "Epoch 1475: Training loss 0.0118, Validation loss 16.5838, learning rate: 0.00001\n",
            "prediction loss: 0.1528, entropy regularization 0.7265\n",
            "Epoch 1480: Training loss 0.0118, Validation loss 16.5827, learning rate: 0.00000\n",
            "prediction loss: 0.1587, entropy regularization 0.7519\n",
            "Epoch 1485: Training loss 0.0118, Validation loss 16.5844, learning rate: 0.00000\n",
            "prediction loss: 0.1960, entropy regularization 0.7280\n",
            "Epoch 1490: Training loss 0.0117, Validation loss 16.5834, learning rate: 0.00000\n",
            "prediction loss: 0.1884, entropy regularization 0.7283\n",
            "Epoch 1495: Training loss 0.0117, Validation loss 16.5833, learning rate: 0.00000\n",
            "prediction loss: 0.2009, entropy regularization 0.7361\n",
            "Epoch 1500: Training loss 1.4141, Validation loss 15.1415, learning rate: 0.00100\n",
            "prediction loss: 0.1921, entropy regularization 0.7241\n",
            "Epoch 1505: Training loss 1.8271, Validation loss 17.0616, learning rate: 0.00100\n",
            "prediction loss: 0.1433, entropy regularization 0.5051\n",
            "Epoch 1510: Training loss 1.5048, Validation loss 16.3919, learning rate: 0.00100\n",
            "prediction loss: 0.2159, entropy regularization 0.4735\n",
            "Epoch 1515: Training loss 1.0677, Validation loss 17.1114, learning rate: 0.00100\n",
            "prediction loss: 0.1650, entropy regularization 0.4561\n",
            "Epoch 1520: Training loss 0.9076, Validation loss 16.6639, learning rate: 0.00100\n",
            "prediction loss: 0.2156, entropy regularization 0.4280\n",
            "Epoch 1525: Training loss 0.7667, Validation loss 16.5242, learning rate: 0.00099\n",
            "prediction loss: 0.2073, entropy regularization 0.4484\n",
            "Epoch 1530: Training loss 0.5420, Validation loss 16.1764, learning rate: 0.00099\n",
            "prediction loss: 0.2270, entropy regularization 0.4104\n",
            "Epoch 1535: Training loss 0.6892, Validation loss 16.1267, learning rate: 0.00099\n",
            "prediction loss: 0.2052, entropy regularization 0.4274\n",
            "Epoch 1540: Training loss 0.5527, Validation loss 16.5587, learning rate: 0.00098\n",
            "prediction loss: 0.1630, entropy regularization 0.4525\n",
            "Epoch 1545: Training loss 0.6271, Validation loss 15.9845, learning rate: 0.00098\n",
            "prediction loss: 0.1333, entropy regularization 0.3479\n",
            "Epoch 1550: Training loss 0.5255, Validation loss 16.7141, learning rate: 0.00097\n",
            "prediction loss: 0.0992, entropy regularization 0.2756\n",
            "Epoch 1555: Training loss 0.6975, Validation loss 15.7139, learning rate: 0.00097\n",
            "prediction loss: 0.0414, entropy regularization 0.2344\n",
            "Epoch 1560: Training loss 0.3588, Validation loss 15.9418, learning rate: 0.00096\n",
            "prediction loss: 0.0357, entropy regularization 0.2397\n",
            "Epoch 1565: Training loss 0.3753, Validation loss 15.7143, learning rate: 0.00096\n",
            "prediction loss: 0.0365, entropy regularization 0.2369\n",
            "Epoch 1570: Training loss 0.3217, Validation loss 15.9452, learning rate: 0.00095\n",
            "prediction loss: 0.0365, entropy regularization 0.2419\n",
            "Epoch 1575: Training loss 0.2261, Validation loss 15.9777, learning rate: 0.00094\n",
            "prediction loss: 0.0377, entropy regularization 0.2306\n",
            "Epoch 1580: Training loss 0.1916, Validation loss 15.9373, learning rate: 0.00094\n",
            "prediction loss: 0.0385, entropy regularization 0.2297\n",
            "Epoch 1585: Training loss 0.1983, Validation loss 16.0455, learning rate: 0.00093\n",
            "prediction loss: 0.0376, entropy regularization 0.2392\n",
            "Epoch 1590: Training loss 0.1970, Validation loss 16.1578, learning rate: 0.00092\n",
            "prediction loss: 0.0364, entropy regularization 0.2443\n",
            "Epoch 1595: Training loss 0.2290, Validation loss 15.9083, learning rate: 0.00091\n",
            "prediction loss: 0.0335, entropy regularization 0.2354\n",
            "Epoch 1600: Training loss 0.1384, Validation loss 15.9639, learning rate: 0.00090\n",
            "prediction loss: 0.0328, entropy regularization 0.2300\n",
            "Epoch 1605: Training loss 0.1046, Validation loss 15.8726, learning rate: 0.00089\n",
            "prediction loss: 0.0364, entropy regularization 0.2339\n",
            "Epoch 1610: Training loss 0.0848, Validation loss 15.7849, learning rate: 0.00088\n",
            "prediction loss: 0.0407, entropy regularization 0.2307\n",
            "Epoch 1615: Training loss 0.0569, Validation loss 15.9143, learning rate: 0.00087\n",
            "prediction loss: 0.0383, entropy regularization 0.2325\n",
            "Epoch 1620: Training loss 0.0740, Validation loss 15.7930, learning rate: 0.00086\n",
            "prediction loss: 0.0350, entropy regularization 0.2320\n",
            "Epoch 1625: Training loss 0.0883, Validation loss 15.9204, learning rate: 0.00085\n",
            "prediction loss: 0.0373, entropy regularization 0.2219\n",
            "Epoch 1630: Training loss 0.0662, Validation loss 16.0961, learning rate: 0.00084\n",
            "prediction loss: 0.0347, entropy regularization 0.2277\n",
            "Epoch 1635: Training loss 0.0712, Validation loss 15.8026, learning rate: 0.00083\n",
            "prediction loss: 0.0396, entropy regularization 0.2258\n",
            "Epoch 1640: Training loss 0.0465, Validation loss 15.8606, learning rate: 0.00082\n",
            "prediction loss: 0.0392, entropy regularization 0.2331\n",
            "Epoch 1645: Training loss 0.0454, Validation loss 15.7143, learning rate: 0.00080\n",
            "prediction loss: 0.0384, entropy regularization 0.2332\n",
            "Epoch 1650: Training loss 0.0478, Validation loss 15.9830, learning rate: 0.00079\n",
            "prediction loss: 0.0381, entropy regularization 0.2287\n",
            "Epoch 1655: Training loss 0.0310, Validation loss 15.8109, learning rate: 0.00078\n",
            "prediction loss: 0.0354, entropy regularization 0.2413\n",
            "Epoch 1660: Training loss 0.0398, Validation loss 15.9777, learning rate: 0.00077\n",
            "prediction loss: 0.0398, entropy regularization 0.2329\n",
            "Epoch 1665: Training loss 0.0292, Validation loss 15.9895, learning rate: 0.00075\n",
            "prediction loss: 0.0396, entropy regularization 0.2327\n",
            "Epoch 1670: Training loss 0.0345, Validation loss 15.8589, learning rate: 0.00074\n",
            "prediction loss: 0.0370, entropy regularization 0.2354\n",
            "Epoch 1675: Training loss 0.0537, Validation loss 16.0765, learning rate: 0.00072\n",
            "prediction loss: 0.0370, entropy regularization 0.2244\n",
            "Epoch 1680: Training loss 0.0394, Validation loss 16.0163, learning rate: 0.00071\n",
            "prediction loss: 0.0362, entropy regularization 0.2244\n",
            "Epoch 1685: Training loss 0.0641, Validation loss 15.7245, learning rate: 0.00070\n",
            "prediction loss: 0.0352, entropy regularization 0.2273\n",
            "Epoch 1690: Training loss 0.0571, Validation loss 15.7580, learning rate: 0.00068\n",
            "prediction loss: 0.0380, entropy regularization 0.2306\n",
            "Epoch 1695: Training loss 0.0512, Validation loss 15.9020, learning rate: 0.00067\n",
            "prediction loss: 0.0409, entropy regularization 0.2105\n",
            "Epoch 1700: Training loss 0.0154, Validation loss 15.8718, learning rate: 0.00065\n",
            "prediction loss: 0.0368, entropy regularization 0.2332\n",
            "Epoch 1705: Training loss 0.0107, Validation loss 15.8671, learning rate: 0.00064\n",
            "prediction loss: 0.0362, entropy regularization 0.2199\n",
            "Epoch 1710: Training loss 0.0222, Validation loss 15.8548, learning rate: 0.00062\n",
            "prediction loss: 0.0345, entropy regularization 0.2278\n",
            "Epoch 1715: Training loss 0.0119, Validation loss 15.8995, learning rate: 0.00061\n",
            "prediction loss: 0.0369, entropy regularization 0.2273\n",
            "Epoch 1720: Training loss 0.0169, Validation loss 15.8882, learning rate: 0.00059\n",
            "prediction loss: 0.0379, entropy regularization 0.2301\n",
            "Epoch 1725: Training loss 0.0165, Validation loss 15.8222, learning rate: 0.00058\n",
            "prediction loss: 0.0402, entropy regularization 0.2174\n",
            "Epoch 1730: Training loss 0.0092, Validation loss 15.7612, learning rate: 0.00056\n",
            "prediction loss: 0.0354, entropy regularization 0.2372\n",
            "Epoch 1735: Training loss 0.0140, Validation loss 15.8371, learning rate: 0.00054\n",
            "prediction loss: 0.0372, entropy regularization 0.2287\n",
            "Epoch 1740: Training loss 0.0093, Validation loss 15.8750, learning rate: 0.00053\n",
            "prediction loss: 0.0368, entropy regularization 0.2274\n",
            "Epoch 1745: Training loss 0.0114, Validation loss 15.8337, learning rate: 0.00051\n",
            "prediction loss: 0.0359, entropy regularization 0.2263\n",
            "Epoch 1750: Training loss 0.0061, Validation loss 15.8426, learning rate: 0.00050\n",
            "prediction loss: 0.0420, entropy regularization 0.2107\n",
            "Epoch 1755: Training loss 0.0117, Validation loss 15.8241, learning rate: 0.00048\n",
            "prediction loss: 0.0403, entropy regularization 0.2234\n",
            "Epoch 1760: Training loss 0.0089, Validation loss 15.8813, learning rate: 0.00047\n",
            "prediction loss: 0.0340, entropy regularization 0.2382\n",
            "Epoch 1765: Training loss 0.0150, Validation loss 15.7439, learning rate: 0.00045\n",
            "prediction loss: 0.0390, entropy regularization 0.2307\n",
            "Epoch 1770: Training loss 0.0089, Validation loss 15.8083, learning rate: 0.00043\n",
            "prediction loss: 0.0342, entropy regularization 0.2290\n",
            "Epoch 1775: Training loss 0.0158, Validation loss 15.7742, learning rate: 0.00042\n",
            "prediction loss: 0.0392, entropy regularization 0.2310\n",
            "Epoch 1780: Training loss 0.0086, Validation loss 15.8659, learning rate: 0.00040\n",
            "prediction loss: 0.0414, entropy regularization 0.2180\n",
            "Epoch 1785: Training loss 0.0035, Validation loss 15.7954, learning rate: 0.00039\n",
            "prediction loss: 0.0355, entropy regularization 0.2290\n",
            "Epoch 1790: Training loss 0.0032, Validation loss 15.8064, learning rate: 0.00037\n",
            "prediction loss: 0.0382, entropy regularization 0.2282\n",
            "Epoch 1795: Training loss 0.0029, Validation loss 15.7995, learning rate: 0.00036\n",
            "prediction loss: 0.0370, entropy regularization 0.2274\n",
            "Epoch 1800: Training loss 0.0065, Validation loss 15.8077, learning rate: 0.00034\n",
            "prediction loss: 0.0377, entropy regularization 0.2280\n",
            "Epoch 1805: Training loss 0.0048, Validation loss 15.8282, learning rate: 0.00033\n",
            "prediction loss: 0.0378, entropy regularization 0.2304\n",
            "Epoch 1810: Training loss 0.0071, Validation loss 15.7700, learning rate: 0.00031\n",
            "prediction loss: 0.0372, entropy regularization 0.2313\n",
            "Epoch 1815: Training loss 0.0034, Validation loss 15.7877, learning rate: 0.00030\n",
            "prediction loss: 0.0389, entropy regularization 0.2316\n",
            "Epoch 1820: Training loss 0.0037, Validation loss 15.7577, learning rate: 0.00028\n",
            "prediction loss: 0.0336, entropy regularization 0.2324\n",
            "Epoch 1825: Training loss 0.0017, Validation loss 15.7781, learning rate: 0.00027\n",
            "prediction loss: 0.0339, entropy regularization 0.2271\n",
            "Epoch 1830: Training loss 0.0018, Validation loss 15.8020, learning rate: 0.00026\n",
            "prediction loss: 0.0336, entropy regularization 0.2387\n",
            "Epoch 1835: Training loss 0.0009, Validation loss 15.7904, learning rate: 0.00024\n",
            "prediction loss: 0.0353, entropy regularization 0.2343\n",
            "Epoch 1840: Training loss 0.0011, Validation loss 15.7918, learning rate: 0.00023\n",
            "prediction loss: 0.0349, entropy regularization 0.2419\n",
            "Epoch 1845: Training loss 0.0018, Validation loss 15.8202, learning rate: 0.00022\n",
            "prediction loss: 0.0340, entropy regularization 0.2365\n",
            "Epoch 1850: Training loss 0.0017, Validation loss 15.7771, learning rate: 0.00020\n",
            "prediction loss: 0.0360, entropy regularization 0.2261\n",
            "Epoch 1855: Training loss 0.0007, Validation loss 15.7883, learning rate: 0.00019\n",
            "prediction loss: 0.0347, entropy regularization 0.2314\n",
            "Epoch 1860: Training loss 0.0008, Validation loss 15.7942, learning rate: 0.00018\n",
            "prediction loss: 0.0353, entropy regularization 0.2348\n",
            "Epoch 1865: Training loss 0.0006, Validation loss 15.7860, learning rate: 0.00017\n",
            "prediction loss: 0.0380, entropy regularization 0.2255\n",
            "Epoch 1870: Training loss 0.0006, Validation loss 15.7950, learning rate: 0.00016\n",
            "prediction loss: 0.0363, entropy regularization 0.2282\n",
            "Epoch 1875: Training loss 0.0007, Validation loss 15.7951, learning rate: 0.00014\n",
            "prediction loss: 0.0351, entropy regularization 0.2291\n",
            "Epoch 1880: Training loss 0.0007, Validation loss 15.7888, learning rate: 0.00013\n",
            "prediction loss: 0.0356, entropy regularization 0.2335\n",
            "Epoch 1885: Training loss 0.0004, Validation loss 15.7973, learning rate: 0.00012\n",
            "prediction loss: 0.0390, entropy regularization 0.2326\n",
            "Epoch 1890: Training loss 0.0004, Validation loss 15.7893, learning rate: 0.00011\n",
            "prediction loss: 0.0362, entropy regularization 0.2299\n",
            "Epoch 1895: Training loss 0.0005, Validation loss 15.7977, learning rate: 0.00010\n",
            "prediction loss: 0.0404, entropy regularization 0.2284\n",
            "Epoch 1900: Training loss 0.0003, Validation loss 15.7974, learning rate: 0.00009\n",
            "prediction loss: 0.0371, entropy regularization 0.2351\n",
            "Epoch 1905: Training loss 0.0003, Validation loss 15.8002, learning rate: 0.00008\n",
            "prediction loss: 0.0355, entropy regularization 0.2386\n",
            "Epoch 1910: Training loss 0.0003, Validation loss 15.8002, learning rate: 0.00008\n",
            "prediction loss: 0.0363, entropy regularization 0.2279\n",
            "Epoch 1915: Training loss 0.0003, Validation loss 15.8000, learning rate: 0.00007\n",
            "prediction loss: 0.0361, entropy regularization 0.2259\n",
            "Epoch 1920: Training loss 0.0003, Validation loss 15.8012, learning rate: 0.00006\n",
            "prediction loss: 0.0387, entropy regularization 0.2413\n",
            "Epoch 1925: Training loss 0.0002, Validation loss 15.7967, learning rate: 0.00005\n",
            "prediction loss: 0.0348, entropy regularization 0.2305\n",
            "Epoch 1930: Training loss 0.0002, Validation loss 15.7990, learning rate: 0.00005\n",
            "prediction loss: 0.0394, entropy regularization 0.2268\n",
            "Epoch 1935: Training loss 0.0002, Validation loss 15.7961, learning rate: 0.00004\n",
            "prediction loss: 0.0378, entropy regularization 0.2274\n",
            "Epoch 1940: Training loss 0.0002, Validation loss 15.7988, learning rate: 0.00003\n",
            "prediction loss: 0.0362, entropy regularization 0.2387\n",
            "Epoch 1945: Training loss 0.0002, Validation loss 15.7972, learning rate: 0.00003\n",
            "prediction loss: 0.0387, entropy regularization 0.2285\n",
            "Epoch 1950: Training loss 0.0002, Validation loss 15.7987, learning rate: 0.00002\n",
            "prediction loss: 0.0363, entropy regularization 0.2390\n",
            "Epoch 1955: Training loss 0.0002, Validation loss 15.7966, learning rate: 0.00002\n",
            "prediction loss: 0.0350, entropy regularization 0.2374\n",
            "Epoch 1960: Training loss 0.0002, Validation loss 15.7991, learning rate: 0.00001\n",
            "prediction loss: 0.0382, entropy regularization 0.2287\n",
            "Epoch 1965: Training loss 0.0002, Validation loss 15.7977, learning rate: 0.00001\n",
            "prediction loss: 0.0370, entropy regularization 0.2345\n",
            "Epoch 1970: Training loss 0.0002, Validation loss 15.7979, learning rate: 0.00001\n",
            "prediction loss: 0.0376, entropy regularization 0.2326\n",
            "Epoch 1975: Training loss 0.0002, Validation loss 15.7978, learning rate: 0.00001\n",
            "prediction loss: 0.0310, entropy regularization 0.2428\n",
            "Epoch 1980: Training loss 0.0002, Validation loss 15.7979, learning rate: 0.00000\n",
            "prediction loss: 0.0375, entropy regularization 0.2377\n",
            "Epoch 1985: Training loss 0.0002, Validation loss 15.7978, learning rate: 0.00000\n",
            "prediction loss: 0.0388, entropy regularization 0.2342\n",
            "Epoch 1990: Training loss 0.0002, Validation loss 15.7980, learning rate: 0.00000\n",
            "prediction loss: 0.0392, entropy regularization 0.2282\n",
            "Epoch 1995: Training loss 0.0002, Validation loss 15.7980, learning rate: 0.00000\n",
            "prediction loss: 0.0389, entropy regularization 0.2314\n",
            "Epoch 2000: Training loss 2.7897, Validation loss 12.9307, learning rate: 0.00100\n",
            "prediction loss: 0.0356, entropy regularization 0.1253\n",
            "Epoch 2005: Training loss 5.3408, Validation loss 18.0299, learning rate: 0.00100\n",
            "prediction loss: 0.0365, entropy regularization 0.0520\n",
            "Epoch 2010: Training loss 3.7690, Validation loss 17.8295, learning rate: 0.00100\n",
            "prediction loss: 0.0331, entropy regularization 0.0442\n",
            "Epoch 2015: Training loss 3.2453, Validation loss 17.8240, learning rate: 0.00100\n",
            "prediction loss: 0.0358, entropy regularization 0.0419\n",
            "Epoch 2020: Training loss 2.9051, Validation loss 17.4351, learning rate: 0.00100\n",
            "prediction loss: 0.0362, entropy regularization 0.0453\n",
            "Epoch 2025: Training loss 1.7997, Validation loss 16.6618, learning rate: 0.00099\n",
            "prediction loss: 0.0362, entropy regularization 0.0378\n",
            "Epoch 2030: Training loss 1.7521, Validation loss 17.3378, learning rate: 0.00099\n",
            "prediction loss: 0.0373, entropy regularization 0.0431\n",
            "Epoch 2035: Training loss 1.7980, Validation loss 16.7359, learning rate: 0.00099\n",
            "prediction loss: 0.0340, entropy regularization 0.0319\n",
            "Epoch 2040: Training loss 1.7428, Validation loss 17.1184, learning rate: 0.00098\n",
            "prediction loss: 0.0364, entropy regularization 0.0483\n",
            "Epoch 2045: Training loss 1.5112, Validation loss 16.2418, learning rate: 0.00098\n",
            "prediction loss: 0.0385, entropy regularization 0.0423\n",
            "Epoch 2050: Training loss 1.1478, Validation loss 16.5614, learning rate: 0.00097\n",
            "prediction loss: 0.0324, entropy regularization 0.0346\n",
            "Epoch 2055: Training loss 1.0867, Validation loss 17.2999, learning rate: 0.00097\n",
            "prediction loss: 0.0349, entropy regularization 0.0471\n",
            "Epoch 2060: Training loss 1.1245, Validation loss 16.8908, learning rate: 0.00096\n",
            "prediction loss: 0.0393, entropy regularization 0.0355\n",
            "Epoch 2065: Training loss 0.9972, Validation loss 17.0110, learning rate: 0.00096\n",
            "prediction loss: 0.0346, entropy regularization 0.0466\n",
            "Epoch 2070: Training loss 0.9697, Validation loss 16.8372, learning rate: 0.00095\n",
            "prediction loss: 0.0370, entropy regularization 0.0461\n",
            "Epoch 2075: Training loss 0.8997, Validation loss 16.9881, learning rate: 0.00094\n",
            "prediction loss: 0.0399, entropy regularization 0.0368\n",
            "Epoch 2080: Training loss 0.9451, Validation loss 16.5782, learning rate: 0.00094\n",
            "prediction loss: 0.0370, entropy regularization 0.0482\n",
            "Epoch 2085: Training loss 0.7599, Validation loss 16.9264, learning rate: 0.00093\n",
            "prediction loss: 0.0409, entropy regularization 0.0354\n",
            "Epoch 2090: Training loss 1.0092, Validation loss 16.5254, learning rate: 0.00092\n",
            "prediction loss: 0.0380, entropy regularization 0.0435\n",
            "Epoch 2095: Training loss 0.7879, Validation loss 17.3097, learning rate: 0.00091\n",
            "prediction loss: 0.0359, entropy regularization 0.0483\n",
            "Epoch 2100: Training loss 0.6029, Validation loss 16.9782, learning rate: 0.00090\n",
            "prediction loss: 0.0343, entropy regularization 0.0485\n",
            "Epoch 2105: Training loss 0.5723, Validation loss 17.0972, learning rate: 0.00089\n",
            "prediction loss: 0.0394, entropy regularization 0.0456\n",
            "Epoch 2110: Training loss 0.6368, Validation loss 17.0280, learning rate: 0.00088\n",
            "prediction loss: 0.0375, entropy regularization 0.0369\n",
            "Epoch 2115: Training loss 0.4861, Validation loss 16.8607, learning rate: 0.00087\n",
            "prediction loss: 0.0363, entropy regularization 0.0377\n",
            "Epoch 2120: Training loss 0.4855, Validation loss 16.9681, learning rate: 0.00086\n",
            "prediction loss: 0.0344, entropy regularization 0.0406\n",
            "Epoch 2125: Training loss 0.6015, Validation loss 16.9891, learning rate: 0.00085\n",
            "prediction loss: 0.0356, entropy regularization 0.0452\n",
            "Epoch 2130: Training loss 0.4175, Validation loss 17.2658, learning rate: 0.00084\n",
            "prediction loss: 0.0376, entropy regularization 0.0406\n",
            "Epoch 2135: Training loss 0.3782, Validation loss 17.0590, learning rate: 0.00083\n",
            "prediction loss: 0.0369, entropy regularization 0.0410\n",
            "Epoch 2140: Training loss 0.3877, Validation loss 17.3875, learning rate: 0.00082\n",
            "prediction loss: 0.0419, entropy regularization 0.0447\n",
            "Epoch 2145: Training loss 0.4305, Validation loss 17.2520, learning rate: 0.00080\n",
            "prediction loss: 0.0385, entropy regularization 0.0383\n",
            "Epoch 2150: Training loss 0.3613, Validation loss 17.4170, learning rate: 0.00079\n",
            "prediction loss: 0.0359, entropy regularization 0.0375\n",
            "Epoch 2155: Training loss 0.3837, Validation loss 17.3312, learning rate: 0.00078\n",
            "prediction loss: 0.0389, entropy regularization 0.0356\n",
            "Epoch 2160: Training loss 0.3014, Validation loss 17.4528, learning rate: 0.00077\n",
            "prediction loss: 0.0382, entropy regularization 0.0395\n",
            "Epoch 2165: Training loss 0.2825, Validation loss 17.1924, learning rate: 0.00075\n",
            "prediction loss: 0.0411, entropy regularization 0.0304\n",
            "Epoch 2170: Training loss 0.2812, Validation loss 17.7715, learning rate: 0.00074\n",
            "prediction loss: 0.0369, entropy regularization 0.0359\n",
            "Epoch 2175: Training loss 0.2715, Validation loss 17.4968, learning rate: 0.00072\n",
            "prediction loss: 0.0411, entropy regularization 0.0326\n",
            "Epoch 2180: Training loss 0.2379, Validation loss 17.3471, learning rate: 0.00071\n",
            "prediction loss: 0.0358, entropy regularization 0.0332\n",
            "Epoch 2185: Training loss 0.2717, Validation loss 17.5201, learning rate: 0.00070\n",
            "prediction loss: 0.0383, entropy regularization 0.0327\n",
            "Epoch 2190: Training loss 0.2292, Validation loss 17.7794, learning rate: 0.00068\n",
            "prediction loss: 0.0380, entropy regularization 0.0413\n",
            "Epoch 2195: Training loss 0.3204, Validation loss 17.6161, learning rate: 0.00067\n",
            "prediction loss: 0.0383, entropy regularization 0.0300\n",
            "Epoch 2200: Training loss 0.2558, Validation loss 17.5422, learning rate: 0.00065\n",
            "prediction loss: 0.0366, entropy regularization 0.0318\n",
            "Epoch 2205: Training loss 0.2169, Validation loss 17.6910, learning rate: 0.00064\n",
            "prediction loss: 0.0337, entropy regularization 0.0378\n",
            "Epoch 2210: Training loss 0.2454, Validation loss 17.6630, learning rate: 0.00062\n",
            "prediction loss: 0.0356, entropy regularization 0.0460\n",
            "Epoch 2215: Training loss 0.2691, Validation loss 17.9880, learning rate: 0.00061\n",
            "prediction loss: 0.0383, entropy regularization 0.0350\n",
            "Epoch 2220: Training loss 0.1520, Validation loss 17.8152, learning rate: 0.00059\n",
            "prediction loss: 0.0400, entropy regularization 0.0347\n",
            "Epoch 2225: Training loss 0.2103, Validation loss 18.2633, learning rate: 0.00058\n",
            "prediction loss: 0.0372, entropy regularization 0.0340\n",
            "Epoch 2230: Training loss 0.1704, Validation loss 17.9091, learning rate: 0.00056\n",
            "prediction loss: 0.0358, entropy regularization 0.0331\n",
            "Epoch 2235: Training loss 0.1686, Validation loss 18.0261, learning rate: 0.00054\n",
            "prediction loss: 0.0369, entropy regularization 0.0360\n",
            "Epoch 2240: Training loss 0.1702, Validation loss 18.0828, learning rate: 0.00053\n",
            "prediction loss: 0.0338, entropy regularization 0.0376\n",
            "Epoch 2245: Training loss 0.1460, Validation loss 18.0777, learning rate: 0.00051\n",
            "prediction loss: 0.0404, entropy regularization 0.0395\n",
            "Epoch 2250: Training loss 0.1284, Validation loss 18.1239, learning rate: 0.00050\n",
            "prediction loss: 0.0373, entropy regularization 0.0239\n",
            "Epoch 2255: Training loss 0.1296, Validation loss 18.1073, learning rate: 0.00048\n",
            "prediction loss: 0.0379, entropy regularization 0.0302\n",
            "Epoch 2260: Training loss 0.1480, Validation loss 18.2993, learning rate: 0.00047\n",
            "prediction loss: 0.0387, entropy regularization 0.0307\n",
            "Epoch 2265: Training loss 0.1210, Validation loss 18.3382, learning rate: 0.00045\n",
            "prediction loss: 0.0371, entropy regularization 0.0330\n",
            "Epoch 2270: Training loss 0.1153, Validation loss 18.1480, learning rate: 0.00043\n",
            "prediction loss: 0.0378, entropy regularization 0.0309\n",
            "Epoch 2275: Training loss 0.1023, Validation loss 18.3859, learning rate: 0.00042\n",
            "prediction loss: 0.0370, entropy regularization 0.0354\n",
            "Epoch 2280: Training loss 0.0995, Validation loss 18.3726, learning rate: 0.00040\n",
            "prediction loss: 0.0375, entropy regularization 0.0386\n",
            "Epoch 2285: Training loss 0.1143, Validation loss 18.3032, learning rate: 0.00039\n",
            "prediction loss: 0.0343, entropy regularization 0.0396\n",
            "Epoch 2290: Training loss 0.1011, Validation loss 18.2250, learning rate: 0.00037\n",
            "prediction loss: 0.0372, entropy regularization 0.0282\n",
            "Epoch 2295: Training loss 0.0791, Validation loss 18.2872, learning rate: 0.00036\n",
            "prediction loss: 0.0369, entropy regularization 0.0331\n",
            "Epoch 2300: Training loss 0.1241, Validation loss 18.2364, learning rate: 0.00034\n",
            "prediction loss: 0.0354, entropy regularization 0.0290\n",
            "Epoch 2305: Training loss 0.0869, Validation loss 18.3308, learning rate: 0.00033\n",
            "prediction loss: 0.0400, entropy regularization 0.0314\n",
            "Epoch 2310: Training loss 0.0762, Validation loss 18.2112, learning rate: 0.00031\n",
            "prediction loss: 0.0394, entropy regularization 0.0289\n",
            "Epoch 2315: Training loss 0.0845, Validation loss 18.3288, learning rate: 0.00030\n",
            "prediction loss: 0.0387, entropy regularization 0.0399\n",
            "Epoch 2320: Training loss 0.0704, Validation loss 18.4509, learning rate: 0.00028\n",
            "prediction loss: 0.0401, entropy regularization 0.0319\n",
            "Epoch 2325: Training loss 0.0686, Validation loss 18.3410, learning rate: 0.00027\n",
            "prediction loss: 0.0365, entropy regularization 0.0380\n",
            "Epoch 2330: Training loss 0.0653, Validation loss 18.4081, learning rate: 0.00026\n",
            "prediction loss: 0.0359, entropy regularization 0.0288\n",
            "Epoch 2335: Training loss 0.0655, Validation loss 18.3856, learning rate: 0.00024\n",
            "prediction loss: 0.0369, entropy regularization 0.0329\n",
            "Epoch 2340: Training loss 0.0663, Validation loss 18.3600, learning rate: 0.00023\n",
            "prediction loss: 0.0365, entropy regularization 0.0395\n",
            "Epoch 2345: Training loss 0.0569, Validation loss 18.3191, learning rate: 0.00022\n",
            "prediction loss: 0.0363, entropy regularization 0.0362\n",
            "Epoch 2350: Training loss 0.0557, Validation loss 18.3505, learning rate: 0.00020\n",
            "prediction loss: 0.0370, entropy regularization 0.0383\n",
            "Epoch 2355: Training loss 0.0480, Validation loss 18.2862, learning rate: 0.00019\n",
            "prediction loss: 0.0367, entropy regularization 0.0285\n",
            "Epoch 2360: Training loss 0.0469, Validation loss 18.3065, learning rate: 0.00018\n",
            "prediction loss: 0.0361, entropy regularization 0.0449\n",
            "Epoch 2365: Training loss 0.0502, Validation loss 18.2686, learning rate: 0.00017\n",
            "prediction loss: 0.0348, entropy regularization 0.0371\n",
            "Epoch 2370: Training loss 0.0580, Validation loss 18.2814, learning rate: 0.00016\n",
            "prediction loss: 0.0358, entropy regularization 0.0297\n",
            "Epoch 2375: Training loss 0.0529, Validation loss 18.3341, learning rate: 0.00014\n",
            "prediction loss: 0.0387, entropy regularization 0.0356\n",
            "Epoch 2380: Training loss 0.0455, Validation loss 18.3395, learning rate: 0.00013\n",
            "prediction loss: 0.0339, entropy regularization 0.0338\n",
            "Epoch 2385: Training loss 0.0443, Validation loss 18.3486, learning rate: 0.00012\n",
            "prediction loss: 0.0378, entropy regularization 0.0356\n",
            "Epoch 2390: Training loss 0.0460, Validation loss 18.3132, learning rate: 0.00011\n",
            "prediction loss: 0.0377, entropy regularization 0.0367\n",
            "Epoch 2395: Training loss 0.0419, Validation loss 18.3011, learning rate: 0.00010\n",
            "prediction loss: 0.0341, entropy regularization 0.0360\n",
            "Epoch 2400: Training loss 0.0421, Validation loss 18.3545, learning rate: 0.00009\n",
            "prediction loss: 0.0366, entropy regularization 0.0325\n",
            "Epoch 2405: Training loss 0.0391, Validation loss 18.3473, learning rate: 0.00008\n",
            "prediction loss: 0.0402, entropy regularization 0.0364\n",
            "Epoch 2410: Training loss 0.0408, Validation loss 18.2910, learning rate: 0.00008\n",
            "prediction loss: 0.0378, entropy regularization 0.0399\n",
            "Epoch 2415: Training loss 0.0395, Validation loss 18.3707, learning rate: 0.00007\n",
            "prediction loss: 0.0354, entropy regularization 0.0336\n",
            "Epoch 2420: Training loss 0.0380, Validation loss 18.3269, learning rate: 0.00006\n",
            "prediction loss: 0.0399, entropy regularization 0.0379\n",
            "Epoch 2425: Training loss 0.0379, Validation loss 18.3390, learning rate: 0.00005\n",
            "prediction loss: 0.0366, entropy regularization 0.0348\n",
            "Epoch 2430: Training loss 0.0377, Validation loss 18.3324, learning rate: 0.00005\n",
            "prediction loss: 0.0362, entropy regularization 0.0256\n",
            "Epoch 2435: Training loss 0.0364, Validation loss 18.3553, learning rate: 0.00004\n",
            "prediction loss: 0.0365, entropy regularization 0.0374\n",
            "Epoch 2440: Training loss 0.0368, Validation loss 18.3671, learning rate: 0.00003\n",
            "prediction loss: 0.0346, entropy regularization 0.0468\n",
            "Epoch 2445: Training loss 0.0354, Validation loss 18.3450, learning rate: 0.00003\n",
            "prediction loss: 0.0381, entropy regularization 0.0373\n",
            "Epoch 2450: Training loss 0.0351, Validation loss 18.3555, learning rate: 0.00002\n",
            "prediction loss: 0.0307, entropy regularization 0.0452\n",
            "Epoch 2455: Training loss 0.0350, Validation loss 18.3501, learning rate: 0.00002\n",
            "prediction loss: 0.0377, entropy regularization 0.0318\n",
            "Epoch 2460: Training loss 0.0351, Validation loss 18.3498, learning rate: 0.00001\n",
            "prediction loss: 0.0375, entropy regularization 0.0362\n",
            "Epoch 2465: Training loss 0.0343, Validation loss 18.3475, learning rate: 0.00001\n",
            "prediction loss: 0.0374, entropy regularization 0.0352\n",
            "Epoch 2470: Training loss 0.0344, Validation loss 18.3465, learning rate: 0.00001\n",
            "prediction loss: 0.0326, entropy regularization 0.0367\n",
            "Epoch 2475: Training loss 0.0342, Validation loss 18.3527, learning rate: 0.00001\n",
            "prediction loss: 0.0399, entropy regularization 0.0339\n",
            "Epoch 2480: Training loss 0.0341, Validation loss 18.3506, learning rate: 0.00000\n",
            "prediction loss: 0.0364, entropy regularization 0.0417\n",
            "Epoch 2485: Training loss 0.0346, Validation loss 18.3510, learning rate: 0.00000\n",
            "prediction loss: 0.0401, entropy regularization 0.0324\n",
            "Epoch 2490: Training loss 0.0340, Validation loss 18.3501, learning rate: 0.00000\n",
            "prediction loss: 0.0366, entropy regularization 0.0362\n",
            "Epoch 2495: Training loss 0.0339, Validation loss 18.3498, learning rate: 0.00000\n",
            "prediction loss: 0.0369, entropy regularization 0.0375\n",
            "Epoch 2500: Training loss 2.1611, Validation loss 17.3636, learning rate: 0.00100\n",
            "prediction loss: 0.0365, entropy regularization 0.0276\n",
            "Epoch 2505: Training loss 1.3121, Validation loss 16.9095, learning rate: 0.00100\n",
            "prediction loss: 0.0356, entropy regularization 0.0333\n",
            "Epoch 2510: Training loss 1.3166, Validation loss 16.3638, learning rate: 0.00100\n",
            "prediction loss: 0.0353, entropy regularization 0.0338\n",
            "Epoch 2515: Training loss 0.8015, Validation loss 17.2510, learning rate: 0.00100\n",
            "prediction loss: 0.0356, entropy regularization 0.0395\n",
            "Epoch 2520: Training loss 0.9609, Validation loss 17.0726, learning rate: 0.00100\n",
            "prediction loss: 0.0415, entropy regularization 0.0376\n",
            "Epoch 2525: Training loss 0.5199, Validation loss 16.5080, learning rate: 0.00099\n",
            "prediction loss: 0.0398, entropy regularization 0.0372\n",
            "Epoch 2530: Training loss 0.3500, Validation loss 16.4881, learning rate: 0.00099\n",
            "prediction loss: 0.0396, entropy regularization 0.0333\n",
            "Epoch 2535: Training loss 0.4690, Validation loss 17.1647, learning rate: 0.00099\n",
            "prediction loss: 0.0355, entropy regularization 0.0408\n",
            "Epoch 2540: Training loss 0.3217, Validation loss 17.2206, learning rate: 0.00098\n",
            "prediction loss: 0.0350, entropy regularization 0.0314\n",
            "Epoch 2545: Training loss 0.4497, Validation loss 17.0413, learning rate: 0.00098\n",
            "prediction loss: 0.0381, entropy regularization 0.0328\n",
            "Epoch 2550: Training loss 0.2946, Validation loss 16.9741, learning rate: 0.00097\n",
            "prediction loss: 0.0373, entropy regularization 0.0301\n",
            "Epoch 2555: Training loss 0.1977, Validation loss 17.0351, learning rate: 0.00097\n",
            "prediction loss: 0.0403, entropy regularization 0.0382\n",
            "Epoch 2560: Training loss 0.1993, Validation loss 16.9464, learning rate: 0.00096\n",
            "prediction loss: 0.0395, entropy regularization 0.0351\n",
            "Epoch 2565: Training loss 0.2545, Validation loss 16.8352, learning rate: 0.00096\n",
            "prediction loss: 0.0343, entropy regularization 0.0339\n",
            "Epoch 2570: Training loss 0.2279, Validation loss 16.7447, learning rate: 0.00095\n",
            "prediction loss: 0.0387, entropy regularization 0.0349\n",
            "Epoch 2575: Training loss 0.2503, Validation loss 16.7966, learning rate: 0.00094\n",
            "prediction loss: 0.0336, entropy regularization 0.0423\n",
            "Epoch 2580: Training loss 0.1729, Validation loss 16.9998, learning rate: 0.00094\n",
            "prediction loss: 0.0329, entropy regularization 0.0332\n",
            "Epoch 2585: Training loss 0.2043, Validation loss 17.0574, learning rate: 0.00093\n",
            "prediction loss: 0.0367, entropy regularization 0.0342\n",
            "Epoch 2590: Training loss 0.1083, Validation loss 17.1150, learning rate: 0.00092\n",
            "prediction loss: 0.0382, entropy regularization 0.0331\n",
            "Epoch 2595: Training loss 0.1022, Validation loss 17.1605, learning rate: 0.00091\n",
            "prediction loss: 0.0362, entropy regularization 0.0303\n",
            "Epoch 2600: Training loss 0.1284, Validation loss 17.1563, learning rate: 0.00090\n",
            "prediction loss: 0.0362, entropy regularization 0.0329\n",
            "Epoch 2605: Training loss 0.1438, Validation loss 16.9153, learning rate: 0.00089\n",
            "prediction loss: 0.0368, entropy regularization 0.0359\n",
            "Epoch 2610: Training loss 0.0889, Validation loss 16.9195, learning rate: 0.00088\n",
            "prediction loss: 0.0368, entropy regularization 0.0384\n",
            "Epoch 2615: Training loss 0.1027, Validation loss 17.1830, learning rate: 0.00087\n",
            "prediction loss: 0.0394, entropy regularization 0.0296\n",
            "Epoch 2620: Training loss 0.1939, Validation loss 16.9927, learning rate: 0.00086\n",
            "prediction loss: 0.0373, entropy regularization 0.0364\n",
            "Epoch 2625: Training loss 0.1001, Validation loss 16.8788, learning rate: 0.00085\n",
            "prediction loss: 0.0381, entropy regularization 0.0439\n",
            "Epoch 2630: Training loss 0.0744, Validation loss 16.8297, learning rate: 0.00084\n",
            "prediction loss: 0.0413, entropy regularization 0.0305\n",
            "Epoch 2635: Training loss 0.1027, Validation loss 16.7526, learning rate: 0.00083\n",
            "prediction loss: 0.0382, entropy regularization 0.0297\n",
            "Epoch 2640: Training loss 0.0820, Validation loss 16.7890, learning rate: 0.00082\n",
            "prediction loss: 0.0368, entropy regularization 0.0363\n",
            "Epoch 2645: Training loss 0.0908, Validation loss 16.9697, learning rate: 0.00080\n",
            "prediction loss: 0.0376, entropy regularization 0.0350\n",
            "Epoch 2650: Training loss 0.1004, Validation loss 16.8391, learning rate: 0.00079\n",
            "prediction loss: 0.0386, entropy regularization 0.0372\n",
            "Epoch 2655: Training loss 0.1321, Validation loss 17.0221, learning rate: 0.00078\n",
            "prediction loss: 0.0363, entropy regularization 0.0345\n",
            "Epoch 2660: Training loss 0.0669, Validation loss 16.6828, learning rate: 0.00077\n",
            "prediction loss: 0.0365, entropy regularization 0.0293\n",
            "Epoch 2665: Training loss 0.0374, Validation loss 16.8550, learning rate: 0.00075\n",
            "prediction loss: 0.0374, entropy regularization 0.0341\n",
            "Epoch 2670: Training loss 0.0465, Validation loss 16.9480, learning rate: 0.00074\n",
            "prediction loss: 0.0349, entropy regularization 0.0303\n",
            "Epoch 2675: Training loss 0.0249, Validation loss 16.7055, learning rate: 0.00072\n",
            "prediction loss: 0.0346, entropy regularization 0.0326\n",
            "Epoch 2680: Training loss 0.0203, Validation loss 16.9851, learning rate: 0.00071\n",
            "prediction loss: 0.0338, entropy regularization 0.0345\n",
            "Epoch 2685: Training loss 0.0424, Validation loss 17.0682, learning rate: 0.00070\n",
            "prediction loss: 0.0345, entropy regularization 0.0391\n",
            "Epoch 2690: Training loss 0.0337, Validation loss 16.7315, learning rate: 0.00068\n",
            "prediction loss: 0.0330, entropy regularization 0.0332\n",
            "Epoch 2695: Training loss 0.0276, Validation loss 16.6978, learning rate: 0.00067\n",
            "prediction loss: 0.0355, entropy regularization 0.0380\n",
            "Epoch 2700: Training loss 0.0257, Validation loss 16.7784, learning rate: 0.00065\n",
            "prediction loss: 0.0381, entropy regularization 0.0338\n",
            "Epoch 2705: Training loss 0.0298, Validation loss 16.9069, learning rate: 0.00064\n",
            "prediction loss: 0.0360, entropy regularization 0.0352\n",
            "Epoch 2710: Training loss 0.0298, Validation loss 16.7171, learning rate: 0.00062\n",
            "prediction loss: 0.0370, entropy regularization 0.0342\n",
            "Epoch 2715: Training loss 0.0273, Validation loss 16.6126, learning rate: 0.00061\n",
            "prediction loss: 0.0402, entropy regularization 0.0292\n",
            "Epoch 2720: Training loss 0.0174, Validation loss 16.6471, learning rate: 0.00059\n",
            "prediction loss: 0.0370, entropy regularization 0.0417\n",
            "Epoch 2725: Training loss 0.0134, Validation loss 16.6592, learning rate: 0.00058\n",
            "prediction loss: 0.0399, entropy regularization 0.0414\n",
            "Epoch 2730: Training loss 0.0148, Validation loss 16.6044, learning rate: 0.00056\n",
            "prediction loss: 0.0361, entropy regularization 0.0297\n",
            "Epoch 2735: Training loss 0.0117, Validation loss 16.5900, learning rate: 0.00054\n",
            "prediction loss: 0.0349, entropy regularization 0.0457\n",
            "Epoch 2740: Training loss 0.0126, Validation loss 16.5794, learning rate: 0.00053\n",
            "prediction loss: 0.0372, entropy regularization 0.0373\n",
            "Epoch 2745: Training loss 0.0143, Validation loss 16.6553, learning rate: 0.00051\n",
            "prediction loss: 0.0373, entropy regularization 0.0373\n",
            "Epoch 2750: Training loss 0.0181, Validation loss 16.5957, learning rate: 0.00050\n",
            "prediction loss: 0.0337, entropy regularization 0.0373\n",
            "Epoch 2755: Training loss 0.0141, Validation loss 16.6550, learning rate: 0.00048\n",
            "prediction loss: 0.0371, entropy regularization 0.0301\n",
            "Epoch 2760: Training loss 0.0088, Validation loss 16.5669, learning rate: 0.00047\n",
            "prediction loss: 0.0382, entropy regularization 0.0363\n",
            "Epoch 2765: Training loss 0.0154, Validation loss 16.5888, learning rate: 0.00045\n",
            "prediction loss: 0.0358, entropy regularization 0.0328\n",
            "Epoch 2770: Training loss 0.0169, Validation loss 16.5699, learning rate: 0.00043\n",
            "prediction loss: 0.0347, entropy regularization 0.0343\n",
            "Epoch 2775: Training loss 0.0140, Validation loss 16.5703, learning rate: 0.00042\n",
            "prediction loss: 0.0379, entropy regularization 0.0384\n",
            "Epoch 2780: Training loss 0.0290, Validation loss 16.5445, learning rate: 0.00040\n",
            "prediction loss: 0.0357, entropy regularization 0.0316\n",
            "Epoch 2785: Training loss 0.0137, Validation loss 16.6011, learning rate: 0.00039\n",
            "prediction loss: 0.0380, entropy regularization 0.0302\n",
            "Epoch 2790: Training loss 0.0098, Validation loss 16.5738, learning rate: 0.00037\n",
            "prediction loss: 0.0352, entropy regularization 0.0293\n",
            "Epoch 2795: Training loss 0.0192, Validation loss 16.5309, learning rate: 0.00036\n",
            "prediction loss: 0.0368, entropy regularization 0.0383\n",
            "Epoch 2800: Training loss 0.0095, Validation loss 16.6153, learning rate: 0.00034\n",
            "prediction loss: 0.0362, entropy regularization 0.0364\n",
            "Epoch 2805: Training loss 0.0090, Validation loss 16.5609, learning rate: 0.00033\n",
            "prediction loss: 0.0345, entropy regularization 0.0351\n",
            "Epoch 2810: Training loss 0.0059, Validation loss 16.5975, learning rate: 0.00031\n",
            "prediction loss: 0.0365, entropy regularization 0.0306\n",
            "Epoch 2815: Training loss 0.0044, Validation loss 16.5903, learning rate: 0.00030\n",
            "prediction loss: 0.0352, entropy regularization 0.0339\n",
            "Epoch 2820: Training loss 0.0055, Validation loss 16.5582, learning rate: 0.00028\n",
            "prediction loss: 0.0357, entropy regularization 0.0386\n",
            "Epoch 2825: Training loss 0.0040, Validation loss 16.5829, learning rate: 0.00027\n",
            "prediction loss: 0.0377, entropy regularization 0.0362\n",
            "Epoch 2830: Training loss 0.0069, Validation loss 16.5447, learning rate: 0.00026\n",
            "prediction loss: 0.0370, entropy regularization 0.0435\n",
            "Epoch 2835: Training loss 0.0045, Validation loss 16.5787, learning rate: 0.00024\n",
            "prediction loss: 0.0368, entropy regularization 0.0333\n",
            "Epoch 2840: Training loss 0.0050, Validation loss 16.5577, learning rate: 0.00023\n",
            "prediction loss: 0.0360, entropy regularization 0.0342\n",
            "Epoch 2845: Training loss 0.0055, Validation loss 16.5468, learning rate: 0.00022\n",
            "prediction loss: 0.0372, entropy regularization 0.0360\n",
            "Epoch 2850: Training loss 0.0041, Validation loss 16.5682, learning rate: 0.00020\n",
            "prediction loss: 0.0343, entropy regularization 0.0333\n",
            "Epoch 2855: Training loss 0.0054, Validation loss 16.5582, learning rate: 0.00019\n",
            "prediction loss: 0.0374, entropy regularization 0.0398\n",
            "Epoch 2860: Training loss 0.0045, Validation loss 16.5691, learning rate: 0.00018\n",
            "prediction loss: 0.0378, entropy regularization 0.0287\n",
            "Epoch 2865: Training loss 0.0042, Validation loss 16.5719, learning rate: 0.00017\n",
            "prediction loss: 0.0375, entropy regularization 0.0282\n",
            "Epoch 2870: Training loss 0.0033, Validation loss 16.5611, learning rate: 0.00016\n",
            "prediction loss: 0.0360, entropy regularization 0.0380\n",
            "Epoch 2875: Training loss 0.0035, Validation loss 16.5522, learning rate: 0.00014\n",
            "prediction loss: 0.0376, entropy regularization 0.0389\n",
            "Epoch 2880: Training loss 0.0028, Validation loss 16.5811, learning rate: 0.00013\n",
            "prediction loss: 0.0333, entropy regularization 0.0417\n",
            "Epoch 2885: Training loss 0.0031, Validation loss 16.5824, learning rate: 0.00012\n",
            "prediction loss: 0.0373, entropy regularization 0.0335\n",
            "Epoch 2890: Training loss 0.0028, Validation loss 16.5568, learning rate: 0.00011\n",
            "prediction loss: 0.0347, entropy regularization 0.0382\n",
            "Epoch 2895: Training loss 0.0027, Validation loss 16.5670, learning rate: 0.00010\n",
            "prediction loss: 0.0372, entropy regularization 0.0392\n",
            "Epoch 2900: Training loss 0.0032, Validation loss 16.5529, learning rate: 0.00009\n",
            "prediction loss: 0.0340, entropy regularization 0.0399\n",
            "Epoch 2905: Training loss 0.0023, Validation loss 16.5645, learning rate: 0.00008\n",
            "prediction loss: 0.0368, entropy regularization 0.0315\n",
            "Epoch 2910: Training loss 0.0022, Validation loss 16.5645, learning rate: 0.00008\n",
            "prediction loss: 0.0342, entropy regularization 0.0402\n",
            "Epoch 2915: Training loss 0.0024, Validation loss 16.5732, learning rate: 0.00007\n",
            "prediction loss: 0.0355, entropy regularization 0.0312\n",
            "Epoch 2920: Training loss 0.0021, Validation loss 16.5627, learning rate: 0.00006\n",
            "prediction loss: 0.0340, entropy regularization 0.0398\n",
            "Epoch 2925: Training loss 0.0022, Validation loss 16.5667, learning rate: 0.00005\n",
            "prediction loss: 0.0378, entropy regularization 0.0380\n",
            "Epoch 2930: Training loss 0.0023, Validation loss 16.5639, learning rate: 0.00005\n",
            "prediction loss: 0.0370, entropy regularization 0.0332\n",
            "Epoch 2935: Training loss 0.0020, Validation loss 16.5637, learning rate: 0.00004\n",
            "prediction loss: 0.0401, entropy regularization 0.0308\n",
            "Epoch 2940: Training loss 0.0020, Validation loss 16.5573, learning rate: 0.00003\n",
            "prediction loss: 0.0371, entropy regularization 0.0367\n",
            "Epoch 2945: Training loss 0.0020, Validation loss 16.5636, learning rate: 0.00003\n",
            "prediction loss: 0.0377, entropy regularization 0.0419\n",
            "Epoch 2950: Training loss 0.0021, Validation loss 16.5628, learning rate: 0.00002\n",
            "prediction loss: 0.0405, entropy regularization 0.0338\n",
            "Epoch 2955: Training loss 0.0020, Validation loss 16.5588, learning rate: 0.00002\n",
            "prediction loss: 0.0361, entropy regularization 0.0353\n",
            "Epoch 2960: Training loss 0.0019, Validation loss 16.5629, learning rate: 0.00001\n",
            "prediction loss: 0.0370, entropy regularization 0.0290\n",
            "Epoch 2965: Training loss 0.0019, Validation loss 16.5622, learning rate: 0.00001\n",
            "prediction loss: 0.0354, entropy regularization 0.0411\n",
            "Epoch 2970: Training loss 0.0019, Validation loss 16.5621, learning rate: 0.00001\n",
            "prediction loss: 0.0392, entropy regularization 0.0312\n",
            "Epoch 2975: Training loss 0.0019, Validation loss 16.5649, learning rate: 0.00001\n",
            "prediction loss: 0.0369, entropy regularization 0.0324\n",
            "Epoch 2980: Training loss 0.0019, Validation loss 16.5629, learning rate: 0.00000\n",
            "prediction loss: 0.0365, entropy regularization 0.0329\n",
            "Epoch 2985: Training loss 0.0018, Validation loss 16.5636, learning rate: 0.00000\n",
            "prediction loss: 0.0385, entropy regularization 0.0359\n",
            "Epoch 2990: Training loss 0.0018, Validation loss 16.5630, learning rate: 0.00000\n",
            "prediction loss: 0.0387, entropy regularization 0.0353\n",
            "Epoch 2995: Training loss 0.0018, Validation loss 16.5632, learning rate: 0.00000\n",
            "prediction loss: 0.0357, entropy regularization 0.0402\n",
            "Epoch 3000: Training loss 5.2932, Validation loss 16.4710, learning rate: 0.00100\n",
            "prediction loss: 0.0379, entropy regularization 0.0606\n",
            "Epoch 3005: Training loss 2.9741, Validation loss 16.8821, learning rate: 0.00100\n",
            "prediction loss: 0.2110, entropy regularization 0.0503\n",
            "Epoch 3010: Training loss 2.0775, Validation loss 17.6099, learning rate: 0.00100\n",
            "prediction loss: 0.2081, entropy regularization 0.0451\n",
            "Epoch 3015: Training loss 1.8774, Validation loss 15.9576, learning rate: 0.00100\n",
            "prediction loss: 0.2259, entropy regularization 0.0451\n",
            "Epoch 3020: Training loss 1.3256, Validation loss 16.8663, learning rate: 0.00100\n",
            "prediction loss: 0.2186, entropy regularization 0.0309\n",
            "Epoch 3025: Training loss 1.1409, Validation loss 17.4518, learning rate: 0.00099\n",
            "prediction loss: 0.2064, entropy regularization 0.0355\n",
            "Epoch 3030: Training loss 1.1544, Validation loss 17.5469, learning rate: 0.00099\n",
            "prediction loss: 0.2651, entropy regularization 0.0355\n",
            "Epoch 3035: Training loss 0.9997, Validation loss 17.2749, learning rate: 0.00099\n",
            "prediction loss: 0.2042, entropy regularization 0.0334\n",
            "Epoch 3040: Training loss 1.5892, Validation loss 18.0418, learning rate: 0.00098\n",
            "prediction loss: 0.1378, entropy regularization 0.0353\n",
            "Epoch 3045: Training loss 0.9704, Validation loss 18.6670, learning rate: 0.00098\n",
            "prediction loss: 0.0810, entropy regularization 0.0373\n",
            "Epoch 3050: Training loss 0.8700, Validation loss 18.0989, learning rate: 0.00097\n",
            "prediction loss: 0.1098, entropy regularization 0.0364\n",
            "Epoch 3055: Training loss 0.5853, Validation loss 18.1005, learning rate: 0.00097\n",
            "prediction loss: 0.0907, entropy regularization 0.0372\n",
            "Epoch 3060: Training loss 0.6703, Validation loss 18.5760, learning rate: 0.00096\n",
            "prediction loss: 0.0319, entropy regularization 0.0378\n",
            "Epoch 3065: Training loss 0.5447, Validation loss 18.6657, learning rate: 0.00096\n",
            "prediction loss: 0.0550, entropy regularization 0.0456\n",
            "Epoch 3070: Training loss 0.5811, Validation loss 18.1623, learning rate: 0.00095\n",
            "prediction loss: 0.1045, entropy regularization 0.0319\n",
            "Epoch 3075: Training loss 3.7335, Validation loss 14.0145, learning rate: 0.00094\n",
            "prediction loss: 0.1669, entropy regularization 0.0341\n",
            "Epoch 3080: Training loss 1.3146, Validation loss 14.4930, learning rate: 0.00094\n",
            "prediction loss: 0.1621, entropy regularization 0.0306\n",
            "Epoch 3085: Training loss 1.1047, Validation loss 14.5855, learning rate: 0.00093\n",
            "prediction loss: 0.1274, entropy regularization 0.0282\n",
            "Epoch 3090: Training loss 0.8765, Validation loss 14.5785, learning rate: 0.00092\n",
            "prediction loss: 0.1686, entropy regularization 0.0302\n",
            "Epoch 3095: Training loss 0.7423, Validation loss 14.6437, learning rate: 0.00091\n",
            "prediction loss: 0.1762, entropy regularization 0.0290\n",
            "Epoch 3100: Training loss 0.6529, Validation loss 14.4986, learning rate: 0.00090\n",
            "prediction loss: 0.2246, entropy regularization 0.0367\n",
            "Epoch 3105: Training loss 0.7155, Validation loss 14.9156, learning rate: 0.00089\n",
            "prediction loss: 0.2357, entropy regularization 0.0317\n",
            "Epoch 3110: Training loss 0.5258, Validation loss 14.9314, learning rate: 0.00088\n",
            "prediction loss: 0.2342, entropy regularization 0.0304\n",
            "Epoch 3115: Training loss 0.4601, Validation loss 14.7752, learning rate: 0.00087\n",
            "prediction loss: 0.2264, entropy regularization 0.0296\n",
            "Epoch 3120: Training loss 0.4953, Validation loss 14.8507, learning rate: 0.00086\n",
            "prediction loss: 0.2289, entropy regularization 0.0306\n",
            "Epoch 3125: Training loss 0.3932, Validation loss 15.1275, learning rate: 0.00085\n",
            "prediction loss: 0.2099, entropy regularization 0.0321\n",
            "Epoch 3130: Training loss 0.2897, Validation loss 15.0300, learning rate: 0.00084\n",
            "prediction loss: 0.2225, entropy regularization 0.0265\n",
            "Epoch 3135: Training loss 0.3155, Validation loss 15.1892, learning rate: 0.00083\n",
            "prediction loss: 0.2148, entropy regularization 0.0392\n",
            "Epoch 3140: Training loss 0.2849, Validation loss 15.0131, learning rate: 0.00082\n",
            "prediction loss: 0.2159, entropy regularization 0.0282\n",
            "Epoch 3145: Training loss 0.2789, Validation loss 14.9874, learning rate: 0.00080\n",
            "prediction loss: 0.2001, entropy regularization 0.0323\n",
            "Epoch 3150: Training loss 0.2190, Validation loss 15.3770, learning rate: 0.00079\n",
            "prediction loss: 0.2270, entropy regularization 0.0261\n",
            "Epoch 3155: Training loss 0.2449, Validation loss 17.6950, learning rate: 0.00078\n",
            "prediction loss: 0.2229, entropy regularization 0.0375\n",
            "Epoch 3160: Training loss 0.2275, Validation loss 15.6794, learning rate: 0.00077\n",
            "prediction loss: 0.2116, entropy regularization 0.0290\n",
            "Epoch 3165: Training loss 0.1927, Validation loss 18.9565, learning rate: 0.00075\n",
            "prediction loss: 0.1960, entropy regularization 0.0409\n",
            "Epoch 3170: Training loss 0.1739, Validation loss 21.5711, learning rate: 0.00074\n",
            "prediction loss: 0.2098, entropy regularization 0.0308\n",
            "Epoch 3175: Training loss 0.1953, Validation loss 18.7284, learning rate: 0.00072\n",
            "prediction loss: 0.1950, entropy regularization 0.0363\n",
            "Epoch 3180: Training loss 0.2854, Validation loss 18.3910, learning rate: 0.00071\n",
            "prediction loss: 0.1895, entropy regularization 0.0385\n",
            "Epoch 3185: Training loss 0.3282, Validation loss 24.7186, learning rate: 0.00070\n",
            "prediction loss: 0.1637, entropy regularization 0.0230\n",
            "Epoch 3190: Training loss 0.1822, Validation loss 25.8658, learning rate: 0.00068\n",
            "prediction loss: 0.2001, entropy regularization 0.0288\n",
            "Epoch 3195: Training loss 0.1319, Validation loss 125.9873, learning rate: 0.00067\n",
            "prediction loss: 0.1669, entropy regularization 0.0328\n",
            "Epoch 3200: Training loss 0.1592, Validation loss 34.2923, learning rate: 0.00065\n",
            "prediction loss: 0.1572, entropy regularization 0.0354\n",
            "Epoch 3205: Training loss 0.1168, Validation loss 45.2329, learning rate: 0.00064\n",
            "prediction loss: 0.1536, entropy regularization 0.0343\n",
            "Epoch 3210: Training loss 0.1225, Validation loss 43.9066, learning rate: 0.00062\n",
            "prediction loss: 0.1725, entropy regularization 0.0315\n",
            "Epoch 3215: Training loss 0.1679, Validation loss 125.3757, learning rate: 0.00061\n",
            "prediction loss: 0.1669, entropy regularization 0.0310\n",
            "Epoch 3220: Training loss 0.1196, Validation loss 101.5271, learning rate: 0.00059\n",
            "prediction loss: 0.1820, entropy regularization 0.0334\n",
            "Epoch 3225: Training loss 0.1121, Validation loss 48.7462, learning rate: 0.00058\n",
            "prediction loss: 0.1988, entropy regularization 0.0356\n",
            "Epoch 3230: Training loss 0.0899, Validation loss 72.7195, learning rate: 0.00056\n",
            "prediction loss: 0.1297, entropy regularization 0.0290\n",
            "Epoch 3235: Training loss 0.1295, Validation loss 42.1485, learning rate: 0.00054\n",
            "prediction loss: 0.1880, entropy regularization 0.0308\n",
            "Epoch 3240: Training loss 0.1122, Validation loss 78.7682, learning rate: 0.00053\n",
            "prediction loss: 0.1982, entropy regularization 0.0297\n",
            "Epoch 3245: Training loss 0.0926, Validation loss 88.4362, learning rate: 0.00051\n",
            "prediction loss: 0.2072, entropy regularization 0.0312\n",
            "Epoch 3250: Training loss 0.0709, Validation loss 316.8729, learning rate: 0.00050\n",
            "prediction loss: 0.2004, entropy regularization 0.0311\n",
            "Epoch 3255: Training loss 0.0834, Validation loss 134.7312, learning rate: 0.00048\n",
            "prediction loss: 0.2169, entropy regularization 0.0303\n",
            "Epoch 3260: Training loss 0.0770, Validation loss 497.4607, learning rate: 0.00047\n",
            "prediction loss: 0.1859, entropy regularization 0.0370\n",
            "Epoch 3265: Training loss 0.0810, Validation loss 185.4336, learning rate: 0.00045\n",
            "prediction loss: 0.2234, entropy regularization 0.0246\n",
            "Epoch 3270: Training loss 0.0673, Validation loss 373.1774, learning rate: 0.00043\n",
            "prediction loss: 0.1876, entropy regularization 0.0309\n",
            "Epoch 3275: Training loss 0.0775, Validation loss 388.5274, learning rate: 0.00042\n",
            "prediction loss: 0.1652, entropy regularization 0.0314\n",
            "Epoch 3280: Training loss 0.0684, Validation loss 625.4901, learning rate: 0.00040\n",
            "prediction loss: 0.2012, entropy regularization 0.0299\n",
            "Epoch 3285: Training loss 0.0575, Validation loss 672.6921, learning rate: 0.00039\n",
            "prediction loss: 0.1897, entropy regularization 0.0280\n",
            "Epoch 3290: Training loss 0.0571, Validation loss 798.6034, learning rate: 0.00037\n",
            "prediction loss: 0.1933, entropy regularization 0.0294\n",
            "Epoch 3295: Training loss 0.0410, Validation loss 641.2624, learning rate: 0.00036\n",
            "prediction loss: 0.1875, entropy regularization 0.0250\n",
            "Epoch 3300: Training loss 0.0403, Validation loss 707.0261, learning rate: 0.00034\n",
            "prediction loss: 0.2180, entropy regularization 0.0290\n",
            "Epoch 3305: Training loss 0.0438, Validation loss 832.8049, learning rate: 0.00033\n",
            "prediction loss: 0.2087, entropy regularization 0.0342\n",
            "Epoch 3310: Training loss 0.0409, Validation loss 760.1996, learning rate: 0.00031\n",
            "prediction loss: 0.1935, entropy regularization 0.0304\n",
            "Epoch 3315: Training loss 0.0350, Validation loss 813.7546, learning rate: 0.00030\n",
            "prediction loss: 0.1778, entropy regularization 0.0303\n",
            "Epoch 3320: Training loss 0.0326, Validation loss 793.7052, learning rate: 0.00028\n",
            "prediction loss: 0.2083, entropy regularization 0.0283\n",
            "Epoch 3325: Training loss 0.0469, Validation loss 799.1063, learning rate: 0.00027\n",
            "prediction loss: 0.2059, entropy regularization 0.0287\n",
            "Epoch 3330: Training loss 0.0322, Validation loss 1042.6393, learning rate: 0.00026\n",
            "prediction loss: 0.1709, entropy regularization 0.0339\n",
            "Epoch 3335: Training loss 0.0311, Validation loss 839.2759, learning rate: 0.00024\n",
            "prediction loss: 0.1965, entropy regularization 0.0340\n",
            "Epoch 3340: Training loss 0.0314, Validation loss 1050.3662, learning rate: 0.00023\n",
            "prediction loss: 0.2257, entropy regularization 0.0305\n",
            "Epoch 3345: Training loss 0.0313, Validation loss 1288.7290, learning rate: 0.00022\n",
            "prediction loss: 0.1975, entropy regularization 0.0265\n",
            "Epoch 3350: Training loss 0.0276, Validation loss 1366.2353, learning rate: 0.00020\n",
            "prediction loss: 0.1809, entropy regularization 0.0297\n",
            "Epoch 3355: Training loss 0.0265, Validation loss 1234.2111, learning rate: 0.00019\n",
            "prediction loss: 0.1763, entropy regularization 0.0299\n",
            "Epoch 3360: Training loss 0.0274, Validation loss 1007.7793, learning rate: 0.00018\n",
            "prediction loss: 0.1864, entropy regularization 0.0382\n",
            "Epoch 3365: Training loss 0.0255, Validation loss 1262.1604, learning rate: 0.00017\n",
            "prediction loss: 0.1969, entropy regularization 0.0282\n",
            "Epoch 3370: Training loss 0.0259, Validation loss 1083.1643, learning rate: 0.00016\n",
            "prediction loss: 0.1805, entropy regularization 0.0359\n",
            "Epoch 3375: Training loss 0.0256, Validation loss 1142.7832, learning rate: 0.00014\n",
            "prediction loss: 0.1852, entropy regularization 0.0303\n",
            "Epoch 3380: Training loss 0.0235, Validation loss 1362.6952, learning rate: 0.00013\n",
            "prediction loss: 0.2042, entropy regularization 0.0338\n",
            "Epoch 3385: Training loss 0.0229, Validation loss 1354.5092, learning rate: 0.00012\n",
            "prediction loss: 0.1764, entropy regularization 0.0326\n",
            "Epoch 3390: Training loss 0.0220, Validation loss 1415.9063, learning rate: 0.00011\n",
            "prediction loss: 0.1576, entropy regularization 0.0309\n",
            "Epoch 3395: Training loss 0.0210, Validation loss 1404.8176, learning rate: 0.00010\n",
            "prediction loss: 0.1807, entropy regularization 0.0252\n",
            "Epoch 3400: Training loss 0.0204, Validation loss 1599.8195, learning rate: 0.00009\n",
            "prediction loss: 0.1965, entropy regularization 0.0277\n",
            "Epoch 3405: Training loss 0.0200, Validation loss 1563.8219, learning rate: 0.00008\n",
            "prediction loss: 0.1533, entropy regularization 0.0361\n",
            "Epoch 3410: Training loss 0.0209, Validation loss 1634.2802, learning rate: 0.00008\n",
            "prediction loss: 0.2052, entropy regularization 0.0327\n",
            "Epoch 3415: Training loss 0.0190, Validation loss 1587.2685, learning rate: 0.00007\n",
            "prediction loss: 0.1934, entropy regularization 0.0285\n",
            "Epoch 3420: Training loss 0.0202, Validation loss 1723.2484, learning rate: 0.00006\n",
            "prediction loss: 0.2128, entropy regularization 0.0304\n",
            "Epoch 3425: Training loss 0.0188, Validation loss 1730.6933, learning rate: 0.00005\n",
            "prediction loss: 0.1979, entropy regularization 0.0274\n",
            "Epoch 3430: Training loss 0.0182, Validation loss 1727.5013, learning rate: 0.00005\n",
            "prediction loss: 0.2051, entropy regularization 0.0255\n",
            "Epoch 3435: Training loss 0.0186, Validation loss 1809.4472, learning rate: 0.00004\n",
            "prediction loss: 0.2102, entropy regularization 0.0297\n",
            "Epoch 3440: Training loss 0.0179, Validation loss 1763.8670, learning rate: 0.00003\n",
            "prediction loss: 0.2134, entropy regularization 0.0289\n",
            "Epoch 3445: Training loss 0.0176, Validation loss 1806.8370, learning rate: 0.00003\n",
            "prediction loss: 0.1839, entropy regularization 0.0302\n",
            "Epoch 3450: Training loss 0.0179, Validation loss 1828.2244, learning rate: 0.00002\n",
            "prediction loss: 0.1943, entropy regularization 0.0308\n",
            "Epoch 3455: Training loss 0.0173, Validation loss 1829.1240, learning rate: 0.00002\n",
            "prediction loss: 0.1734, entropy regularization 0.0332\n",
            "Epoch 3460: Training loss 0.0175, Validation loss 1838.7846, learning rate: 0.00001\n",
            "prediction loss: 0.1645, entropy regularization 0.0316\n",
            "Epoch 3465: Training loss 0.0174, Validation loss 1862.1726, learning rate: 0.00001\n",
            "prediction loss: 0.1816, entropy regularization 0.0313\n",
            "Epoch 3470: Training loss 0.0171, Validation loss 1869.1109, learning rate: 0.00001\n",
            "prediction loss: 0.1948, entropy regularization 0.0294\n",
            "Epoch 3475: Training loss 0.0169, Validation loss 1879.1675, learning rate: 0.00001\n",
            "prediction loss: 0.1941, entropy regularization 0.0300\n",
            "Epoch 3480: Training loss 0.0171, Validation loss 1884.7155, learning rate: 0.00000\n",
            "prediction loss: 0.2028, entropy regularization 0.0281\n",
            "Epoch 3485: Training loss 0.0169, Validation loss 1888.3867, learning rate: 0.00000\n",
            "prediction loss: 0.1937, entropy regularization 0.0295\n",
            "Epoch 3490: Training loss 0.0168, Validation loss 1887.2989, learning rate: 0.00000\n",
            "prediction loss: 0.2144, entropy regularization 0.0243\n",
            "Epoch 3495: Training loss 0.0167, Validation loss 1888.3707, learning rate: 0.00000\n",
            "prediction loss: 0.1773, entropy regularization 0.0272\n",
            "Epoch 3500: Training loss 2.0217, Validation loss 889.7355, learning rate: 0.00100\n",
            "prediction loss: 0.2323, entropy regularization 0.0217\n",
            "Epoch 3505: Training loss 1.2709, Validation loss 14.5509, learning rate: 0.00100\n",
            "prediction loss: 0.1964, entropy regularization 0.0272\n",
            "Epoch 3510: Training loss 0.9014, Validation loss 15.9863, learning rate: 0.00100\n",
            "prediction loss: 0.2035, entropy regularization 0.0340\n",
            "Epoch 3515: Training loss 0.9820, Validation loss 15.8805, learning rate: 0.00100\n",
            "prediction loss: 0.1163, entropy regularization 0.0309\n",
            "Epoch 3520: Training loss 0.7526, Validation loss 15.5142, learning rate: 0.00100\n",
            "prediction loss: 0.1782, entropy regularization 0.0319\n",
            "Epoch 3525: Training loss 0.7188, Validation loss 16.3591, learning rate: 0.00099\n",
            "prediction loss: 0.1960, entropy regularization 0.0383\n",
            "Epoch 3530: Training loss 0.7247, Validation loss 16.3586, learning rate: 0.00099\n",
            "prediction loss: 0.1757, entropy regularization 0.0316\n",
            "Epoch 3535: Training loss 0.5135, Validation loss 16.1989, learning rate: 0.00099\n",
            "prediction loss: 0.2302, entropy regularization 0.0341\n",
            "Epoch 3540: Training loss 0.4639, Validation loss 16.3761, learning rate: 0.00098\n",
            "prediction loss: 0.1754, entropy regularization 0.0292\n",
            "Epoch 3545: Training loss 0.3328, Validation loss 16.4420, learning rate: 0.00098\n",
            "prediction loss: 0.1953, entropy regularization 0.0317\n",
            "Epoch 3550: Training loss 0.3269, Validation loss 16.9134, learning rate: 0.00097\n",
            "prediction loss: 0.1980, entropy regularization 0.0303\n",
            "Epoch 3555: Training loss 0.2365, Validation loss 17.0405, learning rate: 0.00097\n",
            "prediction loss: 0.1679, entropy regularization 0.0251\n",
            "Epoch 3560: Training loss 0.2713, Validation loss 16.8579, learning rate: 0.00096\n",
            "prediction loss: 0.1915, entropy regularization 0.0343\n",
            "Epoch 3565: Training loss 0.3410, Validation loss 17.1169, learning rate: 0.00096\n",
            "prediction loss: 0.1969, entropy regularization 0.0325\n",
            "Epoch 3570: Training loss 0.1480, Validation loss 17.2646, learning rate: 0.00095\n",
            "prediction loss: 0.2343, entropy regularization 0.0328\n",
            "Epoch 3575: Training loss 0.1375, Validation loss 17.2927, learning rate: 0.00094\n",
            "prediction loss: 0.2369, entropy regularization 0.0320\n",
            "Epoch 3580: Training loss 0.1676, Validation loss 17.3017, learning rate: 0.00094\n",
            "prediction loss: 0.2151, entropy regularization 0.0468\n",
            "Epoch 3585: Training loss 0.1227, Validation loss 17.6280, learning rate: 0.00093\n",
            "prediction loss: 0.2045, entropy regularization 0.0315\n",
            "Epoch 3590: Training loss 0.1241, Validation loss 17.3205, learning rate: 0.00092\n",
            "prediction loss: 0.2089, entropy regularization 0.0297\n",
            "Epoch 3595: Training loss 0.1811, Validation loss 17.9069, learning rate: 0.00091\n",
            "prediction loss: 0.2190, entropy regularization 0.0326\n",
            "Epoch 3600: Training loss 0.6404, Validation loss 18.5629, learning rate: 0.00090\n",
            "prediction loss: 0.2343, entropy regularization 0.0299\n",
            "Epoch 3605: Training loss 0.3403, Validation loss 17.7648, learning rate: 0.00089\n",
            "prediction loss: 0.2457, entropy regularization 0.0236\n",
            "Epoch 3610: Training loss 0.1932, Validation loss 17.6756, learning rate: 0.00088\n",
            "prediction loss: 0.2103, entropy regularization 0.0370\n",
            "Epoch 3615: Training loss 0.1045, Validation loss 17.6682, learning rate: 0.00087\n",
            "prediction loss: 0.2271, entropy regularization 0.0275\n",
            "Epoch 3620: Training loss 0.1069, Validation loss 17.9895, learning rate: 0.00086\n",
            "prediction loss: 0.2208, entropy regularization 0.0328\n",
            "Epoch 3625: Training loss 0.3591, Validation loss 17.8496, learning rate: 0.00085\n",
            "prediction loss: 0.2716, entropy regularization 0.0282\n",
            "Epoch 3630: Training loss 0.1114, Validation loss 18.1095, learning rate: 0.00084\n",
            "prediction loss: 0.2447, entropy regularization 0.0340\n",
            "Epoch 3635: Training loss 0.1320, Validation loss 18.2328, learning rate: 0.00083\n",
            "prediction loss: 0.2497, entropy regularization 0.0315\n",
            "Epoch 3640: Training loss 0.1035, Validation loss 18.1855, learning rate: 0.00082\n",
            "prediction loss: 0.2339, entropy regularization 0.0283\n",
            "Epoch 3645: Training loss 0.1070, Validation loss 18.1216, learning rate: 0.00080\n",
            "prediction loss: 0.2322, entropy regularization 0.0339\n",
            "Epoch 3650: Training loss 0.0732, Validation loss 18.1385, learning rate: 0.00079\n",
            "prediction loss: 0.2413, entropy regularization 0.0313\n",
            "Epoch 3655: Training loss 0.1584, Validation loss 18.1214, learning rate: 0.00078\n",
            "prediction loss: 0.2414, entropy regularization 0.0369\n",
            "Epoch 3660: Training loss 0.0404, Validation loss 18.1489, learning rate: 0.00077\n",
            "prediction loss: 0.2254, entropy regularization 0.0307\n",
            "Epoch 3665: Training loss 0.0318, Validation loss 18.4631, learning rate: 0.00075\n",
            "prediction loss: 0.2248, entropy regularization 0.0296\n",
            "Epoch 3670: Training loss 0.0273, Validation loss 18.3767, learning rate: 0.00074\n",
            "prediction loss: 0.2502, entropy regularization 0.0359\n",
            "Epoch 3675: Training loss 0.0441, Validation loss 18.4174, learning rate: 0.00072\n",
            "prediction loss: 0.2393, entropy regularization 0.0277\n",
            "Epoch 3680: Training loss 0.0316, Validation loss 18.4122, learning rate: 0.00071\n",
            "prediction loss: 0.2423, entropy regularization 0.0318\n",
            "Epoch 3685: Training loss 0.0376, Validation loss 18.4473, learning rate: 0.00070\n",
            "prediction loss: 0.2394, entropy regularization 0.0325\n",
            "Epoch 3690: Training loss 0.0281, Validation loss 18.4655, learning rate: 0.00068\n",
            "prediction loss: 0.2465, entropy regularization 0.0362\n",
            "Epoch 3695: Training loss 0.0197, Validation loss 18.5396, learning rate: 0.00067\n",
            "prediction loss: 0.2320, entropy regularization 0.0285\n",
            "Epoch 3700: Training loss 0.0160, Validation loss 18.5809, learning rate: 0.00065\n",
            "prediction loss: 0.2455, entropy regularization 0.0345\n",
            "Epoch 3705: Training loss 0.0197, Validation loss 18.5995, learning rate: 0.00064\n",
            "prediction loss: 0.2385, entropy regularization 0.0340\n",
            "Epoch 3710: Training loss 0.0175, Validation loss 18.5278, learning rate: 0.00062\n",
            "prediction loss: 0.2544, entropy regularization 0.0326\n",
            "Epoch 3715: Training loss 0.0160, Validation loss 18.6443, learning rate: 0.00061\n",
            "prediction loss: 0.2163, entropy regularization 0.0285\n",
            "Epoch 3720: Training loss 0.0151, Validation loss 18.5813, learning rate: 0.00059\n",
            "prediction loss: 0.2564, entropy regularization 0.0304\n",
            "Epoch 3725: Training loss 0.0095, Validation loss 18.6117, learning rate: 0.00058\n",
            "prediction loss: 0.2422, entropy regularization 0.0308\n",
            "Epoch 3730: Training loss 0.0104, Validation loss 18.5613, learning rate: 0.00056\n",
            "prediction loss: 0.2370, entropy regularization 0.0314\n",
            "Epoch 3735: Training loss 0.0082, Validation loss 18.5601, learning rate: 0.00054\n",
            "prediction loss: 0.2366, entropy regularization 0.0301\n",
            "Epoch 3740: Training loss 0.0094, Validation loss 18.6106, learning rate: 0.00053\n",
            "prediction loss: 0.2471, entropy regularization 0.0313\n",
            "Epoch 3745: Training loss 0.0169, Validation loss 18.7092, learning rate: 0.00051\n",
            "prediction loss: 0.2323, entropy regularization 0.0301\n",
            "Epoch 3750: Training loss 0.0273, Validation loss 18.6374, learning rate: 0.00050\n",
            "prediction loss: 0.2415, entropy regularization 0.0341\n",
            "Epoch 3755: Training loss 0.0102, Validation loss 18.5323, learning rate: 0.00048\n",
            "prediction loss: 0.2348, entropy regularization 0.0264\n",
            "Epoch 3760: Training loss 0.0069, Validation loss 18.5977, learning rate: 0.00047\n",
            "prediction loss: 0.2471, entropy regularization 0.0257\n",
            "Epoch 3765: Training loss 0.0082, Validation loss 18.6166, learning rate: 0.00045\n",
            "prediction loss: 0.2330, entropy regularization 0.0272\n",
            "Epoch 3770: Training loss 0.0080, Validation loss 18.6597, learning rate: 0.00043\n",
            "prediction loss: 0.2423, entropy regularization 0.0312\n",
            "Epoch 3775: Training loss 0.0072, Validation loss 18.6677, learning rate: 0.00042\n",
            "prediction loss: 0.2360, entropy regularization 0.0325\n",
            "Epoch 3780: Training loss 0.0073, Validation loss 18.6709, learning rate: 0.00040\n",
            "prediction loss: 0.2381, entropy regularization 0.0245\n",
            "Epoch 3785: Training loss 0.0060, Validation loss 18.6757, learning rate: 0.00039\n",
            "prediction loss: 0.2190, entropy regularization 0.0270\n",
            "Epoch 3790: Training loss 0.0063, Validation loss 18.7077, learning rate: 0.00037\n",
            "prediction loss: 0.2393, entropy regularization 0.0283\n",
            "Epoch 3795: Training loss 0.0056, Validation loss 18.7070, learning rate: 0.00036\n",
            "prediction loss: 0.2110, entropy regularization 0.0305\n",
            "Epoch 3800: Training loss 0.0075, Validation loss 18.6938, learning rate: 0.00034\n",
            "prediction loss: 0.2338, entropy regularization 0.0308\n",
            "Epoch 3805: Training loss 0.0052, Validation loss 18.6669, learning rate: 0.00033\n",
            "prediction loss: 0.2421, entropy regularization 0.0352\n",
            "Epoch 3810: Training loss 0.0046, Validation loss 18.6751, learning rate: 0.00031\n",
            "prediction loss: 0.2358, entropy regularization 0.0305\n",
            "Epoch 3815: Training loss 0.0044, Validation loss 18.6685, learning rate: 0.00030\n",
            "prediction loss: 0.2354, entropy regularization 0.0306\n",
            "Epoch 3820: Training loss 0.0044, Validation loss 18.7069, learning rate: 0.00028\n",
            "prediction loss: 0.2417, entropy regularization 0.0295\n",
            "Epoch 3825: Training loss 0.0044, Validation loss 18.6857, learning rate: 0.00027\n",
            "prediction loss: 0.2227, entropy regularization 0.0296\n",
            "Epoch 3830: Training loss 0.0057, Validation loss 18.6862, learning rate: 0.00026\n",
            "prediction loss: 0.2483, entropy regularization 0.0324\n",
            "Epoch 3835: Training loss 0.0049, Validation loss 18.7188, learning rate: 0.00024\n",
            "prediction loss: 0.2373, entropy regularization 0.0286\n",
            "Epoch 3840: Training loss 0.0038, Validation loss 18.6903, learning rate: 0.00023\n",
            "prediction loss: 0.2408, entropy regularization 0.0323\n",
            "Epoch 3845: Training loss 0.0047, Validation loss 18.6834, learning rate: 0.00022\n",
            "prediction loss: 0.2369, entropy regularization 0.0368\n",
            "Epoch 3850: Training loss 0.0036, Validation loss 18.6991, learning rate: 0.00020\n",
            "prediction loss: 0.2246, entropy regularization 0.0279\n",
            "Epoch 3855: Training loss 0.0037, Validation loss 18.7167, learning rate: 0.00019\n",
            "prediction loss: 0.2418, entropy regularization 0.0292\n",
            "Epoch 3860: Training loss 0.0038, Validation loss 18.7071, learning rate: 0.00018\n",
            "prediction loss: 0.2305, entropy regularization 0.0321\n",
            "Epoch 3865: Training loss 0.0035, Validation loss 18.7139, learning rate: 0.00017\n",
            "prediction loss: 0.2326, entropy regularization 0.0285\n",
            "Epoch 3870: Training loss 0.0034, Validation loss 18.6814, learning rate: 0.00016\n",
            "prediction loss: 0.2410, entropy regularization 0.0367\n",
            "Epoch 3875: Training loss 0.0034, Validation loss 18.6995, learning rate: 0.00014\n",
            "prediction loss: 0.2253, entropy regularization 0.0345\n",
            "Epoch 3880: Training loss 0.0034, Validation loss 18.7127, learning rate: 0.00013\n",
            "prediction loss: 0.2457, entropy regularization 0.0352\n",
            "Epoch 3885: Training loss 0.0033, Validation loss 18.7021, learning rate: 0.00012\n",
            "prediction loss: 0.2514, entropy regularization 0.0313\n",
            "Epoch 3890: Training loss 0.0032, Validation loss 18.7064, learning rate: 0.00011\n",
            "prediction loss: 0.2304, entropy regularization 0.0317\n",
            "Epoch 3895: Training loss 0.0031, Validation loss 18.7078, learning rate: 0.00010\n",
            "prediction loss: 0.2194, entropy regularization 0.0331\n",
            "Epoch 3900: Training loss 0.0031, Validation loss 18.7021, learning rate: 0.00009\n",
            "prediction loss: 0.2351, entropy regularization 0.0259\n",
            "Epoch 3905: Training loss 0.0031, Validation loss 18.7185, learning rate: 0.00008\n",
            "prediction loss: 0.2445, entropy regularization 0.0391\n",
            "Epoch 3910: Training loss 0.0031, Validation loss 18.7194, learning rate: 0.00008\n",
            "prediction loss: 0.2382, entropy regularization 0.0300\n",
            "Epoch 3915: Training loss 0.0032, Validation loss 18.7101, learning rate: 0.00007\n",
            "prediction loss: 0.2327, entropy regularization 0.0248\n",
            "Epoch 3920: Training loss 0.0030, Validation loss 18.7203, learning rate: 0.00006\n",
            "prediction loss: 0.2244, entropy regularization 0.0286\n",
            "Epoch 3925: Training loss 0.0030, Validation loss 18.7186, learning rate: 0.00005\n",
            "prediction loss: 0.2418, entropy regularization 0.0351\n",
            "Epoch 3930: Training loss 0.0030, Validation loss 18.7114, learning rate: 0.00005\n",
            "prediction loss: 0.2384, entropy regularization 0.0278\n",
            "Epoch 3935: Training loss 0.0030, Validation loss 18.7182, learning rate: 0.00004\n",
            "prediction loss: 0.2246, entropy regularization 0.0336\n",
            "Epoch 3940: Training loss 0.0032, Validation loss 18.7073, learning rate: 0.00003\n",
            "prediction loss: 0.2512, entropy regularization 0.0369\n",
            "Epoch 3945: Training loss 0.0029, Validation loss 18.7169, learning rate: 0.00003\n",
            "prediction loss: 0.2271, entropy regularization 0.0272\n",
            "Epoch 3950: Training loss 0.0029, Validation loss 18.7170, learning rate: 0.00002\n",
            "prediction loss: 0.2369, entropy regularization 0.0259\n",
            "Epoch 3955: Training loss 0.0029, Validation loss 18.7181, learning rate: 0.00002\n",
            "prediction loss: 0.2393, entropy regularization 0.0309\n",
            "Epoch 3960: Training loss 0.0029, Validation loss 18.7169, learning rate: 0.00001\n",
            "prediction loss: 0.2197, entropy regularization 0.0321\n",
            "Epoch 3965: Training loss 0.0028, Validation loss 18.7137, learning rate: 0.00001\n",
            "prediction loss: 0.2367, entropy regularization 0.0320\n",
            "Epoch 3970: Training loss 0.0029, Validation loss 18.7194, learning rate: 0.00001\n",
            "prediction loss: 0.2341, entropy regularization 0.0341\n",
            "Epoch 3975: Training loss 0.0028, Validation loss 18.7175, learning rate: 0.00001\n",
            "prediction loss: 0.2349, entropy regularization 0.0288\n",
            "Epoch 3980: Training loss 0.0028, Validation loss 18.7180, learning rate: 0.00000\n",
            "prediction loss: 0.2402, entropy regularization 0.0267\n",
            "Epoch 3985: Training loss 0.0028, Validation loss 18.7180, learning rate: 0.00000\n",
            "prediction loss: 0.2250, entropy regularization 0.0368\n",
            "Epoch 3990: Training loss 0.0029, Validation loss 18.7184, learning rate: 0.00000\n",
            "prediction loss: 0.2412, entropy regularization 0.0387\n",
            "Epoch 3995: Training loss 0.0029, Validation loss 18.7183, learning rate: 0.00000\n",
            "prediction loss: 0.2462, entropy regularization 0.0291\n",
            "Epoch 4000: Training loss 2.7077, Validation loss 14.7369, learning rate: 0.00100\n",
            "prediction loss: 0.2180, entropy regularization 0.0429\n",
            "Epoch 4005: Training loss 5.8524, Validation loss 19.2299, learning rate: 0.00100\n",
            "prediction loss: 0.2022, entropy regularization 0.0698\n",
            "Epoch 4010: Training loss 4.1821, Validation loss 17.0138, learning rate: 0.00100\n",
            "prediction loss: 0.2108, entropy regularization 0.0676\n",
            "Epoch 4015: Training loss 3.4873, Validation loss 16.4690, learning rate: 0.00100\n",
            "prediction loss: 0.2098, entropy regularization 0.0684\n",
            "Epoch 4020: Training loss 3.1172, Validation loss 15.8879, learning rate: 0.00100\n",
            "prediction loss: 0.2437, entropy regularization 0.0737\n",
            "Epoch 4025: Training loss 2.8045, Validation loss 15.9255, learning rate: 0.00099\n",
            "prediction loss: 0.2240, entropy regularization 0.0748\n",
            "Epoch 4030: Training loss 2.7945, Validation loss 15.8686, learning rate: 0.00099\n",
            "prediction loss: 0.2613, entropy regularization 0.0722\n",
            "Epoch 4035: Training loss 2.3130, Validation loss 15.6828, learning rate: 0.00099\n",
            "prediction loss: 0.2702, entropy regularization 0.0691\n",
            "Epoch 4040: Training loss 2.1373, Validation loss 16.0241, learning rate: 0.00098\n",
            "prediction loss: 0.2700, entropy regularization 0.0694\n",
            "Epoch 4045: Training loss 2.0130, Validation loss 15.6198, learning rate: 0.00098\n",
            "prediction loss: 0.2587, entropy regularization 0.0649\n",
            "Epoch 4050: Training loss 1.9373, Validation loss 15.9473, learning rate: 0.00097\n",
            "prediction loss: 0.2655, entropy regularization 0.0665\n",
            "Epoch 4055: Training loss 1.8131, Validation loss 16.1582, learning rate: 0.00097\n",
            "prediction loss: 0.2596, entropy regularization 0.0697\n",
            "Epoch 4060: Training loss 1.6670, Validation loss 15.7039, learning rate: 0.00096\n",
            "prediction loss: 0.2615, entropy regularization 0.0692\n",
            "Epoch 4065: Training loss 1.7292, Validation loss 15.4773, learning rate: 0.00096\n",
            "prediction loss: 0.2637, entropy regularization 0.0694\n",
            "Epoch 4070: Training loss 1.5548, Validation loss 15.6873, learning rate: 0.00095\n",
            "prediction loss: 0.2518, entropy regularization 0.0685\n",
            "Epoch 4075: Training loss 1.5066, Validation loss 15.2275, learning rate: 0.00094\n",
            "prediction loss: 0.2648, entropy regularization 0.0741\n",
            "Epoch 4080: Training loss 1.4727, Validation loss 15.6712, learning rate: 0.00094\n",
            "prediction loss: 0.2669, entropy regularization 0.0663\n",
            "Epoch 4085: Training loss 1.3965, Validation loss 15.5578, learning rate: 0.00093\n",
            "prediction loss: 0.2644, entropy regularization 0.0752\n",
            "Epoch 4090: Training loss 1.3585, Validation loss 15.1983, learning rate: 0.00092\n",
            "prediction loss: 0.2620, entropy regularization 0.0725\n",
            "Epoch 4095: Training loss 1.2589, Validation loss 15.3561, learning rate: 0.00091\n",
            "prediction loss: 0.2587, entropy regularization 0.0688\n",
            "Epoch 4100: Training loss 1.2983, Validation loss 15.4918, learning rate: 0.00090\n",
            "prediction loss: 0.2583, entropy regularization 0.0682\n",
            "Epoch 4105: Training loss 1.2710, Validation loss 15.5168, learning rate: 0.00089\n",
            "prediction loss: 0.2599, entropy regularization 0.0677\n",
            "Epoch 4110: Training loss 1.1953, Validation loss 15.5436, learning rate: 0.00088\n",
            "prediction loss: 0.2619, entropy regularization 0.0748\n",
            "Epoch 4115: Training loss 1.1225, Validation loss 15.2581, learning rate: 0.00087\n",
            "prediction loss: 0.2570, entropy regularization 0.0673\n",
            "Epoch 4120: Training loss 1.0476, Validation loss 15.5805, learning rate: 0.00086\n",
            "prediction loss: 0.2691, entropy regularization 0.0713\n",
            "Epoch 4125: Training loss 1.0596, Validation loss 15.4389, learning rate: 0.00085\n",
            "prediction loss: 0.2625, entropy regularization 0.0769\n",
            "Epoch 4130: Training loss 1.0169, Validation loss 15.4319, learning rate: 0.00084\n",
            "prediction loss: 0.2768, entropy regularization 0.0657\n",
            "Epoch 4135: Training loss 1.0971, Validation loss 15.5190, learning rate: 0.00083\n",
            "prediction loss: 0.2770, entropy regularization 0.0737\n",
            "Epoch 4140: Training loss 0.9752, Validation loss 15.4573, learning rate: 0.00082\n",
            "prediction loss: 0.2625, entropy regularization 0.0738\n",
            "Epoch 4145: Training loss 0.9336, Validation loss 15.4962, learning rate: 0.00080\n",
            "prediction loss: 0.2426, entropy regularization 0.0666\n",
            "Epoch 4150: Training loss 0.9425, Validation loss 15.4913, learning rate: 0.00079\n",
            "prediction loss: 0.2464, entropy regularization 0.0717\n",
            "Epoch 4155: Training loss 0.9527, Validation loss 15.3676, learning rate: 0.00078\n",
            "prediction loss: 0.2548, entropy regularization 0.0677\n",
            "Epoch 4160: Training loss 0.8439, Validation loss 15.5301, learning rate: 0.00077\n",
            "prediction loss: 0.2522, entropy regularization 0.0786\n",
            "Epoch 4165: Training loss 0.8486, Validation loss 15.4587, learning rate: 0.00075\n",
            "prediction loss: 0.2674, entropy regularization 0.0678\n",
            "Epoch 4170: Training loss 0.8107, Validation loss 15.5419, learning rate: 0.00074\n",
            "prediction loss: 0.2578, entropy regularization 0.0732\n",
            "Epoch 4175: Training loss 0.8117, Validation loss 15.6655, learning rate: 0.00072\n",
            "prediction loss: 0.2672, entropy regularization 0.0718\n",
            "Epoch 4180: Training loss 0.8134, Validation loss 15.7084, learning rate: 0.00071\n",
            "prediction loss: 0.2634, entropy regularization 0.0664\n",
            "Epoch 4185: Training loss 0.7550, Validation loss 15.7654, learning rate: 0.00070\n",
            "prediction loss: 0.2565, entropy regularization 0.0711\n",
            "Epoch 4190: Training loss 0.6884, Validation loss 15.6824, learning rate: 0.00068\n",
            "prediction loss: 0.2756, entropy regularization 0.0700\n",
            "Epoch 4195: Training loss 0.6856, Validation loss 15.8157, learning rate: 0.00067\n",
            "prediction loss: 0.2611, entropy regularization 0.0668\n",
            "Epoch 4200: Training loss 0.6876, Validation loss 15.7786, learning rate: 0.00065\n",
            "prediction loss: 0.2665, entropy regularization 0.0678\n",
            "Epoch 4205: Training loss 0.6963, Validation loss 15.7294, learning rate: 0.00064\n",
            "prediction loss: 0.2562, entropy regularization 0.0690\n",
            "Epoch 4210: Training loss 0.6750, Validation loss 15.7827, learning rate: 0.00062\n",
            "prediction loss: 0.2618, entropy regularization 0.0693\n",
            "Epoch 4215: Training loss 0.6095, Validation loss 15.7851, learning rate: 0.00061\n",
            "prediction loss: 0.2506, entropy regularization 0.0712\n",
            "Epoch 4220: Training loss 0.6562, Validation loss 15.8610, learning rate: 0.00059\n",
            "prediction loss: 0.2530, entropy regularization 0.0702\n",
            "Epoch 4225: Training loss 0.6388, Validation loss 15.7371, learning rate: 0.00058\n",
            "prediction loss: 0.2633, entropy regularization 0.0723\n",
            "Epoch 4230: Training loss 0.5933, Validation loss 15.6685, learning rate: 0.00056\n",
            "prediction loss: 0.2587, entropy regularization 0.0735\n",
            "Epoch 4235: Training loss 0.6042, Validation loss 15.8072, learning rate: 0.00054\n",
            "prediction loss: 0.2631, entropy regularization 0.0755\n",
            "Epoch 4240: Training loss 0.5621, Validation loss 15.8888, learning rate: 0.00053\n",
            "prediction loss: 0.2855, entropy regularization 0.0672\n",
            "Epoch 4245: Training loss 0.5042, Validation loss 15.8639, learning rate: 0.00051\n",
            "prediction loss: 0.2721, entropy regularization 0.0690\n",
            "Epoch 4250: Training loss 0.5111, Validation loss 15.8289, learning rate: 0.00050\n",
            "prediction loss: 0.2626, entropy regularization 0.0746\n",
            "Epoch 4255: Training loss 0.4934, Validation loss 15.9404, learning rate: 0.00048\n",
            "prediction loss: 0.2614, entropy regularization 0.0740\n",
            "Epoch 4260: Training loss 0.4693, Validation loss 15.8347, learning rate: 0.00047\n",
            "prediction loss: 0.2673, entropy regularization 0.0698\n",
            "Epoch 4265: Training loss 0.4782, Validation loss 15.8479, learning rate: 0.00045\n",
            "prediction loss: 0.2764, entropy regularization 0.0729\n",
            "Epoch 4270: Training loss 0.4877, Validation loss 15.7650, learning rate: 0.00043\n",
            "prediction loss: 0.2626, entropy regularization 0.0730\n",
            "Epoch 4275: Training loss 0.4463, Validation loss 15.7766, learning rate: 0.00042\n",
            "prediction loss: 0.2515, entropy regularization 0.0776\n",
            "Epoch 4280: Training loss 0.4466, Validation loss 15.8549, learning rate: 0.00040\n",
            "prediction loss: 0.2538, entropy regularization 0.0695\n",
            "Epoch 4285: Training loss 0.4565, Validation loss 15.9096, learning rate: 0.00039\n",
            "prediction loss: 0.2604, entropy regularization 0.0768\n",
            "Epoch 4290: Training loss 0.4132, Validation loss 15.8194, learning rate: 0.00037\n",
            "prediction loss: 0.2621, entropy regularization 0.0722\n",
            "Epoch 4295: Training loss 0.4995, Validation loss 15.7590, learning rate: 0.00036\n",
            "prediction loss: 0.2663, entropy regularization 0.0688\n",
            "Epoch 4300: Training loss 0.4744, Validation loss 15.9772, learning rate: 0.00034\n",
            "prediction loss: 0.2664, entropy regularization 0.0674\n",
            "Epoch 4305: Training loss 0.4030, Validation loss 15.8517, learning rate: 0.00033\n",
            "prediction loss: 0.2607, entropy regularization 0.0665\n",
            "Epoch 4310: Training loss 0.4049, Validation loss 15.8793, learning rate: 0.00031\n",
            "prediction loss: 0.2780, entropy regularization 0.0677\n",
            "Epoch 4315: Training loss 0.3829, Validation loss 15.8703, learning rate: 0.00030\n",
            "prediction loss: 0.2639, entropy regularization 0.0736\n",
            "Epoch 4320: Training loss 0.3840, Validation loss 15.8307, learning rate: 0.00028\n",
            "prediction loss: 0.2563, entropy regularization 0.0693\n",
            "Epoch 4325: Training loss 0.3646, Validation loss 15.9011, learning rate: 0.00027\n",
            "prediction loss: 0.2544, entropy regularization 0.0721\n",
            "Epoch 4330: Training loss 0.4065, Validation loss 15.9022, learning rate: 0.00026\n",
            "prediction loss: 0.2533, entropy regularization 0.0680\n",
            "Epoch 4335: Training loss 0.3415, Validation loss 15.8906, learning rate: 0.00024\n",
            "prediction loss: 0.2593, entropy regularization 0.0684\n",
            "Epoch 4340: Training loss 0.3429, Validation loss 15.9021, learning rate: 0.00023\n",
            "prediction loss: 0.2674, entropy regularization 0.0785\n",
            "Epoch 4345: Training loss 0.3287, Validation loss 15.9092, learning rate: 0.00022\n",
            "prediction loss: 0.2685, entropy regularization 0.0751\n",
            "Epoch 4350: Training loss 0.3230, Validation loss 15.9067, learning rate: 0.00020\n",
            "prediction loss: 0.2484, entropy regularization 0.0729\n",
            "Epoch 4355: Training loss 0.3221, Validation loss 15.9518, learning rate: 0.00019\n",
            "prediction loss: 0.2736, entropy regularization 0.0763\n",
            "Epoch 4360: Training loss 0.3139, Validation loss 15.9138, learning rate: 0.00018\n",
            "prediction loss: 0.2657, entropy regularization 0.0762\n",
            "Epoch 4365: Training loss 0.3070, Validation loss 15.9316, learning rate: 0.00017\n",
            "prediction loss: 0.2701, entropy regularization 0.0743\n",
            "Epoch 4370: Training loss 0.3026, Validation loss 15.9411, learning rate: 0.00016\n",
            "prediction loss: 0.2534, entropy regularization 0.0716\n",
            "Epoch 4375: Training loss 0.3000, Validation loss 15.9220, learning rate: 0.00014\n",
            "prediction loss: 0.2642, entropy regularization 0.0739\n",
            "Epoch 4380: Training loss 0.3004, Validation loss 15.9396, learning rate: 0.00013\n",
            "prediction loss: 0.2663, entropy regularization 0.0748\n",
            "Epoch 4385: Training loss 0.2922, Validation loss 15.9546, learning rate: 0.00012\n",
            "prediction loss: 0.2644, entropy regularization 0.0749\n",
            "Epoch 4390: Training loss 0.2870, Validation loss 15.9399, learning rate: 0.00011\n",
            "prediction loss: 0.2539, entropy regularization 0.0717\n",
            "Epoch 4395: Training loss 0.2864, Validation loss 15.9505, learning rate: 0.00010\n",
            "prediction loss: 0.2612, entropy regularization 0.0741\n",
            "Epoch 4400: Training loss 0.2797, Validation loss 15.9452, learning rate: 0.00009\n",
            "prediction loss: 0.2587, entropy regularization 0.0713\n",
            "Epoch 4405: Training loss 0.2896, Validation loss 15.9476, learning rate: 0.00008\n",
            "prediction loss: 0.2643, entropy regularization 0.0719\n",
            "Epoch 4410: Training loss 0.2748, Validation loss 15.9560, learning rate: 0.00008\n",
            "prediction loss: 0.2497, entropy regularization 0.0713\n",
            "Epoch 4415: Training loss 0.2738, Validation loss 15.9703, learning rate: 0.00007\n",
            "prediction loss: 0.2653, entropy regularization 0.0726\n",
            "Epoch 4420: Training loss 0.2686, Validation loss 15.9784, learning rate: 0.00006\n",
            "prediction loss: 0.2546, entropy regularization 0.0708\n",
            "Epoch 4425: Training loss 0.2664, Validation loss 15.9936, learning rate: 0.00005\n",
            "prediction loss: 0.2573, entropy regularization 0.0730\n",
            "Epoch 4430: Training loss 0.2647, Validation loss 15.9923, learning rate: 0.00005\n",
            "prediction loss: 0.2557, entropy regularization 0.0732\n",
            "Epoch 4435: Training loss 0.2663, Validation loss 16.0102, learning rate: 0.00004\n",
            "prediction loss: 0.2551, entropy regularization 0.0793\n",
            "Epoch 4440: Training loss 0.2619, Validation loss 15.9973, learning rate: 0.00003\n",
            "prediction loss: 0.2510, entropy regularization 0.0766\n",
            "Epoch 4445: Training loss 0.2624, Validation loss 15.9985, learning rate: 0.00003\n",
            "prediction loss: 0.2743, entropy regularization 0.0708\n",
            "Epoch 4450: Training loss 0.2634, Validation loss 15.9854, learning rate: 0.00002\n",
            "prediction loss: 0.2471, entropy regularization 0.0757\n",
            "Epoch 4455: Training loss 0.2614, Validation loss 16.0039, learning rate: 0.00002\n",
            "prediction loss: 0.2574, entropy regularization 0.0681\n",
            "Epoch 4460: Training loss 0.2595, Validation loss 15.9967, learning rate: 0.00001\n",
            "prediction loss: 0.2728, entropy regularization 0.0720\n",
            "Epoch 4465: Training loss 0.2569, Validation loss 16.0049, learning rate: 0.00001\n",
            "prediction loss: 0.2581, entropy regularization 0.0717\n",
            "Epoch 4470: Training loss 0.2560, Validation loss 16.0053, learning rate: 0.00001\n",
            "prediction loss: 0.2701, entropy regularization 0.0692\n",
            "Epoch 4475: Training loss 0.2568, Validation loss 16.0056, learning rate: 0.00001\n",
            "prediction loss: 0.2598, entropy regularization 0.0767\n",
            "Epoch 4480: Training loss 0.2576, Validation loss 16.0059, learning rate: 0.00000\n",
            "prediction loss: 0.2754, entropy regularization 0.0752\n",
            "Epoch 4485: Training loss 0.2562, Validation loss 16.0065, learning rate: 0.00000\n",
            "prediction loss: 0.2800, entropy regularization 0.0697\n",
            "Epoch 4490: Training loss 0.2556, Validation loss 16.0057, learning rate: 0.00000\n",
            "prediction loss: 0.2599, entropy regularization 0.0683\n",
            "Epoch 4495: Training loss 0.2541, Validation loss 16.0057, learning rate: 0.00000\n",
            "prediction loss: 0.2723, entropy regularization 0.0706\n",
            "Epoch 4500: Training loss 0.9492, Validation loss 16.0181, learning rate: 0.00100\n",
            "prediction loss: 0.2672, entropy regularization 0.0697\n",
            "Epoch 4505: Training loss 1.1591, Validation loss 16.2298, learning rate: 0.00100\n",
            "prediction loss: 0.2599, entropy regularization 0.0724\n",
            "Epoch 4510: Training loss 0.9709, Validation loss 16.1119, learning rate: 0.00100\n",
            "prediction loss: 0.2653, entropy regularization 0.0697\n",
            "Epoch 4515: Training loss 0.6215, Validation loss 16.2306, learning rate: 0.00100\n",
            "prediction loss: 0.2390, entropy regularization 0.0693\n",
            "Epoch 4520: Training loss 0.5270, Validation loss 16.4649, learning rate: 0.00100\n",
            "prediction loss: 0.2555, entropy regularization 0.0707\n",
            "Epoch 4525: Training loss 0.5204, Validation loss 16.4321, learning rate: 0.00099\n",
            "prediction loss: 0.2766, entropy regularization 0.0748\n",
            "Epoch 4530: Training loss 0.6719, Validation loss 16.6031, learning rate: 0.00099\n",
            "prediction loss: 0.2523, entropy regularization 0.0746\n",
            "Epoch 4535: Training loss 0.4634, Validation loss 16.5744, learning rate: 0.00099\n",
            "prediction loss: 0.2716, entropy regularization 0.0782\n",
            "Epoch 4540: Training loss 0.4110, Validation loss 17.0190, learning rate: 0.00098\n",
            "prediction loss: 0.2620, entropy regularization 0.0703\n",
            "Epoch 4545: Training loss 0.4326, Validation loss 16.9524, learning rate: 0.00098\n",
            "prediction loss: 0.2710, entropy regularization 0.0797\n",
            "Epoch 4550: Training loss 0.3748, Validation loss 16.8788, learning rate: 0.00097\n",
            "prediction loss: 0.2482, entropy regularization 0.0704\n",
            "Epoch 4555: Training loss 0.5289, Validation loss 16.4684, learning rate: 0.00097\n",
            "prediction loss: 0.2565, entropy regularization 0.0761\n",
            "Epoch 4560: Training loss 0.3357, Validation loss 16.7645, learning rate: 0.00096\n",
            "prediction loss: 0.2708, entropy regularization 0.0725\n",
            "Epoch 4565: Training loss 0.4627, Validation loss 17.0882, learning rate: 0.00096\n",
            "prediction loss: 0.2671, entropy regularization 0.0704\n",
            "Epoch 4570: Training loss 0.4001, Validation loss 16.4224, learning rate: 0.00095\n",
            "prediction loss: 0.2639, entropy regularization 0.0768\n",
            "Epoch 4575: Training loss 0.3202, Validation loss 16.8598, learning rate: 0.00094\n",
            "prediction loss: 0.2562, entropy regularization 0.0708\n",
            "Epoch 4580: Training loss 0.2919, Validation loss 16.8699, learning rate: 0.00094\n",
            "prediction loss: 0.2612, entropy regularization 0.0721\n",
            "Epoch 4585: Training loss 0.2891, Validation loss 16.8831, learning rate: 0.00093\n",
            "prediction loss: 0.2618, entropy regularization 0.0751\n",
            "Epoch 4590: Training loss 0.2462, Validation loss 16.9416, learning rate: 0.00092\n",
            "prediction loss: 0.2576, entropy regularization 0.0731\n",
            "Epoch 4595: Training loss 0.3519, Validation loss 17.4194, learning rate: 0.00091\n",
            "prediction loss: 0.2604, entropy regularization 0.0751\n",
            "Epoch 4600: Training loss 0.2749, Validation loss 17.2716, learning rate: 0.00090\n",
            "prediction loss: 0.2693, entropy regularization 0.0763\n",
            "Epoch 4605: Training loss 0.2726, Validation loss 16.9635, learning rate: 0.00089\n",
            "prediction loss: 0.2607, entropy regularization 0.0741\n",
            "Epoch 4610: Training loss 0.2076, Validation loss 16.9474, learning rate: 0.00088\n",
            "prediction loss: 0.2692, entropy regularization 0.0680\n",
            "Epoch 4615: Training loss 0.2409, Validation loss 17.1590, learning rate: 0.00087\n",
            "prediction loss: 0.2602, entropy regularization 0.0813\n",
            "Epoch 4620: Training loss 0.1733, Validation loss 17.1212, learning rate: 0.00086\n",
            "prediction loss: 0.2547, entropy regularization 0.0751\n",
            "Epoch 4625: Training loss 0.1310, Validation loss 16.9494, learning rate: 0.00085\n",
            "prediction loss: 0.2681, entropy regularization 0.0770\n",
            "Epoch 4630: Training loss 0.1596, Validation loss 16.8856, learning rate: 0.00084\n",
            "prediction loss: 0.2689, entropy regularization 0.0772\n",
            "Epoch 4635: Training loss 0.1296, Validation loss 16.8838, learning rate: 0.00083\n",
            "prediction loss: 0.2715, entropy regularization 0.0727\n",
            "Epoch 4640: Training loss 0.1917, Validation loss 16.8232, learning rate: 0.00082\n",
            "prediction loss: 0.2636, entropy regularization 0.0708\n",
            "Epoch 4645: Training loss 0.1636, Validation loss 17.0716, learning rate: 0.00080\n",
            "prediction loss: 0.2588, entropy regularization 0.0683\n",
            "Epoch 4650: Training loss 0.3254, Validation loss 17.0619, learning rate: 0.00079\n",
            "prediction loss: 0.2668, entropy regularization 0.0797\n",
            "Epoch 4655: Training loss 0.1362, Validation loss 16.9904, learning rate: 0.00078\n",
            "prediction loss: 0.2616, entropy regularization 0.0762\n",
            "Epoch 4660: Training loss 0.1174, Validation loss 17.0305, learning rate: 0.00077\n",
            "prediction loss: 0.2596, entropy regularization 0.0784\n",
            "Epoch 4665: Training loss 0.1631, Validation loss 17.1326, learning rate: 0.00075\n",
            "prediction loss: 0.2506, entropy regularization 0.0786\n",
            "Epoch 4670: Training loss 0.1852, Validation loss 17.1824, learning rate: 0.00074\n",
            "prediction loss: 0.2542, entropy regularization 0.0753\n",
            "Epoch 4675: Training loss 0.3032, Validation loss 17.0623, learning rate: 0.00072\n",
            "prediction loss: 0.2495, entropy regularization 0.0756\n",
            "Epoch 4680: Training loss 0.1205, Validation loss 17.0959, learning rate: 0.00071\n",
            "prediction loss: 0.2521, entropy regularization 0.0733\n",
            "Epoch 4685: Training loss 0.1153, Validation loss 17.1452, learning rate: 0.00070\n",
            "prediction loss: 0.2585, entropy regularization 0.0702\n",
            "Epoch 4690: Training loss 0.0887, Validation loss 16.9344, learning rate: 0.00068\n",
            "prediction loss: 0.2706, entropy regularization 0.0708\n",
            "Epoch 4695: Training loss 0.0810, Validation loss 17.0473, learning rate: 0.00067\n",
            "prediction loss: 0.2609, entropy regularization 0.0765\n",
            "Epoch 4700: Training loss 0.1114, Validation loss 16.8919, learning rate: 0.00065\n",
            "prediction loss: 0.2616, entropy regularization 0.0771\n",
            "Epoch 4705: Training loss 0.1097, Validation loss 16.9827, learning rate: 0.00064\n",
            "prediction loss: 0.2680, entropy regularization 0.0670\n",
            "Epoch 4710: Training loss 0.0808, Validation loss 16.9165, learning rate: 0.00062\n",
            "prediction loss: 0.2597, entropy regularization 0.0763\n",
            "Epoch 4715: Training loss 0.1032, Validation loss 17.1044, learning rate: 0.00061\n",
            "prediction loss: 0.2704, entropy regularization 0.0729\n",
            "Epoch 4720: Training loss 0.0962, Validation loss 17.1464, learning rate: 0.00059\n",
            "prediction loss: 0.2571, entropy regularization 0.0711\n",
            "Epoch 4725: Training loss 0.0874, Validation loss 16.9918, learning rate: 0.00058\n",
            "prediction loss: 0.2588, entropy regularization 0.0731\n",
            "Epoch 4730: Training loss 0.0567, Validation loss 16.9811, learning rate: 0.00056\n",
            "prediction loss: 0.2636, entropy regularization 0.0802\n",
            "Epoch 4735: Training loss 0.0838, Validation loss 16.8955, learning rate: 0.00054\n",
            "prediction loss: 0.2667, entropy regularization 0.0747\n",
            "Epoch 4740: Training loss 0.1005, Validation loss 17.0133, learning rate: 0.00053\n",
            "prediction loss: 0.2525, entropy regularization 0.0728\n",
            "Epoch 4745: Training loss 0.0606, Validation loss 17.0389, learning rate: 0.00051\n",
            "prediction loss: 0.2475, entropy regularization 0.0718\n",
            "Epoch 4750: Training loss 0.0386, Validation loss 17.0136, learning rate: 0.00050\n",
            "prediction loss: 0.2545, entropy regularization 0.0691\n",
            "Epoch 4755: Training loss 0.0354, Validation loss 16.9643, learning rate: 0.00048\n",
            "prediction loss: 0.2618, entropy regularization 0.0789\n",
            "Epoch 4760: Training loss 0.0528, Validation loss 16.9039, learning rate: 0.00047\n",
            "prediction loss: 0.2700, entropy regularization 0.0746\n",
            "Epoch 4765: Training loss 0.0386, Validation loss 16.9293, learning rate: 0.00045\n",
            "prediction loss: 0.2678, entropy regularization 0.0744\n",
            "Epoch 4770: Training loss 0.0358, Validation loss 16.8585, learning rate: 0.00043\n",
            "prediction loss: 0.2612, entropy regularization 0.0785\n",
            "Epoch 4775: Training loss 0.0309, Validation loss 16.9476, learning rate: 0.00042\n",
            "prediction loss: 0.2660, entropy regularization 0.0750\n",
            "Epoch 4780: Training loss 0.0325, Validation loss 16.9965, learning rate: 0.00040\n",
            "prediction loss: 0.2544, entropy regularization 0.0724\n",
            "Epoch 4785: Training loss 0.0361, Validation loss 16.9676, learning rate: 0.00039\n",
            "prediction loss: 0.2620, entropy regularization 0.0746\n",
            "Epoch 4790: Training loss 0.0340, Validation loss 16.9211, learning rate: 0.00037\n",
            "prediction loss: 0.2579, entropy regularization 0.0731\n",
            "Epoch 4795: Training loss 0.0297, Validation loss 16.9332, learning rate: 0.00036\n",
            "prediction loss: 0.2679, entropy regularization 0.0796\n",
            "Epoch 4800: Training loss 0.0258, Validation loss 16.9423, learning rate: 0.00034\n",
            "prediction loss: 0.2619, entropy regularization 0.0782\n",
            "Epoch 4805: Training loss 0.0525, Validation loss 16.9295, learning rate: 0.00033\n",
            "prediction loss: 0.2676, entropy regularization 0.0771\n",
            "Epoch 4810: Training loss 0.0409, Validation loss 16.9208, learning rate: 0.00031\n",
            "prediction loss: 0.2793, entropy regularization 0.0761\n",
            "Epoch 4815: Training loss 0.0287, Validation loss 16.9128, learning rate: 0.00030\n",
            "prediction loss: 0.2667, entropy regularization 0.0708\n",
            "Epoch 4820: Training loss 0.0300, Validation loss 16.9101, learning rate: 0.00028\n",
            "prediction loss: 0.2714, entropy regularization 0.0707\n",
            "Epoch 4825: Training loss 0.0205, Validation loss 16.9116, learning rate: 0.00027\n",
            "prediction loss: 0.2481, entropy regularization 0.0756\n",
            "Epoch 4830: Training loss 0.0276, Validation loss 16.9474, learning rate: 0.00026\n",
            "prediction loss: 0.2610, entropy regularization 0.0738\n",
            "Epoch 4835: Training loss 0.0242, Validation loss 16.9203, learning rate: 0.00024\n",
            "prediction loss: 0.2693, entropy regularization 0.0784\n",
            "Epoch 4840: Training loss 0.0175, Validation loss 16.9776, learning rate: 0.00023\n",
            "prediction loss: 0.2608, entropy regularization 0.0733\n",
            "Epoch 4845: Training loss 0.0165, Validation loss 16.9258, learning rate: 0.00022\n",
            "prediction loss: 0.2759, entropy regularization 0.0761\n",
            "Epoch 4850: Training loss 0.0166, Validation loss 16.9109, learning rate: 0.00020\n",
            "prediction loss: 0.2526, entropy regularization 0.0780\n",
            "Epoch 4855: Training loss 0.0152, Validation loss 16.9503, learning rate: 0.00019\n",
            "prediction loss: 0.2537, entropy regularization 0.0747\n",
            "Epoch 4860: Training loss 0.0140, Validation loss 16.9023, learning rate: 0.00018\n",
            "prediction loss: 0.2495, entropy regularization 0.0769\n",
            "Epoch 4865: Training loss 0.0135, Validation loss 16.9223, learning rate: 0.00017\n",
            "prediction loss: 0.2661, entropy regularization 0.0747\n",
            "Epoch 4870: Training loss 0.0123, Validation loss 16.9414, learning rate: 0.00016\n",
            "prediction loss: 0.2651, entropy regularization 0.0758\n",
            "Epoch 4875: Training loss 0.0133, Validation loss 16.9338, learning rate: 0.00014\n",
            "prediction loss: 0.2706, entropy regularization 0.0711\n",
            "Epoch 4880: Training loss 0.0125, Validation loss 16.9198, learning rate: 0.00013\n",
            "prediction loss: 0.2624, entropy regularization 0.0723\n",
            "Epoch 4885: Training loss 0.0141, Validation loss 16.9201, learning rate: 0.00012\n",
            "prediction loss: 0.2657, entropy regularization 0.0792\n",
            "Epoch 4890: Training loss 0.0128, Validation loss 16.9101, learning rate: 0.00011\n",
            "prediction loss: 0.2696, entropy regularization 0.0732\n",
            "Epoch 4895: Training loss 0.0155, Validation loss 16.9254, learning rate: 0.00010\n",
            "prediction loss: 0.2691, entropy regularization 0.0791\n",
            "Epoch 4900: Training loss 0.0111, Validation loss 16.9384, learning rate: 0.00009\n",
            "prediction loss: 0.2582, entropy regularization 0.0730\n",
            "Epoch 4905: Training loss 0.0108, Validation loss 16.9367, learning rate: 0.00008\n",
            "prediction loss: 0.2592, entropy regularization 0.0691\n",
            "Epoch 4910: Training loss 0.0111, Validation loss 16.9231, learning rate: 0.00008\n",
            "prediction loss: 0.2683, entropy regularization 0.0773\n",
            "Epoch 4915: Training loss 0.0107, Validation loss 16.9404, learning rate: 0.00007\n",
            "prediction loss: 0.2634, entropy regularization 0.0795\n",
            "Epoch 4920: Training loss 0.0098, Validation loss 16.9415, learning rate: 0.00006\n",
            "prediction loss: 0.2512, entropy regularization 0.0749\n",
            "Epoch 4925: Training loss 0.0104, Validation loss 16.9228, learning rate: 0.00005\n",
            "prediction loss: 0.2557, entropy regularization 0.0776\n",
            "Epoch 4930: Training loss 0.0108, Validation loss 16.9306, learning rate: 0.00005\n",
            "prediction loss: 0.2595, entropy regularization 0.0722\n",
            "Epoch 4935: Training loss 0.0097, Validation loss 16.9361, learning rate: 0.00004\n",
            "prediction loss: 0.2657, entropy regularization 0.0710\n",
            "Epoch 4940: Training loss 0.0097, Validation loss 16.9409, learning rate: 0.00003\n",
            "prediction loss: 0.2618, entropy regularization 0.0707\n",
            "Epoch 4945: Training loss 0.0097, Validation loss 16.9375, learning rate: 0.00003\n",
            "prediction loss: 0.2616, entropy regularization 0.0788\n",
            "Epoch 4950: Training loss 0.0094, Validation loss 16.9402, learning rate: 0.00002\n",
            "prediction loss: 0.2657, entropy regularization 0.0730\n",
            "Epoch 4955: Training loss 0.0092, Validation loss 16.9401, learning rate: 0.00002\n",
            "prediction loss: 0.2411, entropy regularization 0.0796\n",
            "Epoch 4960: Training loss 0.0093, Validation loss 16.9341, learning rate: 0.00001\n",
            "prediction loss: 0.2627, entropy regularization 0.0801\n",
            "Epoch 4965: Training loss 0.0090, Validation loss 16.9383, learning rate: 0.00001\n",
            "prediction loss: 0.2608, entropy regularization 0.0695\n",
            "Epoch 4970: Training loss 0.0092, Validation loss 16.9413, learning rate: 0.00001\n",
            "prediction loss: 0.2577, entropy regularization 0.0791\n",
            "Epoch 4975: Training loss 0.0090, Validation loss 16.9402, learning rate: 0.00001\n",
            "prediction loss: 0.2662, entropy regularization 0.0759\n",
            "Epoch 4980: Training loss 0.0088, Validation loss 16.9393, learning rate: 0.00000\n",
            "prediction loss: 0.2407, entropy regularization 0.0771\n",
            "Epoch 4985: Training loss 0.0089, Validation loss 16.9403, learning rate: 0.00000\n",
            "prediction loss: 0.2549, entropy regularization 0.0794\n",
            "Epoch 4990: Training loss 0.0089, Validation loss 16.9405, learning rate: 0.00000\n",
            "prediction loss: 0.2656, entropy regularization 0.0733\n",
            "Epoch 4995: Training loss 0.0092, Validation loss 16.9402, learning rate: 0.00000\n",
            "prediction loss: 0.2530, entropy regularization 0.0724\n",
            "Epoch 5000: Training loss 7.0256, Validation loss 14.4123, learning rate: 0.00100\n",
            "prediction loss: 0.2733, entropy regularization 0.0726\n",
            "Epoch 5005: Training loss 1.9481, Validation loss 15.7364, learning rate: 0.00100\n",
            "prediction loss: 0.2621, entropy regularization 0.0780\n",
            "Epoch 5010: Training loss 1.4245, Validation loss 16.0646, learning rate: 0.00100\n",
            "prediction loss: 0.2614, entropy regularization 0.0773\n",
            "Epoch 5015: Training loss 1.0635, Validation loss 16.0047, learning rate: 0.00100\n",
            "prediction loss: 0.2291, entropy regularization 0.0746\n",
            "Epoch 5020: Training loss 1.0932, Validation loss 15.9732, learning rate: 0.00100\n",
            "prediction loss: 0.2587, entropy regularization 0.0800\n",
            "Epoch 5025: Training loss 0.8060, Validation loss 15.9492, learning rate: 0.00099\n",
            "prediction loss: 0.2572, entropy regularization 0.0835\n",
            "Epoch 5030: Training loss 0.7080, Validation loss 16.9048, learning rate: 0.00099\n",
            "prediction loss: 0.2664, entropy regularization 0.0825\n",
            "Epoch 5035: Training loss 0.6593, Validation loss 17.3808, learning rate: 0.00099\n",
            "prediction loss: 0.2482, entropy regularization 0.0910\n",
            "Epoch 5040: Training loss 0.7075, Validation loss 17.0152, learning rate: 0.00098\n",
            "prediction loss: 0.2692, entropy regularization 0.0853\n",
            "Epoch 5045: Training loss 0.4859, Validation loss 16.9314, learning rate: 0.00098\n",
            "prediction loss: 0.2627, entropy regularization 0.0950\n",
            "Epoch 5050: Training loss 0.4495, Validation loss 16.4810, learning rate: 0.00097\n",
            "prediction loss: 0.2689, entropy regularization 0.0902\n",
            "Epoch 5055: Training loss 0.5442, Validation loss 16.8720, learning rate: 0.00097\n",
            "prediction loss: 0.2528, entropy regularization 0.0947\n",
            "Epoch 5060: Training loss 0.3647, Validation loss 16.8504, learning rate: 0.00096\n",
            "prediction loss: 0.2655, entropy regularization 0.0938\n",
            "Epoch 5065: Training loss 0.6443, Validation loss 16.2164, learning rate: 0.00096\n",
            "prediction loss: 0.2697, entropy regularization 0.1034\n",
            "Epoch 5070: Training loss 0.3174, Validation loss 16.9592, learning rate: 0.00095\n",
            "prediction loss: 0.2549, entropy regularization 0.1035\n",
            "Epoch 5075: Training loss 0.5212, Validation loss 16.6108, learning rate: 0.00094\n",
            "prediction loss: 0.2567, entropy regularization 0.1055\n",
            "Epoch 5080: Training loss 0.3375, Validation loss 16.5037, learning rate: 0.00094\n",
            "prediction loss: 0.2622, entropy regularization 0.0952\n",
            "Epoch 5085: Training loss 0.2531, Validation loss 16.2571, learning rate: 0.00093\n",
            "prediction loss: 0.2708, entropy regularization 0.1024\n",
            "Epoch 5090: Training loss 0.2791, Validation loss 16.4646, learning rate: 0.00092\n",
            "prediction loss: 0.2704, entropy regularization 0.0972\n",
            "Epoch 5095: Training loss 0.3203, Validation loss 16.3907, learning rate: 0.00091\n",
            "prediction loss: 0.2507, entropy regularization 0.1081\n",
            "Epoch 5100: Training loss 0.3070, Validation loss 16.1361, learning rate: 0.00090\n",
            "prediction loss: 0.2632, entropy regularization 0.1096\n",
            "Epoch 5105: Training loss 0.2074, Validation loss 16.2265, learning rate: 0.00089\n",
            "prediction loss: 0.2737, entropy regularization 0.1045\n",
            "Epoch 5110: Training loss 0.1650, Validation loss 16.0494, learning rate: 0.00088\n",
            "prediction loss: 0.2616, entropy regularization 0.0988\n",
            "Epoch 5115: Training loss 0.1681, Validation loss 16.2561, learning rate: 0.00087\n",
            "prediction loss: 0.2512, entropy regularization 0.1009\n",
            "Epoch 5120: Training loss 0.1907, Validation loss 16.3061, learning rate: 0.00086\n",
            "prediction loss: 0.2434, entropy regularization 0.0997\n",
            "Epoch 5125: Training loss 0.2126, Validation loss 16.0364, learning rate: 0.00085\n",
            "prediction loss: 0.2471, entropy regularization 0.1008\n",
            "Epoch 5130: Training loss 0.1599, Validation loss 16.6137, learning rate: 0.00084\n",
            "prediction loss: 0.2658, entropy regularization 0.1051\n",
            "Epoch 5135: Training loss 0.1138, Validation loss 16.6028, learning rate: 0.00083\n",
            "prediction loss: 0.2472, entropy regularization 0.1082\n",
            "Epoch 5140: Training loss 0.1430, Validation loss 16.2660, learning rate: 0.00082\n",
            "prediction loss: 0.2694, entropy regularization 0.1099\n",
            "Epoch 5145: Training loss 0.1165, Validation loss 16.5269, learning rate: 0.00080\n",
            "prediction loss: 0.2564, entropy regularization 0.1049\n",
            "Epoch 5150: Training loss 0.0942, Validation loss 16.4028, learning rate: 0.00079\n",
            "prediction loss: 0.2558, entropy regularization 0.1016\n",
            "Epoch 5155: Training loss 0.0802, Validation loss 16.5322, learning rate: 0.00078\n",
            "prediction loss: 0.2632, entropy regularization 0.1067\n",
            "Epoch 5160: Training loss 0.0909, Validation loss 16.5726, learning rate: 0.00077\n",
            "prediction loss: 0.2727, entropy regularization 0.1025\n",
            "Epoch 5165: Training loss 0.0785, Validation loss 16.6675, learning rate: 0.00075\n",
            "prediction loss: 0.2533, entropy regularization 0.1052\n",
            "Epoch 5170: Training loss 0.0730, Validation loss 16.6175, learning rate: 0.00074\n",
            "prediction loss: 0.2661, entropy regularization 0.1146\n",
            "Epoch 5175: Training loss 0.0734, Validation loss 16.7989, learning rate: 0.00072\n",
            "prediction loss: 0.2526, entropy regularization 0.1169\n",
            "Epoch 5180: Training loss 0.0729, Validation loss 16.5557, learning rate: 0.00071\n",
            "prediction loss: 0.2740, entropy regularization 0.1080\n",
            "Epoch 5185: Training loss 0.1147, Validation loss 16.7747, learning rate: 0.00070\n",
            "prediction loss: 0.2598, entropy regularization 0.1104\n",
            "Epoch 5190: Training loss 0.0696, Validation loss 16.3936, learning rate: 0.00068\n",
            "prediction loss: 0.2822, entropy regularization 0.1124\n",
            "Epoch 5195: Training loss 0.0574, Validation loss 16.6631, learning rate: 0.00067\n",
            "prediction loss: 0.2474, entropy regularization 0.1117\n",
            "Epoch 5200: Training loss 0.1017, Validation loss 16.2684, learning rate: 0.00065\n",
            "prediction loss: 0.2560, entropy regularization 0.1128\n",
            "Epoch 5205: Training loss 0.0751, Validation loss 16.4745, learning rate: 0.00064\n",
            "prediction loss: 0.2679, entropy regularization 0.1174\n",
            "Epoch 5210: Training loss 0.0593, Validation loss 16.6844, learning rate: 0.00062\n",
            "prediction loss: 0.2651, entropy regularization 0.1161\n",
            "Epoch 5215: Training loss 0.0417, Validation loss 16.7065, learning rate: 0.00061\n",
            "prediction loss: 0.2769, entropy regularization 0.1134\n",
            "Epoch 5220: Training loss 0.0330, Validation loss 16.3738, learning rate: 0.00059\n",
            "prediction loss: 0.2530, entropy regularization 0.1159\n",
            "Epoch 5225: Training loss 0.0525, Validation loss 16.4882, learning rate: 0.00058\n",
            "prediction loss: 0.2704, entropy regularization 0.1146\n",
            "Epoch 5230: Training loss 0.0508, Validation loss 16.4944, learning rate: 0.00056\n",
            "prediction loss: 0.2637, entropy regularization 0.1131\n",
            "Epoch 5235: Training loss 0.0503, Validation loss 16.4794, learning rate: 0.00054\n",
            "prediction loss: 0.2678, entropy regularization 0.1150\n",
            "Epoch 5240: Training loss 0.0429, Validation loss 16.6178, learning rate: 0.00053\n",
            "prediction loss: 0.2677, entropy regularization 0.1145\n",
            "Epoch 5245: Training loss 0.0494, Validation loss 16.5177, learning rate: 0.00051\n",
            "prediction loss: 0.2577, entropy regularization 0.1065\n",
            "Epoch 5250: Training loss 0.0208, Validation loss 16.6606, learning rate: 0.00050\n",
            "prediction loss: 0.2589, entropy regularization 0.1094\n",
            "Epoch 5255: Training loss 0.0344, Validation loss 16.6113, learning rate: 0.00048\n",
            "prediction loss: 0.2712, entropy regularization 0.1211\n",
            "Epoch 5260: Training loss 0.0320, Validation loss 16.6107, learning rate: 0.00047\n",
            "prediction loss: 0.2554, entropy regularization 0.1159\n",
            "Epoch 5265: Training loss 0.0249, Validation loss 16.4354, learning rate: 0.00045\n",
            "prediction loss: 0.2443, entropy regularization 0.1172\n",
            "Epoch 5270: Training loss 0.0199, Validation loss 16.5512, learning rate: 0.00043\n",
            "prediction loss: 0.2653, entropy regularization 0.1169\n",
            "Epoch 5275: Training loss 0.0246, Validation loss 16.5098, learning rate: 0.00042\n",
            "prediction loss: 0.2706, entropy regularization 0.1140\n",
            "Epoch 5280: Training loss 0.0305, Validation loss 16.4685, learning rate: 0.00040\n",
            "prediction loss: 0.2795, entropy regularization 0.1142\n",
            "Epoch 5285: Training loss 0.0311, Validation loss 16.4842, learning rate: 0.00039\n",
            "prediction loss: 0.2531, entropy regularization 0.1180\n",
            "Epoch 5290: Training loss 0.0152, Validation loss 16.5644, learning rate: 0.00037\n",
            "prediction loss: 0.2508, entropy regularization 0.1107\n",
            "Epoch 5295: Training loss 0.0141, Validation loss 16.5260, learning rate: 0.00036\n",
            "prediction loss: 0.2666, entropy regularization 0.1127\n",
            "Epoch 5300: Training loss 0.0167, Validation loss 16.4564, learning rate: 0.00034\n",
            "prediction loss: 0.2555, entropy regularization 0.1146\n",
            "Epoch 5305: Training loss 0.0149, Validation loss 16.5011, learning rate: 0.00033\n",
            "prediction loss: 0.2662, entropy regularization 0.1142\n",
            "Epoch 5310: Training loss 0.0100, Validation loss 16.4783, learning rate: 0.00031\n",
            "prediction loss: 0.2673, entropy regularization 0.1132\n",
            "Epoch 5315: Training loss 0.0105, Validation loss 16.4989, learning rate: 0.00030\n",
            "prediction loss: 0.2609, entropy regularization 0.1101\n",
            "Epoch 5320: Training loss 0.0107, Validation loss 16.4638, learning rate: 0.00028\n",
            "prediction loss: 0.2466, entropy regularization 0.1169\n",
            "Epoch 5325: Training loss 0.0105, Validation loss 16.5002, learning rate: 0.00027\n",
            "prediction loss: 0.2497, entropy regularization 0.1170\n",
            "Epoch 5330: Training loss 0.0076, Validation loss 16.4699, learning rate: 0.00026\n",
            "prediction loss: 0.2519, entropy regularization 0.1065\n",
            "Epoch 5335: Training loss 0.0071, Validation loss 16.4679, learning rate: 0.00024\n",
            "prediction loss: 0.2511, entropy regularization 0.1176\n",
            "Epoch 5340: Training loss 0.0121, Validation loss 16.4934, learning rate: 0.00023\n",
            "prediction loss: 0.2553, entropy regularization 0.1109\n",
            "Epoch 5345: Training loss 0.0074, Validation loss 16.4912, learning rate: 0.00022\n",
            "prediction loss: 0.2607, entropy regularization 0.1161\n",
            "Epoch 5350: Training loss 0.0081, Validation loss 16.4646, learning rate: 0.00020\n",
            "prediction loss: 0.2715, entropy regularization 0.1052\n",
            "Epoch 5355: Training loss 0.0125, Validation loss 16.4571, learning rate: 0.00019\n",
            "prediction loss: 0.2609, entropy regularization 0.1188\n",
            "Epoch 5360: Training loss 0.0102, Validation loss 16.4535, learning rate: 0.00018\n",
            "prediction loss: 0.2691, entropy regularization 0.1125\n",
            "Epoch 5365: Training loss 0.0048, Validation loss 16.4376, learning rate: 0.00017\n",
            "prediction loss: 0.2668, entropy regularization 0.1145\n",
            "Epoch 5370: Training loss 0.0050, Validation loss 16.4699, learning rate: 0.00016\n",
            "prediction loss: 0.2592, entropy regularization 0.1124\n",
            "Epoch 5375: Training loss 0.0045, Validation loss 16.4385, learning rate: 0.00014\n",
            "prediction loss: 0.2680, entropy regularization 0.1108\n",
            "Epoch 5380: Training loss 0.0079, Validation loss 16.4275, learning rate: 0.00013\n",
            "prediction loss: 0.2593, entropy regularization 0.1128\n",
            "Epoch 5385: Training loss 0.0058, Validation loss 16.4318, learning rate: 0.00012\n",
            "prediction loss: 0.2718, entropy regularization 0.1173\n",
            "Epoch 5390: Training loss 0.0041, Validation loss 16.4436, learning rate: 0.00011\n",
            "prediction loss: 0.2713, entropy regularization 0.1194\n",
            "Epoch 5395: Training loss 0.0042, Validation loss 16.4680, learning rate: 0.00010\n",
            "prediction loss: 0.2588, entropy regularization 0.1085\n",
            "Epoch 5400: Training loss 0.0040, Validation loss 16.4648, learning rate: 0.00009\n",
            "prediction loss: 0.2511, entropy regularization 0.1173\n",
            "Epoch 5405: Training loss 0.0025, Validation loss 16.4469, learning rate: 0.00008\n",
            "prediction loss: 0.2732, entropy regularization 0.1128\n",
            "Epoch 5410: Training loss 0.0026, Validation loss 16.4449, learning rate: 0.00008\n",
            "prediction loss: 0.2709, entropy regularization 0.1082\n",
            "Epoch 5415: Training loss 0.0024, Validation loss 16.4406, learning rate: 0.00007\n",
            "prediction loss: 0.2618, entropy regularization 0.1074\n",
            "Epoch 5420: Training loss 0.0022, Validation loss 16.4427, learning rate: 0.00006\n",
            "prediction loss: 0.2960, entropy regularization 0.1076\n",
            "Epoch 5425: Training loss 0.0026, Validation loss 16.4507, learning rate: 0.00005\n",
            "prediction loss: 0.2698, entropy regularization 0.1136\n",
            "Epoch 5430: Training loss 0.0023, Validation loss 16.4383, learning rate: 0.00005\n",
            "prediction loss: 0.2525, entropy regularization 0.1131\n",
            "Epoch 5435: Training loss 0.0020, Validation loss 16.4373, learning rate: 0.00004\n",
            "prediction loss: 0.2693, entropy regularization 0.1145\n",
            "Epoch 5440: Training loss 0.0023, Validation loss 16.4294, learning rate: 0.00003\n",
            "prediction loss: 0.2653, entropy regularization 0.1183\n",
            "Epoch 5445: Training loss 0.0021, Validation loss 16.4402, learning rate: 0.00003\n",
            "prediction loss: 0.2602, entropy regularization 0.1165\n",
            "Epoch 5450: Training loss 0.0022, Validation loss 16.4294, learning rate: 0.00002\n",
            "prediction loss: 0.2599, entropy regularization 0.1095\n",
            "Epoch 5455: Training loss 0.0018, Validation loss 16.4349, learning rate: 0.00002\n",
            "prediction loss: 0.2670, entropy regularization 0.1143\n",
            "Epoch 5460: Training loss 0.0018, Validation loss 16.4356, learning rate: 0.00001\n",
            "prediction loss: 0.2564, entropy regularization 0.1163\n",
            "Epoch 5465: Training loss 0.0017, Validation loss 16.4376, learning rate: 0.00001\n",
            "prediction loss: 0.2557, entropy regularization 0.1164\n",
            "Epoch 5470: Training loss 0.0018, Validation loss 16.4341, learning rate: 0.00001\n",
            "prediction loss: 0.2629, entropy regularization 0.1176\n",
            "Epoch 5475: Training loss 0.0017, Validation loss 16.4341, learning rate: 0.00001\n",
            "prediction loss: 0.2569, entropy regularization 0.1157\n",
            "Epoch 5480: Training loss 0.0017, Validation loss 16.4348, learning rate: 0.00000\n",
            "prediction loss: 0.2695, entropy regularization 0.1130\n",
            "Epoch 5485: Training loss 0.0017, Validation loss 16.4339, learning rate: 0.00000\n",
            "prediction loss: 0.2610, entropy regularization 0.1142\n",
            "Epoch 5490: Training loss 0.0017, Validation loss 16.4338, learning rate: 0.00000\n",
            "prediction loss: 0.2671, entropy regularization 0.1106\n",
            "Epoch 5495: Training loss 0.0016, Validation loss 16.4338, learning rate: 0.00000\n",
            "prediction loss: 0.2732, entropy regularization 0.1056\n",
            "Epoch 5500: Training loss 1.1407, Validation loss 15.3365, learning rate: 0.00100\n",
            "prediction loss: 0.2732, entropy regularization 0.1227\n",
            "Epoch 5505: Training loss 1.9939, Validation loss 16.8304, learning rate: 0.00100\n",
            "prediction loss: 0.2638, entropy regularization 0.1178\n",
            "Epoch 5510: Training loss 1.4665, Validation loss 16.2338, learning rate: 0.00100\n",
            "prediction loss: 0.2595, entropy regularization 0.1445\n",
            "Epoch 5515: Training loss 0.9668, Validation loss 17.3853, learning rate: 0.00100\n",
            "prediction loss: 0.2611, entropy regularization 0.1527\n",
            "Epoch 5520: Training loss 0.6686, Validation loss 17.5258, learning rate: 0.00100\n",
            "prediction loss: 0.2629, entropy regularization 0.1420\n",
            "Epoch 5525: Training loss 0.6240, Validation loss 18.0166, learning rate: 0.00099\n",
            "prediction loss: 0.2658, entropy regularization 0.1428\n",
            "Epoch 5530: Training loss 0.6728, Validation loss 16.8936, learning rate: 0.00099\n",
            "prediction loss: 0.2601, entropy regularization 0.1579\n",
            "Epoch 5535: Training loss 0.4667, Validation loss 16.9801, learning rate: 0.00099\n",
            "prediction loss: 0.2588, entropy regularization 0.1560\n",
            "Epoch 5540: Training loss 0.2940, Validation loss 16.5503, learning rate: 0.00098\n",
            "prediction loss: 0.2662, entropy regularization 0.1585\n",
            "Epoch 5545: Training loss 0.3117, Validation loss 16.8723, learning rate: 0.00098\n",
            "prediction loss: 0.2595, entropy regularization 0.1650\n",
            "Epoch 5550: Training loss 0.2629, Validation loss 16.8386, learning rate: 0.00097\n",
            "prediction loss: 0.2718, entropy regularization 0.1629\n",
            "Epoch 5555: Training loss 0.2342, Validation loss 16.6821, learning rate: 0.00097\n",
            "prediction loss: 0.2505, entropy regularization 0.1725\n",
            "Epoch 5560: Training loss 0.2088, Validation loss 16.6175, learning rate: 0.00096\n",
            "prediction loss: 0.2690, entropy regularization 0.1570\n",
            "Epoch 5565: Training loss 0.1723, Validation loss 16.5008, learning rate: 0.00096\n",
            "prediction loss: 0.2419, entropy regularization 0.1598\n",
            "Epoch 5570: Training loss 0.1592, Validation loss 16.7297, learning rate: 0.00095\n",
            "prediction loss: 0.2611, entropy regularization 0.1648\n",
            "Epoch 5575: Training loss 0.2367, Validation loss 16.2923, learning rate: 0.00094\n",
            "prediction loss: 0.2467, entropy regularization 0.1687\n",
            "Epoch 5580: Training loss 0.2737, Validation loss 16.8831, learning rate: 0.00094\n",
            "prediction loss: 0.2685, entropy regularization 0.1591\n",
            "Epoch 5585: Training loss 0.1291, Validation loss 16.6767, learning rate: 0.00093\n",
            "prediction loss: 0.2639, entropy regularization 0.1531\n",
            "Epoch 5590: Training loss 0.1264, Validation loss 16.6513, learning rate: 0.00092\n",
            "prediction loss: 0.2593, entropy regularization 0.1794\n",
            "Epoch 5595: Training loss 0.1088, Validation loss 16.5392, learning rate: 0.00091\n",
            "prediction loss: 0.2463, entropy regularization 0.1691\n",
            "Epoch 5600: Training loss 0.1053, Validation loss 16.8404, learning rate: 0.00090\n",
            "prediction loss: 0.2542, entropy regularization 0.1617\n",
            "Epoch 5605: Training loss 0.0680, Validation loss 16.9654, learning rate: 0.00089\n",
            "prediction loss: 0.2783, entropy regularization 0.1755\n",
            "Epoch 5610: Training loss 0.0509, Validation loss 16.6607, learning rate: 0.00088\n",
            "prediction loss: 0.2680, entropy regularization 0.1701\n",
            "Epoch 5615: Training loss 0.0860, Validation loss 16.8542, learning rate: 0.00087\n",
            "prediction loss: 0.2666, entropy regularization 0.1654\n",
            "Epoch 5620: Training loss 0.0801, Validation loss 16.6373, learning rate: 0.00086\n",
            "prediction loss: 0.2486, entropy regularization 0.1643\n",
            "Epoch 5625: Training loss 0.0582, Validation loss 16.7981, learning rate: 0.00085\n",
            "prediction loss: 0.2704, entropy regularization 0.1734\n",
            "Epoch 5630: Training loss 0.0631, Validation loss 16.9099, learning rate: 0.00084\n",
            "prediction loss: 0.2593, entropy regularization 0.1730\n",
            "Epoch 5635: Training loss 0.0672, Validation loss 16.9448, learning rate: 0.00083\n",
            "prediction loss: 0.2683, entropy regularization 0.1718\n",
            "Epoch 5640: Training loss 0.0896, Validation loss 17.1139, learning rate: 0.00082\n",
            "prediction loss: 0.2729, entropy regularization 0.1636\n",
            "Epoch 5645: Training loss 0.0528, Validation loss 16.9959, learning rate: 0.00080\n",
            "prediction loss: 0.2515, entropy regularization 0.1726\n",
            "Epoch 5650: Training loss 0.0364, Validation loss 16.9369, learning rate: 0.00079\n",
            "prediction loss: 0.2637, entropy regularization 0.1638\n",
            "Epoch 5655: Training loss 0.0240, Validation loss 16.8706, learning rate: 0.00078\n",
            "prediction loss: 0.2500, entropy regularization 0.1677\n",
            "Epoch 5660: Training loss 0.0404, Validation loss 16.9019, learning rate: 0.00077\n",
            "prediction loss: 0.2671, entropy regularization 0.1683\n",
            "Epoch 5665: Training loss 0.0470, Validation loss 16.9847, learning rate: 0.00075\n",
            "prediction loss: 0.2637, entropy regularization 0.1696\n",
            "Epoch 5670: Training loss 0.0199, Validation loss 16.8455, learning rate: 0.00074\n",
            "prediction loss: 0.2565, entropy regularization 0.1600\n",
            "Epoch 5675: Training loss 0.0259, Validation loss 16.7689, learning rate: 0.00072\n",
            "prediction loss: 0.2524, entropy regularization 0.1669\n",
            "Epoch 5680: Training loss 0.0332, Validation loss 16.9343, learning rate: 0.00071\n",
            "prediction loss: 0.2763, entropy regularization 0.1660\n",
            "Epoch 5685: Training loss 0.0191, Validation loss 16.8121, learning rate: 0.00070\n",
            "prediction loss: 0.2664, entropy regularization 0.1671\n",
            "Epoch 5690: Training loss 0.0173, Validation loss 16.8380, learning rate: 0.00068\n",
            "prediction loss: 0.2593, entropy regularization 0.1683\n",
            "Epoch 5695: Training loss 0.0261, Validation loss 16.7418, learning rate: 0.00067\n",
            "prediction loss: 0.2701, entropy regularization 0.1656\n",
            "Epoch 5700: Training loss 0.0224, Validation loss 16.8646, learning rate: 0.00065\n",
            "prediction loss: 0.2718, entropy regularization 0.1622\n",
            "Epoch 5705: Training loss 0.0450, Validation loss 16.8252, learning rate: 0.00064\n",
            "prediction loss: 0.2599, entropy regularization 0.1670\n",
            "Epoch 5710: Training loss 0.0213, Validation loss 16.7212, learning rate: 0.00062\n",
            "prediction loss: 0.2463, entropy regularization 0.1737\n",
            "Epoch 5715: Training loss 0.0477, Validation loss 16.8868, learning rate: 0.00061\n",
            "prediction loss: 0.2610, entropy regularization 0.1670\n",
            "Epoch 5720: Training loss 0.0559, Validation loss 16.8915, learning rate: 0.00059\n",
            "prediction loss: 0.2614, entropy regularization 0.1644\n",
            "Epoch 5725: Training loss 0.0553, Validation loss 16.7084, learning rate: 0.00058\n",
            "prediction loss: 0.2613, entropy regularization 0.1649\n",
            "Epoch 5730: Training loss 0.0346, Validation loss 16.7283, learning rate: 0.00056\n",
            "prediction loss: 0.2642, entropy regularization 0.1657\n",
            "Epoch 5735: Training loss 0.0176, Validation loss 16.7629, learning rate: 0.00054\n",
            "prediction loss: 0.2686, entropy regularization 0.1654\n",
            "Epoch 5740: Training loss 0.0196, Validation loss 16.8434, learning rate: 0.00053\n",
            "prediction loss: 0.2523, entropy regularization 0.1652\n",
            "Epoch 5745: Training loss 0.0265, Validation loss 16.7221, learning rate: 0.00051\n",
            "prediction loss: 0.2484, entropy regularization 0.1664\n",
            "Epoch 5750: Training loss 0.0204, Validation loss 16.7780, learning rate: 0.00050\n",
            "prediction loss: 0.2546, entropy regularization 0.1611\n",
            "Epoch 5755: Training loss 0.0092, Validation loss 16.7427, learning rate: 0.00048\n",
            "prediction loss: 0.2469, entropy regularization 0.1753\n",
            "Epoch 5760: Training loss 0.0092, Validation loss 16.7751, learning rate: 0.00047\n",
            "prediction loss: 0.2610, entropy regularization 0.1702\n",
            "Epoch 5765: Training loss 0.0209, Validation loss 16.7479, learning rate: 0.00045\n",
            "prediction loss: 0.2635, entropy regularization 0.1701\n",
            "Epoch 5770: Training loss 0.0108, Validation loss 16.7301, learning rate: 0.00043\n",
            "prediction loss: 0.2527, entropy regularization 0.1704\n",
            "Epoch 5775: Training loss 0.0108, Validation loss 16.8101, learning rate: 0.00042\n",
            "prediction loss: 0.2494, entropy regularization 0.1645\n",
            "Epoch 5780: Training loss 0.0081, Validation loss 16.7512, learning rate: 0.00040\n",
            "prediction loss: 0.2612, entropy regularization 0.1655\n",
            "Epoch 5785: Training loss 0.0116, Validation loss 16.8376, learning rate: 0.00039\n",
            "prediction loss: 0.2521, entropy regularization 0.1690\n",
            "Epoch 5790: Training loss 0.0083, Validation loss 16.7885, learning rate: 0.00037\n",
            "prediction loss: 0.2669, entropy regularization 0.1648\n",
            "Epoch 5795: Training loss 0.0081, Validation loss 16.8685, learning rate: 0.00036\n",
            "prediction loss: 0.2722, entropy regularization 0.1675\n",
            "Epoch 5800: Training loss 0.0098, Validation loss 16.7984, learning rate: 0.00034\n",
            "prediction loss: 0.2653, entropy regularization 0.1667\n",
            "Epoch 5805: Training loss 0.0046, Validation loss 16.8201, learning rate: 0.00033\n",
            "prediction loss: 0.2666, entropy regularization 0.1660\n",
            "Epoch 5810: Training loss 0.0057, Validation loss 16.7938, learning rate: 0.00031\n",
            "prediction loss: 0.2505, entropy regularization 0.1751\n",
            "Epoch 5815: Training loss 0.0073, Validation loss 16.7695, learning rate: 0.00030\n",
            "prediction loss: 0.2722, entropy regularization 0.1632\n",
            "Epoch 5820: Training loss 0.0060, Validation loss 16.7939, learning rate: 0.00028\n",
            "prediction loss: 0.2625, entropy regularization 0.1725\n",
            "Epoch 5825: Training loss 0.0059, Validation loss 16.7927, learning rate: 0.00027\n",
            "prediction loss: 0.2666, entropy regularization 0.1692\n",
            "Epoch 5830: Training loss 0.0038, Validation loss 16.8319, learning rate: 0.00026\n",
            "prediction loss: 0.2269, entropy regularization 0.1787\n",
            "Epoch 5835: Training loss 0.0040, Validation loss 16.7675, learning rate: 0.00024\n",
            "prediction loss: 0.2630, entropy regularization 0.1718\n",
            "Epoch 5840: Training loss 0.0061, Validation loss 16.7877, learning rate: 0.00023\n",
            "prediction loss: 0.2501, entropy regularization 0.1774\n",
            "Epoch 5845: Training loss 0.0030, Validation loss 16.8165, learning rate: 0.00022\n",
            "prediction loss: 0.2651, entropy regularization 0.1692\n",
            "Epoch 5850: Training loss 0.0053, Validation loss 16.7857, learning rate: 0.00020\n",
            "prediction loss: 0.2598, entropy regularization 0.1665\n",
            "Epoch 5855: Training loss 0.0023, Validation loss 16.8248, learning rate: 0.00019\n",
            "prediction loss: 0.2677, entropy regularization 0.1702\n",
            "Epoch 5860: Training loss 0.0050, Validation loss 16.7526, learning rate: 0.00018\n",
            "prediction loss: 0.2440, entropy regularization 0.1738\n",
            "Epoch 5865: Training loss 0.0027, Validation loss 16.7912, learning rate: 0.00017\n",
            "prediction loss: 0.2453, entropy regularization 0.1782\n",
            "Epoch 5870: Training loss 0.0016, Validation loss 16.7660, learning rate: 0.00016\n",
            "prediction loss: 0.2582, entropy regularization 0.1709\n",
            "Epoch 5875: Training loss 0.0017, Validation loss 16.8073, learning rate: 0.00014\n",
            "prediction loss: 0.2577, entropy regularization 0.1657\n",
            "Epoch 5880: Training loss 0.0012, Validation loss 16.7899, learning rate: 0.00013\n",
            "prediction loss: 0.2476, entropy regularization 0.1768\n",
            "Epoch 5885: Training loss 0.0008, Validation loss 16.7931, learning rate: 0.00012\n",
            "prediction loss: 0.2614, entropy regularization 0.1727\n",
            "Epoch 5890: Training loss 0.0014, Validation loss 16.8039, learning rate: 0.00011\n",
            "prediction loss: 0.2695, entropy regularization 0.1665\n",
            "Epoch 5895: Training loss 0.0009, Validation loss 16.7957, learning rate: 0.00010\n",
            "prediction loss: 0.2539, entropy regularization 0.1757\n",
            "Epoch 5900: Training loss 0.0008, Validation loss 16.7961, learning rate: 0.00009\n",
            "prediction loss: 0.2493, entropy regularization 0.1767\n",
            "Epoch 5905: Training loss 0.0006, Validation loss 16.7990, learning rate: 0.00008\n",
            "prediction loss: 0.2604, entropy regularization 0.1739\n",
            "Epoch 5910: Training loss 0.0007, Validation loss 16.7989, learning rate: 0.00008\n",
            "prediction loss: 0.2572, entropy regularization 0.1800\n",
            "Epoch 5915: Training loss 0.0005, Validation loss 16.7912, learning rate: 0.00007\n",
            "prediction loss: 0.2590, entropy regularization 0.1816\n",
            "Epoch 5920: Training loss 0.0005, Validation loss 16.7904, learning rate: 0.00006\n",
            "prediction loss: 0.2692, entropy regularization 0.1751\n",
            "Epoch 5925: Training loss 0.0004, Validation loss 16.7922, learning rate: 0.00005\n",
            "prediction loss: 0.2754, entropy regularization 0.1658\n",
            "Epoch 5930: Training loss 0.0004, Validation loss 16.7950, learning rate: 0.00005\n",
            "prediction loss: 0.2665, entropy regularization 0.1791\n",
            "Epoch 5935: Training loss 0.0004, Validation loss 16.7933, learning rate: 0.00004\n",
            "prediction loss: 0.2770, entropy regularization 0.1718\n",
            "Epoch 5940: Training loss 0.0003, Validation loss 16.7931, learning rate: 0.00003\n",
            "prediction loss: 0.2667, entropy regularization 0.1724\n",
            "Epoch 5945: Training loss 0.0003, Validation loss 16.7917, learning rate: 0.00003\n",
            "prediction loss: 0.2488, entropy regularization 0.1778\n",
            "Epoch 5950: Training loss 0.0003, Validation loss 16.7936, learning rate: 0.00002\n",
            "prediction loss: 0.2659, entropy regularization 0.1686\n",
            "Epoch 5955: Training loss 0.0003, Validation loss 16.7946, learning rate: 0.00002\n",
            "prediction loss: 0.2433, entropy regularization 0.1795\n",
            "Epoch 5960: Training loss 0.0003, Validation loss 16.7932, learning rate: 0.00001\n",
            "prediction loss: 0.2679, entropy regularization 0.1720\n",
            "Epoch 5965: Training loss 0.0003, Validation loss 16.7930, learning rate: 0.00001\n",
            "prediction loss: 0.2763, entropy regularization 0.1757\n",
            "Epoch 5970: Training loss 0.0003, Validation loss 16.7919, learning rate: 0.00001\n",
            "prediction loss: 0.2768, entropy regularization 0.1676\n",
            "Epoch 5975: Training loss 0.0003, Validation loss 16.7932, learning rate: 0.00001\n",
            "prediction loss: 0.2531, entropy regularization 0.1814\n",
            "Epoch 5980: Training loss 0.0003, Validation loss 16.7929, learning rate: 0.00000\n",
            "prediction loss: 0.2659, entropy regularization 0.1793\n",
            "Epoch 5985: Training loss 0.0003, Validation loss 16.7931, learning rate: 0.00000\n",
            "prediction loss: 0.2674, entropy regularization 0.1775\n",
            "Epoch 5990: Training loss 0.0003, Validation loss 16.7932, learning rate: 0.00000\n",
            "prediction loss: 0.2642, entropy regularization 0.1741\n",
            "Epoch 5995: Training loss 0.0003, Validation loss 16.7932, learning rate: 0.00000\n",
            "prediction loss: 0.2564, entropy regularization 0.1707\n",
            "Epoch 6000: Training loss 1.6840, Validation loss 15.1932, learning rate: 0.00100\n",
            "prediction loss: 0.2549, entropy regularization 0.1629\n",
            "Epoch 6005: Training loss 1.5488, Validation loss 16.0375, learning rate: 0.00100\n",
            "prediction loss: 0.2619, entropy regularization 0.0669\n",
            "Epoch 6010: Training loss 0.9212, Validation loss 16.7668, learning rate: 0.00100\n",
            "prediction loss: 0.2606, entropy regularization 0.0732\n",
            "Epoch 6015: Training loss 0.6269, Validation loss 16.2080, learning rate: 0.00100\n",
            "prediction loss: 0.2703, entropy regularization 0.0733\n",
            "Epoch 6020: Training loss 0.8154, Validation loss 15.9766, learning rate: 0.00100\n",
            "prediction loss: 0.2523, entropy regularization 0.1380\n",
            "Epoch 6025: Training loss 0.5725, Validation loss 16.3972, learning rate: 0.00099\n",
            "prediction loss: 0.2444, entropy regularization 0.1111\n",
            "Epoch 6030: Training loss 0.3614, Validation loss 16.8279, learning rate: 0.00099\n",
            "prediction loss: 0.2747, entropy regularization 0.0923\n",
            "Epoch 6035: Training loss 0.2692, Validation loss 16.5759, learning rate: 0.00099\n",
            "prediction loss: 0.2621, entropy regularization 0.0983\n",
            "Epoch 6040: Training loss 0.1701, Validation loss 16.9216, learning rate: 0.00098\n",
            "prediction loss: 0.2651, entropy regularization 0.0927\n",
            "Epoch 6045: Training loss 0.1843, Validation loss 16.3777, learning rate: 0.00098\n",
            "prediction loss: 0.2662, entropy regularization 0.0950\n",
            "Epoch 6050: Training loss 0.1795, Validation loss 16.9122, learning rate: 0.00097\n",
            "prediction loss: 0.2619, entropy regularization 0.0876\n",
            "Epoch 6055: Training loss 0.1338, Validation loss 17.0757, learning rate: 0.00097\n",
            "prediction loss: 0.2655, entropy regularization 0.0929\n",
            "Epoch 6060: Training loss 0.0935, Validation loss 16.6168, learning rate: 0.00096\n",
            "prediction loss: 0.2629, entropy regularization 0.0917\n",
            "Epoch 6065: Training loss 0.0950, Validation loss 16.9098, learning rate: 0.00096\n",
            "prediction loss: 0.2547, entropy regularization 0.0913\n",
            "Epoch 6070: Training loss 0.0719, Validation loss 17.0314, learning rate: 0.00095\n",
            "prediction loss: 0.2805, entropy regularization 0.0875\n",
            "Epoch 6075: Training loss 0.0740, Validation loss 16.9501, learning rate: 0.00094\n",
            "prediction loss: 0.2567, entropy regularization 0.0893\n",
            "Epoch 6080: Training loss 0.1078, Validation loss 16.8275, learning rate: 0.00094\n",
            "prediction loss: 0.2666, entropy regularization 0.0862\n",
            "Epoch 6085: Training loss 0.1092, Validation loss 16.8908, learning rate: 0.00093\n",
            "prediction loss: 0.2586, entropy regularization 0.0856\n",
            "Epoch 6090: Training loss 0.0915, Validation loss 17.1542, learning rate: 0.00092\n",
            "prediction loss: 0.2549, entropy regularization 0.0826\n",
            "Epoch 6095: Training loss 0.0565, Validation loss 16.9816, learning rate: 0.00091\n",
            "prediction loss: 0.2722, entropy regularization 0.0805\n",
            "Epoch 6100: Training loss 0.0379, Validation loss 16.9044, learning rate: 0.00090\n",
            "prediction loss: 0.2462, entropy regularization 0.0863\n",
            "Epoch 6105: Training loss 0.0372, Validation loss 16.9904, learning rate: 0.00089\n",
            "prediction loss: 0.2503, entropy regularization 0.0842\n",
            "Epoch 6110: Training loss 0.0347, Validation loss 17.0523, learning rate: 0.00088\n",
            "prediction loss: 0.2601, entropy regularization 0.0821\n",
            "Epoch 6115: Training loss 0.0274, Validation loss 17.0072, learning rate: 0.00087\n",
            "prediction loss: 0.2483, entropy regularization 0.0769\n",
            "Epoch 6120: Training loss 0.0327, Validation loss 17.0607, learning rate: 0.00086\n",
            "prediction loss: 0.2598, entropy regularization 0.0849\n",
            "Epoch 6125: Training loss 0.0280, Validation loss 16.8925, learning rate: 0.00085\n",
            "prediction loss: 0.2544, entropy regularization 0.0896\n",
            "Epoch 6130: Training loss 0.0293, Validation loss 16.8924, learning rate: 0.00084\n",
            "prediction loss: 0.2625, entropy regularization 0.0846\n",
            "Epoch 6135: Training loss 0.0661, Validation loss 16.7813, learning rate: 0.00083\n",
            "prediction loss: 0.2638, entropy regularization 0.0853\n",
            "Epoch 6140: Training loss 0.0372, Validation loss 16.9363, learning rate: 0.00082\n",
            "prediction loss: 0.2567, entropy regularization 0.0801\n",
            "Epoch 6145: Training loss 0.0417, Validation loss 16.9639, learning rate: 0.00080\n",
            "prediction loss: 0.2672, entropy regularization 0.0773\n",
            "Epoch 6150: Training loss 0.0271, Validation loss 16.9343, learning rate: 0.00079\n",
            "prediction loss: 0.2699, entropy regularization 0.0783\n",
            "Epoch 6155: Training loss 0.0246, Validation loss 16.9546, learning rate: 0.00078\n",
            "prediction loss: 0.2603, entropy regularization 0.0786\n",
            "Epoch 6160: Training loss 0.0165, Validation loss 16.9758, learning rate: 0.00077\n",
            "prediction loss: 0.2813, entropy regularization 0.0758\n",
            "Epoch 6165: Training loss 0.0085, Validation loss 17.1383, learning rate: 0.00075\n",
            "prediction loss: 0.2621, entropy regularization 0.0735\n",
            "Epoch 6170: Training loss 0.0195, Validation loss 17.0644, learning rate: 0.00074\n",
            "prediction loss: 0.2553, entropy regularization 0.0764\n",
            "Epoch 6175: Training loss 0.0157, Validation loss 17.1575, learning rate: 0.00072\n",
            "prediction loss: 0.2594, entropy regularization 0.0724\n",
            "Epoch 6180: Training loss 0.0129, Validation loss 17.0895, learning rate: 0.00071\n",
            "prediction loss: 0.2443, entropy regularization 0.0751\n",
            "Epoch 6185: Training loss 0.0326, Validation loss 17.0159, learning rate: 0.00070\n",
            "prediction loss: 0.2720, entropy regularization 0.0754\n",
            "Epoch 6190: Training loss 0.0248, Validation loss 17.1375, learning rate: 0.00068\n",
            "prediction loss: 0.2591, entropy regularization 0.0777\n",
            "Epoch 6195: Training loss 0.0128, Validation loss 17.0119, learning rate: 0.00067\n",
            "prediction loss: 0.2567, entropy regularization 0.0724\n",
            "Epoch 6200: Training loss 0.0118, Validation loss 17.1875, learning rate: 0.00065\n",
            "prediction loss: 0.2585, entropy regularization 0.0771\n",
            "Epoch 6205: Training loss 0.0177, Validation loss 16.9550, learning rate: 0.00064\n",
            "prediction loss: 0.2619, entropy regularization 0.0714\n",
            "Epoch 6210: Training loss 0.0121, Validation loss 17.1124, learning rate: 0.00062\n",
            "prediction loss: 0.2680, entropy regularization 0.0725\n",
            "Epoch 6215: Training loss 0.0069, Validation loss 16.9203, learning rate: 0.00061\n",
            "prediction loss: 0.2588, entropy regularization 0.0708\n",
            "Epoch 6220: Training loss 0.0042, Validation loss 16.9770, learning rate: 0.00059\n",
            "prediction loss: 0.2614, entropy regularization 0.0711\n",
            "Epoch 6225: Training loss 0.0024, Validation loss 16.9801, learning rate: 0.00058\n",
            "prediction loss: 0.2648, entropy regularization 0.0666\n",
            "Epoch 6230: Training loss 0.0013, Validation loss 17.0116, learning rate: 0.00056\n",
            "prediction loss: 0.2524, entropy regularization 0.0654\n",
            "Epoch 6235: Training loss 0.0007, Validation loss 17.0190, learning rate: 0.00054\n",
            "prediction loss: 0.2592, entropy regularization 0.0704\n",
            "Epoch 6240: Training loss 0.0004, Validation loss 17.0103, learning rate: 0.00053\n",
            "prediction loss: 0.2639, entropy regularization 0.0662\n",
            "Epoch 6245: Training loss 0.0006, Validation loss 17.0223, learning rate: 0.00051\n",
            "prediction loss: 0.2570, entropy regularization 0.0704\n",
            "Epoch 6250: Training loss 0.0005, Validation loss 17.0360, learning rate: 0.00050\n",
            "prediction loss: 0.2590, entropy regularization 0.0723\n",
            "Epoch 6255: Training loss 0.0005, Validation loss 17.0164, learning rate: 0.00048\n",
            "prediction loss: 0.2717, entropy regularization 0.0642\n",
            "Epoch 6260: Training loss 0.0003, Validation loss 17.0034, learning rate: 0.00047\n",
            "prediction loss: 0.2609, entropy regularization 0.0646\n",
            "Epoch 6265: Training loss 0.0004, Validation loss 17.0200, learning rate: 0.00045\n",
            "prediction loss: 0.2632, entropy regularization 0.0590\n",
            "Epoch 6270: Training loss 0.0003, Validation loss 17.0127, learning rate: 0.00043\n",
            "prediction loss: 0.2588, entropy regularization 0.0681\n",
            "Epoch 6275: Training loss 0.0002, Validation loss 17.0077, learning rate: 0.00042\n",
            "prediction loss: 0.2528, entropy regularization 0.0712\n",
            "Epoch 6280: Training loss 0.0003, Validation loss 17.0210, learning rate: 0.00040\n",
            "prediction loss: 0.2498, entropy regularization 0.0680\n",
            "Epoch 6285: Training loss 0.0002, Validation loss 17.0039, learning rate: 0.00039\n",
            "prediction loss: 0.2608, entropy regularization 0.0700\n",
            "Epoch 6290: Training loss 0.0001, Validation loss 17.0082, learning rate: 0.00037\n",
            "prediction loss: 0.2473, entropy regularization 0.0709\n",
            "Epoch 6295: Training loss 0.0002, Validation loss 17.0010, learning rate: 0.00036\n",
            "prediction loss: 0.2473, entropy regularization 0.0747\n",
            "Epoch 6300: Training loss 0.0002, Validation loss 17.0044, learning rate: 0.00034\n",
            "prediction loss: 0.2512, entropy regularization 0.0697\n",
            "Epoch 6305: Training loss 0.0001, Validation loss 17.0007, learning rate: 0.00033\n",
            "prediction loss: 0.2699, entropy regularization 0.0743\n",
            "Epoch 6310: Training loss 0.0001, Validation loss 17.0039, learning rate: 0.00031\n",
            "prediction loss: 0.2739, entropy regularization 0.0642\n",
            "Epoch 6315: Training loss 0.0001, Validation loss 16.9980, learning rate: 0.00030\n",
            "prediction loss: 0.2626, entropy regularization 0.0711\n",
            "Epoch 6320: Training loss 0.0001, Validation loss 17.0066, learning rate: 0.00028\n",
            "prediction loss: 0.2662, entropy regularization 0.0656\n",
            "Epoch 6325: Training loss 0.0001, Validation loss 17.0043, learning rate: 0.00027\n",
            "prediction loss: 0.2767, entropy regularization 0.0673\n",
            "Epoch 6330: Training loss 0.0001, Validation loss 17.0017, learning rate: 0.00026\n",
            "prediction loss: 0.2515, entropy regularization 0.0707\n",
            "Epoch 6335: Training loss 0.0001, Validation loss 16.9994, learning rate: 0.00024\n",
            "prediction loss: 0.2618, entropy regularization 0.0628\n",
            "Epoch 6340: Training loss 0.0001, Validation loss 16.9962, learning rate: 0.00023\n",
            "prediction loss: 0.2457, entropy regularization 0.0726\n",
            "Epoch 6345: Training loss 0.0001, Validation loss 17.0000, learning rate: 0.00022\n",
            "prediction loss: 0.2675, entropy regularization 0.0697\n",
            "Epoch 6350: Training loss 0.0001, Validation loss 16.9987, learning rate: 0.00020\n",
            "prediction loss: 0.2633, entropy regularization 0.0695\n",
            "Epoch 6355: Training loss 0.0000, Validation loss 17.0018, learning rate: 0.00019\n",
            "prediction loss: 0.2751, entropy regularization 0.0662\n",
            "Epoch 6360: Training loss 0.0001, Validation loss 16.9963, learning rate: 0.00018\n",
            "prediction loss: 0.2609, entropy regularization 0.0741\n",
            "Epoch 6365: Training loss 0.0000, Validation loss 16.9992, learning rate: 0.00017\n",
            "prediction loss: 0.2699, entropy regularization 0.0657\n",
            "Epoch 6370: Training loss 0.0000, Validation loss 17.0011, learning rate: 0.00016\n",
            "prediction loss: 0.2699, entropy regularization 0.0661\n",
            "Epoch 6375: Training loss 0.0000, Validation loss 16.9964, learning rate: 0.00014\n",
            "prediction loss: 0.2638, entropy regularization 0.0705\n",
            "Epoch 6380: Training loss 0.0000, Validation loss 16.9960, learning rate: 0.00013\n",
            "prediction loss: 0.2691, entropy regularization 0.0685\n",
            "Epoch 6385: Training loss 0.0000, Validation loss 16.9925, learning rate: 0.00012\n",
            "prediction loss: 0.2669, entropy regularization 0.0694\n",
            "Epoch 6390: Training loss 0.0000, Validation loss 16.9955, learning rate: 0.00011\n",
            "prediction loss: 0.2574, entropy regularization 0.0677\n",
            "Epoch 6395: Training loss 0.0000, Validation loss 16.9981, learning rate: 0.00010\n",
            "prediction loss: 0.2420, entropy regularization 0.0695\n",
            "Epoch 6400: Training loss 0.0000, Validation loss 16.9942, learning rate: 0.00009\n",
            "prediction loss: 0.2544, entropy regularization 0.0653\n",
            "Epoch 6405: Training loss 0.0000, Validation loss 16.9938, learning rate: 0.00008\n",
            "prediction loss: 0.2634, entropy regularization 0.0715\n",
            "Epoch 6410: Training loss 0.0000, Validation loss 16.9929, learning rate: 0.00008\n",
            "prediction loss: 0.2535, entropy regularization 0.0734\n",
            "Epoch 6415: Training loss 0.0000, Validation loss 16.9948, learning rate: 0.00007\n",
            "prediction loss: 0.2576, entropy regularization 0.0619\n",
            "Epoch 6420: Training loss 0.0000, Validation loss 16.9950, learning rate: 0.00006\n",
            "prediction loss: 0.2630, entropy regularization 0.0649\n",
            "Epoch 6425: Training loss 0.0000, Validation loss 16.9946, learning rate: 0.00005\n",
            "prediction loss: 0.2678, entropy regularization 0.0635\n",
            "Epoch 6430: Training loss 0.0000, Validation loss 16.9938, learning rate: 0.00005\n",
            "prediction loss: 0.2517, entropy regularization 0.0722\n",
            "Epoch 6435: Training loss 0.0000, Validation loss 16.9933, learning rate: 0.00004\n",
            "prediction loss: 0.2754, entropy regularization 0.0714\n",
            "Epoch 6440: Training loss 0.0000, Validation loss 16.9938, learning rate: 0.00003\n",
            "prediction loss: 0.2647, entropy regularization 0.0792\n",
            "Epoch 6445: Training loss 0.0000, Validation loss 16.9935, learning rate: 0.00003\n",
            "prediction loss: 0.2523, entropy regularization 0.0676\n",
            "Epoch 6450: Training loss 0.0000, Validation loss 16.9935, learning rate: 0.00002\n",
            "prediction loss: 0.2550, entropy regularization 0.0689\n",
            "Epoch 6455: Training loss 0.0000, Validation loss 16.9939, learning rate: 0.00002\n",
            "prediction loss: 0.2649, entropy regularization 0.0660\n",
            "Epoch 6460: Training loss 0.0000, Validation loss 16.9934, learning rate: 0.00001\n",
            "prediction loss: 0.2567, entropy regularization 0.0692\n",
            "Epoch 6465: Training loss 0.0000, Validation loss 16.9939, learning rate: 0.00001\n",
            "prediction loss: 0.2633, entropy regularization 0.0712\n",
            "Epoch 6470: Training loss 0.0000, Validation loss 16.9932, learning rate: 0.00001\n",
            "prediction loss: 0.2585, entropy regularization 0.0681\n",
            "Epoch 6475: Training loss 0.0000, Validation loss 16.9933, learning rate: 0.00001\n",
            "prediction loss: 0.2538, entropy regularization 0.0708\n",
            "Epoch 6480: Training loss 0.0000, Validation loss 16.9934, learning rate: 0.00000\n",
            "prediction loss: 0.2609, entropy regularization 0.0665\n",
            "Epoch 6485: Training loss 0.0000, Validation loss 16.9933, learning rate: 0.00000\n",
            "prediction loss: 0.2688, entropy regularization 0.0675\n",
            "Epoch 6490: Training loss 0.0000, Validation loss 16.9933, learning rate: 0.00000\n",
            "prediction loss: 0.2657, entropy regularization 0.0667\n",
            "Epoch 6495: Training loss 0.0000, Validation loss 16.9933, learning rate: 0.00000\n",
            "prediction loss: 0.2740, entropy regularization 0.0725\n",
            "Epoch 6500: Training loss 2.1316, Validation loss 14.9826, learning rate: 0.00100\n",
            "prediction loss: 0.2683, entropy regularization 0.0695\n",
            "Epoch 6505: Training loss 2.9389, Validation loss 17.7743, learning rate: 0.00100\n",
            "prediction loss: 0.2645, entropy regularization 0.2393\n",
            "Epoch 6510: Training loss 1.7093, Validation loss 17.3474, learning rate: 0.00100\n",
            "prediction loss: 0.2816, entropy regularization 0.1814\n",
            "Epoch 6515: Training loss 1.3552, Validation loss 17.5181, learning rate: 0.00100\n",
            "prediction loss: 0.2744, entropy regularization 0.1637\n",
            "Epoch 6520: Training loss 1.0140, Validation loss 17.3955, learning rate: 0.00100\n",
            "prediction loss: 0.2559, entropy regularization 0.1563\n",
            "Epoch 6525: Training loss 0.7879, Validation loss 17.8525, learning rate: 0.00099\n",
            "prediction loss: 0.2514, entropy regularization 0.1587\n",
            "Epoch 6530: Training loss 0.7879, Validation loss 17.6052, learning rate: 0.00099\n",
            "prediction loss: 0.2519, entropy regularization 0.1442\n",
            "Epoch 6535: Training loss 0.5922, Validation loss 17.6155, learning rate: 0.00099\n",
            "prediction loss: 0.2648, entropy regularization 0.1304\n",
            "Epoch 6540: Training loss 0.5216, Validation loss 17.8383, learning rate: 0.00098\n",
            "prediction loss: 0.2603, entropy regularization 0.1224\n",
            "Epoch 6545: Training loss 0.5482, Validation loss 18.2177, learning rate: 0.00098\n",
            "prediction loss: 0.2640, entropy regularization 0.1209\n",
            "Epoch 6550: Training loss 0.5048, Validation loss 17.7904, learning rate: 0.00097\n",
            "prediction loss: 0.2698, entropy regularization 0.1110\n",
            "Epoch 6555: Training loss 0.3484, Validation loss 17.8517, learning rate: 0.00097\n",
            "prediction loss: 0.2659, entropy regularization 0.1342\n",
            "Epoch 6560: Training loss 0.2780, Validation loss 18.3486, learning rate: 0.00096\n",
            "prediction loss: 0.2599, entropy regularization 0.1257\n",
            "Epoch 6565: Training loss 0.3275, Validation loss 18.4703, learning rate: 0.00096\n",
            "prediction loss: 0.2623, entropy regularization 0.1145\n",
            "Epoch 6570: Training loss 0.3133, Validation loss 18.6849, learning rate: 0.00095\n",
            "prediction loss: 0.2760, entropy regularization 0.1188\n",
            "Epoch 6575: Training loss 0.2794, Validation loss 18.1450, learning rate: 0.00094\n",
            "prediction loss: 0.2697, entropy regularization 0.1121\n",
            "Epoch 6580: Training loss 0.2203, Validation loss 18.7072, learning rate: 0.00094\n",
            "prediction loss: 0.2562, entropy regularization 0.1206\n",
            "Epoch 6585: Training loss 0.2107, Validation loss 18.6175, learning rate: 0.00093\n",
            "prediction loss: 0.2690, entropy regularization 0.1150\n",
            "Epoch 6590: Training loss 0.1920, Validation loss 19.1827, learning rate: 0.00092\n",
            "prediction loss: 0.2538, entropy regularization 0.1209\n",
            "Epoch 6595: Training loss 0.2005, Validation loss 18.9154, learning rate: 0.00091\n",
            "prediction loss: 0.2406, entropy regularization 0.1252\n",
            "Epoch 6600: Training loss 0.1485, Validation loss 18.7457, learning rate: 0.00090\n",
            "prediction loss: 0.2690, entropy regularization 0.1164\n",
            "Epoch 6605: Training loss 0.1341, Validation loss 18.5694, learning rate: 0.00089\n",
            "prediction loss: 0.2689, entropy regularization 0.1142\n",
            "Epoch 6610: Training loss 0.1522, Validation loss 18.8450, learning rate: 0.00088\n",
            "prediction loss: 0.2582, entropy regularization 0.1115\n",
            "Epoch 6615: Training loss 0.1137, Validation loss 19.1220, learning rate: 0.00087\n",
            "prediction loss: 0.2634, entropy regularization 0.1131\n",
            "Epoch 6620: Training loss 0.1154, Validation loss 18.6800, learning rate: 0.00086\n",
            "prediction loss: 0.2640, entropy regularization 0.1154\n",
            "Epoch 6625: Training loss 0.0842, Validation loss 18.7286, learning rate: 0.00085\n",
            "prediction loss: 0.2781, entropy regularization 0.1137\n",
            "Epoch 6630: Training loss 0.1353, Validation loss 18.9911, learning rate: 0.00084\n",
            "prediction loss: 0.2517, entropy regularization 0.1093\n",
            "Epoch 6635: Training loss 0.1506, Validation loss 19.1658, learning rate: 0.00083\n",
            "prediction loss: 0.2557, entropy regularization 0.1169\n",
            "Epoch 6640: Training loss 0.0892, Validation loss 18.8656, learning rate: 0.00082\n",
            "prediction loss: 0.2650, entropy regularization 0.1081\n",
            "Epoch 6645: Training loss 0.0758, Validation loss 18.8741, learning rate: 0.00080\n",
            "prediction loss: 0.2550, entropy regularization 0.1114\n",
            "Epoch 6650: Training loss 0.0922, Validation loss 18.5578, learning rate: 0.00079\n",
            "prediction loss: 0.2544, entropy regularization 0.1082\n",
            "Epoch 6655: Training loss 0.0830, Validation loss 18.5680, learning rate: 0.00078\n",
            "prediction loss: 0.2517, entropy regularization 0.1185\n",
            "Epoch 6660: Training loss 0.0859, Validation loss 18.5672, learning rate: 0.00077\n",
            "prediction loss: 0.2554, entropy regularization 0.1145\n",
            "Epoch 6665: Training loss 0.0432, Validation loss 18.7882, learning rate: 0.00075\n",
            "prediction loss: 0.2720, entropy regularization 0.1098\n",
            "Epoch 6670: Training loss 0.0452, Validation loss 18.7430, learning rate: 0.00074\n",
            "prediction loss: 0.2582, entropy regularization 0.1146\n",
            "Epoch 6675: Training loss 0.0553, Validation loss 18.7452, learning rate: 0.00072\n",
            "prediction loss: 0.2674, entropy regularization 0.1144\n",
            "Epoch 6680: Training loss 0.0290, Validation loss 18.6933, learning rate: 0.00071\n",
            "prediction loss: 0.2554, entropy regularization 0.1127\n",
            "Epoch 6685: Training loss 0.0277, Validation loss 18.8503, learning rate: 0.00070\n",
            "prediction loss: 0.2523, entropy regularization 0.1218\n",
            "Epoch 6690: Training loss 0.0271, Validation loss 18.8118, learning rate: 0.00068\n",
            "prediction loss: 0.2720, entropy regularization 0.1163\n",
            "Epoch 6695: Training loss 0.0292, Validation loss 18.8305, learning rate: 0.00067\n",
            "prediction loss: 0.2573, entropy regularization 0.1240\n",
            "Epoch 6700: Training loss 0.0324, Validation loss 18.8466, learning rate: 0.00065\n",
            "prediction loss: 0.2469, entropy regularization 0.1137\n",
            "Epoch 6705: Training loss 0.0183, Validation loss 18.7302, learning rate: 0.00064\n",
            "prediction loss: 0.2650, entropy regularization 0.1087\n",
            "Epoch 6710: Training loss 0.0203, Validation loss 18.7483, learning rate: 0.00062\n",
            "prediction loss: 0.2596, entropy regularization 0.1091\n",
            "Epoch 6715: Training loss 0.0218, Validation loss 18.9341, learning rate: 0.00061\n",
            "prediction loss: 0.2681, entropy regularization 0.1149\n",
            "Epoch 6720: Training loss 0.0107, Validation loss 18.8364, learning rate: 0.00059\n",
            "prediction loss: 0.2627, entropy regularization 0.1159\n",
            "Epoch 6725: Training loss 0.0106, Validation loss 18.7632, learning rate: 0.00058\n",
            "prediction loss: 0.2809, entropy regularization 0.1211\n",
            "Epoch 6730: Training loss 0.0179, Validation loss 18.8741, learning rate: 0.00056\n",
            "prediction loss: 0.2625, entropy regularization 0.1232\n",
            "Epoch 6735: Training loss 0.0094, Validation loss 18.7648, learning rate: 0.00054\n",
            "prediction loss: 0.2495, entropy regularization 0.1064\n",
            "Epoch 6740: Training loss 0.0108, Validation loss 18.8176, learning rate: 0.00053\n",
            "prediction loss: 0.2635, entropy regularization 0.1119\n",
            "Epoch 6745: Training loss 0.0084, Validation loss 18.8043, learning rate: 0.00051\n",
            "prediction loss: 0.2713, entropy regularization 0.1047\n",
            "Epoch 6750: Training loss 0.0151, Validation loss 18.9021, learning rate: 0.00050\n",
            "prediction loss: 0.2589, entropy regularization 0.1091\n",
            "Epoch 6755: Training loss 0.0104, Validation loss 18.8816, learning rate: 0.00048\n",
            "prediction loss: 0.2645, entropy regularization 0.1104\n",
            "Epoch 6760: Training loss 0.0063, Validation loss 18.8245, learning rate: 0.00047\n",
            "prediction loss: 0.2704, entropy regularization 0.1092\n",
            "Epoch 6765: Training loss 0.0085, Validation loss 18.8130, learning rate: 0.00045\n",
            "prediction loss: 0.2581, entropy regularization 0.1133\n",
            "Epoch 6770: Training loss 0.0055, Validation loss 18.8115, learning rate: 0.00043\n",
            "prediction loss: 0.2600, entropy regularization 0.1109\n",
            "Epoch 6775: Training loss 0.0039, Validation loss 18.7970, learning rate: 0.00042\n",
            "prediction loss: 0.2671, entropy regularization 0.1043\n",
            "Epoch 6780: Training loss 0.0035, Validation loss 18.7713, learning rate: 0.00040\n",
            "prediction loss: 0.2584, entropy regularization 0.1090\n",
            "Epoch 6785: Training loss 0.0027, Validation loss 18.7948, learning rate: 0.00039\n",
            "prediction loss: 0.2699, entropy regularization 0.1028\n",
            "Epoch 6790: Training loss 0.0040, Validation loss 18.7870, learning rate: 0.00037\n",
            "prediction loss: 0.2752, entropy regularization 0.1125\n",
            "Epoch 6795: Training loss 0.0057, Validation loss 18.7745, learning rate: 0.00036\n",
            "prediction loss: 0.2671, entropy regularization 0.1183\n",
            "Epoch 6800: Training loss 0.0028, Validation loss 18.7664, learning rate: 0.00034\n",
            "prediction loss: 0.2559, entropy regularization 0.1158\n",
            "Epoch 6805: Training loss 0.0036, Validation loss 18.8098, learning rate: 0.00033\n",
            "prediction loss: 0.2497, entropy regularization 0.1160\n",
            "Epoch 6810: Training loss 0.0027, Validation loss 18.8107, learning rate: 0.00031\n",
            "prediction loss: 0.2534, entropy regularization 0.1028\n",
            "Epoch 6815: Training loss 0.0012, Validation loss 18.8079, learning rate: 0.00030\n",
            "prediction loss: 0.2694, entropy regularization 0.1143\n",
            "Epoch 6820: Training loss 0.0025, Validation loss 18.7987, learning rate: 0.00028\n",
            "prediction loss: 0.2554, entropy regularization 0.1059\n",
            "Epoch 6825: Training loss 0.0014, Validation loss 18.7966, learning rate: 0.00027\n",
            "prediction loss: 0.2641, entropy regularization 0.1132\n",
            "Epoch 6830: Training loss 0.0016, Validation loss 18.7862, learning rate: 0.00026\n",
            "prediction loss: 0.2491, entropy regularization 0.1147\n",
            "Epoch 6835: Training loss 0.0007, Validation loss 18.8060, learning rate: 0.00024\n",
            "prediction loss: 0.2522, entropy regularization 0.1071\n",
            "Epoch 6840: Training loss 0.0008, Validation loss 18.7874, learning rate: 0.00023\n",
            "prediction loss: 0.2673, entropy regularization 0.1043\n",
            "Epoch 6845: Training loss 0.0007, Validation loss 18.8124, learning rate: 0.00022\n",
            "prediction loss: 0.2622, entropy regularization 0.1066\n",
            "Epoch 6850: Training loss 0.0007, Validation loss 18.7976, learning rate: 0.00020\n",
            "prediction loss: 0.2618, entropy regularization 0.1198\n",
            "Epoch 6855: Training loss 0.0008, Validation loss 18.8153, learning rate: 0.00019\n",
            "prediction loss: 0.2524, entropy regularization 0.1158\n",
            "Epoch 6860: Training loss 0.0005, Validation loss 18.8114, learning rate: 0.00018\n",
            "prediction loss: 0.2643, entropy regularization 0.1110\n",
            "Epoch 6865: Training loss 0.0004, Validation loss 18.8200, learning rate: 0.00017\n",
            "prediction loss: 0.2505, entropy regularization 0.1223\n",
            "Epoch 6870: Training loss 0.0004, Validation loss 18.7988, learning rate: 0.00016\n",
            "prediction loss: 0.2491, entropy regularization 0.1169\n",
            "Epoch 6875: Training loss 0.0005, Validation loss 18.8260, learning rate: 0.00014\n",
            "prediction loss: 0.2555, entropy regularization 0.1079\n",
            "Epoch 6880: Training loss 0.0003, Validation loss 18.8060, learning rate: 0.00013\n",
            "prediction loss: 0.2601, entropy regularization 0.1082\n",
            "Epoch 6885: Training loss 0.0003, Validation loss 18.8202, learning rate: 0.00012\n",
            "prediction loss: 0.2500, entropy regularization 0.1096\n",
            "Epoch 6890: Training loss 0.0003, Validation loss 18.8147, learning rate: 0.00011\n",
            "prediction loss: 0.2553, entropy regularization 0.1107\n",
            "Epoch 6895: Training loss 0.0003, Validation loss 18.8159, learning rate: 0.00010\n",
            "prediction loss: 0.2658, entropy regularization 0.1054\n",
            "Epoch 6900: Training loss 0.0003, Validation loss 18.8211, learning rate: 0.00009\n",
            "prediction loss: 0.2595, entropy regularization 0.1082\n",
            "Epoch 6905: Training loss 0.0002, Validation loss 18.8208, learning rate: 0.00008\n",
            "prediction loss: 0.2702, entropy regularization 0.1081\n",
            "Epoch 6910: Training loss 0.0003, Validation loss 18.8225, learning rate: 0.00008\n",
            "prediction loss: 0.2579, entropy regularization 0.1081\n",
            "Epoch 6915: Training loss 0.0002, Validation loss 18.8209, learning rate: 0.00007\n",
            "prediction loss: 0.2550, entropy regularization 0.1065\n",
            "Epoch 6920: Training loss 0.0003, Validation loss 18.8191, learning rate: 0.00006\n",
            "prediction loss: 0.2610, entropy regularization 0.1077\n",
            "Epoch 6925: Training loss 0.0002, Validation loss 18.8193, learning rate: 0.00005\n",
            "prediction loss: 0.2569, entropy regularization 0.1022\n",
            "Epoch 6930: Training loss 0.0002, Validation loss 18.8203, learning rate: 0.00005\n",
            "prediction loss: 0.2669, entropy regularization 0.1079\n",
            "Epoch 6935: Training loss 0.0002, Validation loss 18.8219, learning rate: 0.00004\n",
            "prediction loss: 0.2652, entropy regularization 0.1099\n",
            "Epoch 6940: Training loss 0.0002, Validation loss 18.8241, learning rate: 0.00003\n",
            "prediction loss: 0.2479, entropy regularization 0.1226\n",
            "Epoch 6945: Training loss 0.0002, Validation loss 18.8226, learning rate: 0.00003\n",
            "prediction loss: 0.2598, entropy regularization 0.1071\n",
            "Epoch 6950: Training loss 0.0002, Validation loss 18.8178, learning rate: 0.00002\n",
            "prediction loss: 0.2501, entropy regularization 0.1055\n",
            "Epoch 6955: Training loss 0.0002, Validation loss 18.8217, learning rate: 0.00002\n",
            "prediction loss: 0.2606, entropy regularization 0.1170\n",
            "Epoch 6960: Training loss 0.0002, Validation loss 18.8225, learning rate: 0.00001\n",
            "prediction loss: 0.2707, entropy regularization 0.1084\n",
            "Epoch 6965: Training loss 0.0002, Validation loss 18.8205, learning rate: 0.00001\n",
            "prediction loss: 0.2524, entropy regularization 0.1136\n",
            "Epoch 6970: Training loss 0.0002, Validation loss 18.8221, learning rate: 0.00001\n",
            "prediction loss: 0.2623, entropy regularization 0.1090\n",
            "Epoch 6975: Training loss 0.0002, Validation loss 18.8214, learning rate: 0.00001\n",
            "prediction loss: 0.2680, entropy regularization 0.1084\n",
            "Epoch 6980: Training loss 0.0002, Validation loss 18.8218, learning rate: 0.00000\n",
            "prediction loss: 0.2636, entropy regularization 0.1135\n",
            "Epoch 6985: Training loss 0.0002, Validation loss 18.8216, learning rate: 0.00000\n",
            "prediction loss: 0.2520, entropy regularization 0.1060\n",
            "Epoch 6990: Training loss 0.0002, Validation loss 18.8219, learning rate: 0.00000\n",
            "prediction loss: 0.2598, entropy regularization 0.1154\n",
            "Epoch 6995: Training loss 0.0002, Validation loss 18.8219, learning rate: 0.00000\n",
            "prediction loss: 0.2603, entropy regularization 0.1153\n",
            "Epoch 7000: Training loss 2.8519, Validation loss 16.4952, learning rate: 0.00100\n",
            "prediction loss: 0.2736, entropy regularization 0.1111\n",
            "Epoch 7005: Training loss 1.7945, Validation loss 17.9739, learning rate: 0.00100\n",
            "prediction loss: 0.2631, entropy regularization 0.0438\n",
            "Epoch 7010: Training loss 1.3848, Validation loss 17.2913, learning rate: 0.00100\n",
            "prediction loss: 0.2491, entropy regularization 0.0392\n",
            "Epoch 7015: Training loss 0.8109, Validation loss 17.6988, learning rate: 0.00100\n",
            "prediction loss: 0.2731, entropy regularization 0.0414\n",
            "Epoch 7020: Training loss 0.8499, Validation loss 18.7211, learning rate: 0.00100\n",
            "prediction loss: 0.2731, entropy regularization 0.0330\n",
            "Epoch 7025: Training loss 0.6997, Validation loss 17.7923, learning rate: 0.00099\n",
            "prediction loss: 0.2584, entropy regularization 0.0335\n",
            "Epoch 7030: Training loss 0.4348, Validation loss 18.4670, learning rate: 0.00099\n",
            "prediction loss: 0.2694, entropy regularization 0.0334\n",
            "Epoch 7035: Training loss 0.3571, Validation loss 19.1886, learning rate: 0.00099\n",
            "prediction loss: 0.2516, entropy regularization 0.0366\n",
            "Epoch 7040: Training loss 0.2900, Validation loss 18.4068, learning rate: 0.00098\n",
            "prediction loss: 0.2750, entropy regularization 0.0353\n",
            "Epoch 7045: Training loss 0.3212, Validation loss 18.8130, learning rate: 0.00098\n",
            "prediction loss: 0.2627, entropy regularization 0.0374\n",
            "Epoch 7050: Training loss 0.2724, Validation loss 18.4730, learning rate: 0.00097\n",
            "prediction loss: 0.2633, entropy regularization 0.0322\n",
            "Epoch 7055: Training loss 0.2453, Validation loss 18.7031, learning rate: 0.00097\n",
            "prediction loss: 0.2694, entropy regularization 0.0365\n",
            "Epoch 7060: Training loss 0.2180, Validation loss 18.6652, learning rate: 0.00096\n",
            "prediction loss: 0.2512, entropy regularization 0.0286\n",
            "Epoch 7065: Training loss 0.2227, Validation loss 18.5646, learning rate: 0.00096\n",
            "prediction loss: 0.2861, entropy regularization 0.0301\n",
            "Epoch 7070: Training loss 0.1389, Validation loss 18.7276, learning rate: 0.00095\n",
            "prediction loss: 0.2692, entropy regularization 0.0296\n",
            "Epoch 7075: Training loss 0.1272, Validation loss 18.6800, learning rate: 0.00094\n",
            "prediction loss: 0.2679, entropy regularization 0.0357\n",
            "Epoch 7080: Training loss 0.0910, Validation loss 18.3549, learning rate: 0.00094\n",
            "prediction loss: 0.2576, entropy regularization 0.0318\n",
            "Epoch 7085: Training loss 0.1475, Validation loss 18.4715, learning rate: 0.00093\n",
            "prediction loss: 0.2617, entropy regularization 0.0368\n",
            "Epoch 7090: Training loss 0.1628, Validation loss 18.7022, learning rate: 0.00092\n",
            "prediction loss: 0.2484, entropy regularization 0.0339\n",
            "Epoch 7095: Training loss 0.0887, Validation loss 18.4660, learning rate: 0.00091\n",
            "prediction loss: 0.2667, entropy regularization 0.0303\n",
            "Epoch 7100: Training loss 0.0885, Validation loss 18.3756, learning rate: 0.00090\n",
            "prediction loss: 0.2526, entropy regularization 0.0339\n",
            "Epoch 7105: Training loss 0.0848, Validation loss 18.4568, learning rate: 0.00089\n",
            "prediction loss: 0.2614, entropy regularization 0.0348\n",
            "Epoch 7110: Training loss 0.0694, Validation loss 18.5303, learning rate: 0.00088\n",
            "prediction loss: 0.2772, entropy regularization 0.0320\n",
            "Epoch 7115: Training loss 0.0567, Validation loss 18.5001, learning rate: 0.00087\n",
            "prediction loss: 0.2599, entropy regularization 0.0434\n",
            "Epoch 7120: Training loss 0.0328, Validation loss 18.3315, learning rate: 0.00086\n",
            "prediction loss: 0.2741, entropy regularization 0.0266\n",
            "Epoch 7125: Training loss 0.0344, Validation loss 18.5111, learning rate: 0.00085\n",
            "prediction loss: 0.2519, entropy regularization 0.0373\n",
            "Epoch 7130: Training loss 0.0235, Validation loss 18.3925, learning rate: 0.00084\n",
            "prediction loss: 0.2490, entropy regularization 0.0369\n",
            "Epoch 7135: Training loss 0.0555, Validation loss 18.3783, learning rate: 0.00083\n",
            "prediction loss: 0.2583, entropy regularization 0.0373\n",
            "Epoch 7140: Training loss 0.0558, Validation loss 18.3660, learning rate: 0.00082\n",
            "prediction loss: 0.2616, entropy regularization 0.0332\n",
            "Epoch 7145: Training loss 0.0479, Validation loss 18.1615, learning rate: 0.00080\n",
            "prediction loss: 0.2628, entropy regularization 0.0297\n",
            "Epoch 7150: Training loss 0.0371, Validation loss 18.5372, learning rate: 0.00079\n",
            "prediction loss: 0.2649, entropy regularization 0.0344\n",
            "Epoch 7155: Training loss 0.0673, Validation loss 18.4253, learning rate: 0.00078\n",
            "prediction loss: 0.2647, entropy regularization 0.0311\n",
            "Epoch 7160: Training loss 0.0399, Validation loss 18.4137, learning rate: 0.00077\n",
            "prediction loss: 0.2721, entropy regularization 0.0351\n",
            "Epoch 7165: Training loss 0.0336, Validation loss 18.4614, learning rate: 0.00075\n",
            "prediction loss: 0.2613, entropy regularization 0.0277\n",
            "Epoch 7170: Training loss 0.0216, Validation loss 18.3037, learning rate: 0.00074\n",
            "prediction loss: 0.2530, entropy regularization 0.0327\n",
            "Epoch 7175: Training loss 0.0185, Validation loss 18.2887, learning rate: 0.00072\n",
            "prediction loss: 0.2469, entropy regularization 0.0349\n",
            "Epoch 7180: Training loss 0.0184, Validation loss 18.3658, learning rate: 0.00071\n",
            "prediction loss: 0.2687, entropy regularization 0.0307\n",
            "Epoch 7185: Training loss 0.0163, Validation loss 18.2948, learning rate: 0.00070\n",
            "prediction loss: 0.2522, entropy regularization 0.0329\n",
            "Epoch 7190: Training loss 0.0137, Validation loss 18.2756, learning rate: 0.00068\n",
            "prediction loss: 0.2488, entropy regularization 0.0349\n",
            "Epoch 7195: Training loss 0.0081, Validation loss 18.4036, learning rate: 0.00067\n",
            "prediction loss: 0.2624, entropy regularization 0.0305\n",
            "Epoch 7200: Training loss 0.0044, Validation loss 18.3161, learning rate: 0.00065\n",
            "prediction loss: 0.2658, entropy regularization 0.0362\n",
            "Epoch 7205: Training loss 0.0046, Validation loss 18.3247, learning rate: 0.00064\n",
            "prediction loss: 0.2604, entropy regularization 0.0457\n",
            "Epoch 7210: Training loss 0.0052, Validation loss 18.2685, learning rate: 0.00062\n",
            "prediction loss: 0.2659, entropy regularization 0.0420\n",
            "Epoch 7215: Training loss 0.0072, Validation loss 18.3913, learning rate: 0.00061\n",
            "prediction loss: 0.2542, entropy regularization 0.0341\n",
            "Epoch 7220: Training loss 0.0093, Validation loss 18.3499, learning rate: 0.00059\n",
            "prediction loss: 0.2585, entropy regularization 0.0335\n",
            "Epoch 7225: Training loss 0.0081, Validation loss 18.2722, learning rate: 0.00058\n",
            "prediction loss: 0.2718, entropy regularization 0.0363\n",
            "Epoch 7230: Training loss 0.0077, Validation loss 18.3382, learning rate: 0.00056\n",
            "prediction loss: 0.2575, entropy regularization 0.0355\n",
            "Epoch 7235: Training loss 0.0041, Validation loss 18.3235, learning rate: 0.00054\n",
            "prediction loss: 0.2639, entropy regularization 0.0335\n",
            "Epoch 7240: Training loss 0.0035, Validation loss 18.3746, learning rate: 0.00053\n",
            "prediction loss: 0.2470, entropy regularization 0.0344\n",
            "Epoch 7245: Training loss 0.0044, Validation loss 18.2937, learning rate: 0.00051\n",
            "prediction loss: 0.2733, entropy regularization 0.0291\n",
            "Epoch 7250: Training loss 0.0104, Validation loss 18.4074, learning rate: 0.00050\n",
            "prediction loss: 0.2726, entropy regularization 0.0282\n",
            "Epoch 7255: Training loss 0.0042, Validation loss 18.3383, learning rate: 0.00048\n",
            "prediction loss: 0.2565, entropy regularization 0.0303\n",
            "Epoch 7260: Training loss 0.0024, Validation loss 18.2964, learning rate: 0.00047\n",
            "prediction loss: 0.2704, entropy regularization 0.0317\n",
            "Epoch 7265: Training loss 0.0029, Validation loss 18.3378, learning rate: 0.00045\n",
            "prediction loss: 0.2756, entropy regularization 0.0296\n",
            "Epoch 7270: Training loss 0.0019, Validation loss 18.3032, learning rate: 0.00043\n",
            "prediction loss: 0.2587, entropy regularization 0.0376\n",
            "Epoch 7275: Training loss 0.0023, Validation loss 18.3235, learning rate: 0.00042\n",
            "prediction loss: 0.2565, entropy regularization 0.0310\n",
            "Epoch 7280: Training loss 0.0018, Validation loss 18.2962, learning rate: 0.00040\n",
            "prediction loss: 0.2623, entropy regularization 0.0253\n",
            "Epoch 7285: Training loss 0.0020, Validation loss 18.3070, learning rate: 0.00039\n",
            "prediction loss: 0.2611, entropy regularization 0.0439\n",
            "Epoch 7290: Training loss 0.0025, Validation loss 18.3525, learning rate: 0.00037\n",
            "prediction loss: 0.2523, entropy regularization 0.0361\n",
            "Epoch 7295: Training loss 0.0018, Validation loss 18.3169, learning rate: 0.00036\n",
            "prediction loss: 0.2502, entropy regularization 0.0337\n",
            "Epoch 7300: Training loss 0.0013, Validation loss 18.3090, learning rate: 0.00034\n",
            "prediction loss: 0.2676, entropy regularization 0.0439\n",
            "Epoch 7305: Training loss 0.0011, Validation loss 18.3243, learning rate: 0.00033\n",
            "prediction loss: 0.2853, entropy regularization 0.0348\n",
            "Epoch 7310: Training loss 0.0011, Validation loss 18.2875, learning rate: 0.00031\n",
            "prediction loss: 0.2701, entropy regularization 0.0361\n",
            "Epoch 7315: Training loss 0.0008, Validation loss 18.3004, learning rate: 0.00030\n",
            "prediction loss: 0.2636, entropy regularization 0.0274\n",
            "Epoch 7320: Training loss 0.0010, Validation loss 18.2870, learning rate: 0.00028\n",
            "prediction loss: 0.2613, entropy regularization 0.0385\n",
            "Epoch 7325: Training loss 0.0009, Validation loss 18.2969, learning rate: 0.00027\n",
            "prediction loss: 0.2647, entropy regularization 0.0271\n",
            "Epoch 7330: Training loss 0.0007, Validation loss 18.2924, learning rate: 0.00026\n",
            "prediction loss: 0.2562, entropy regularization 0.0251\n",
            "Epoch 7335: Training loss 0.0011, Validation loss 18.2991, learning rate: 0.00024\n",
            "prediction loss: 0.2659, entropy regularization 0.0280\n",
            "Epoch 7340: Training loss 0.0006, Validation loss 18.2732, learning rate: 0.00023\n",
            "prediction loss: 0.2731, entropy regularization 0.0404\n",
            "Epoch 7345: Training loss 0.0007, Validation loss 18.2767, learning rate: 0.00022\n",
            "prediction loss: 0.2626, entropy regularization 0.0314\n",
            "Epoch 7350: Training loss 0.0005, Validation loss 18.2950, learning rate: 0.00020\n",
            "prediction loss: 0.2600, entropy regularization 0.0361\n",
            "Epoch 7355: Training loss 0.0004, Validation loss 18.3002, learning rate: 0.00019\n",
            "prediction loss: 0.2789, entropy regularization 0.0305\n",
            "Epoch 7360: Training loss 0.0004, Validation loss 18.2959, learning rate: 0.00018\n",
            "prediction loss: 0.2425, entropy regularization 0.0365\n",
            "Epoch 7365: Training loss 0.0003, Validation loss 18.2820, learning rate: 0.00017\n",
            "prediction loss: 0.2434, entropy regularization 0.0357\n",
            "Epoch 7370: Training loss 0.0006, Validation loss 18.2916, learning rate: 0.00016\n",
            "prediction loss: 0.2618, entropy regularization 0.0283\n",
            "Epoch 7375: Training loss 0.0004, Validation loss 18.2786, learning rate: 0.00014\n",
            "prediction loss: 0.2602, entropy regularization 0.0410\n",
            "Epoch 7380: Training loss 0.0004, Validation loss 18.2964, learning rate: 0.00013\n",
            "prediction loss: 0.2632, entropy regularization 0.0314\n",
            "Epoch 7385: Training loss 0.0004, Validation loss 18.2975, learning rate: 0.00012\n",
            "prediction loss: 0.2732, entropy regularization 0.0322\n",
            "Epoch 7390: Training loss 0.0004, Validation loss 18.2848, learning rate: 0.00011\n",
            "prediction loss: 0.2629, entropy regularization 0.0334\n",
            "Epoch 7395: Training loss 0.0003, Validation loss 18.2865, learning rate: 0.00010\n",
            "prediction loss: 0.2535, entropy regularization 0.0349\n",
            "Epoch 7400: Training loss 0.0003, Validation loss 18.2852, learning rate: 0.00009\n",
            "prediction loss: 0.2577, entropy regularization 0.0365\n",
            "Epoch 7405: Training loss 0.0003, Validation loss 18.2914, learning rate: 0.00008\n",
            "prediction loss: 0.2641, entropy regularization 0.0354\n",
            "Epoch 7410: Training loss 0.0003, Validation loss 18.2860, learning rate: 0.00008\n",
            "prediction loss: 0.2695, entropy regularization 0.0281\n",
            "Epoch 7415: Training loss 0.0003, Validation loss 18.2814, learning rate: 0.00007\n",
            "prediction loss: 0.2632, entropy regularization 0.0357\n",
            "Epoch 7420: Training loss 0.0003, Validation loss 18.2943, learning rate: 0.00006\n",
            "prediction loss: 0.2723, entropy regularization 0.0372\n",
            "Epoch 7425: Training loss 0.0002, Validation loss 18.2872, learning rate: 0.00005\n",
            "prediction loss: 0.2594, entropy regularization 0.0337\n",
            "Epoch 7430: Training loss 0.0002, Validation loss 18.2875, learning rate: 0.00005\n",
            "prediction loss: 0.2612, entropy regularization 0.0469\n",
            "Epoch 7435: Training loss 0.0002, Validation loss 18.2840, learning rate: 0.00004\n",
            "prediction loss: 0.2647, entropy regularization 0.0379\n",
            "Epoch 7440: Training loss 0.0002, Validation loss 18.2859, learning rate: 0.00003\n",
            "prediction loss: 0.2701, entropy regularization 0.0353\n",
            "Epoch 7445: Training loss 0.0002, Validation loss 18.2884, learning rate: 0.00003\n",
            "prediction loss: 0.2560, entropy regularization 0.0292\n",
            "Epoch 7450: Training loss 0.0002, Validation loss 18.2849, learning rate: 0.00002\n",
            "prediction loss: 0.2675, entropy regularization 0.0336\n",
            "Epoch 7455: Training loss 0.0002, Validation loss 18.2873, learning rate: 0.00002\n",
            "prediction loss: 0.2662, entropy regularization 0.0304\n",
            "Epoch 7460: Training loss 0.0002, Validation loss 18.2869, learning rate: 0.00001\n",
            "prediction loss: 0.2612, entropy regularization 0.0334\n",
            "Epoch 7465: Training loss 0.0002, Validation loss 18.2866, learning rate: 0.00001\n",
            "prediction loss: 0.2418, entropy regularization 0.0387\n",
            "Epoch 7470: Training loss 0.0002, Validation loss 18.2879, learning rate: 0.00001\n",
            "prediction loss: 0.2671, entropy regularization 0.0309\n",
            "Epoch 7475: Training loss 0.0002, Validation loss 18.2871, learning rate: 0.00001\n",
            "prediction loss: 0.2627, entropy regularization 0.0311\n",
            "Epoch 7480: Training loss 0.0002, Validation loss 18.2865, learning rate: 0.00000\n",
            "prediction loss: 0.2614, entropy regularization 0.0330\n",
            "Epoch 7485: Training loss 0.0002, Validation loss 18.2864, learning rate: 0.00000\n",
            "prediction loss: 0.2688, entropy regularization 0.0357\n",
            "Epoch 7490: Training loss 0.0002, Validation loss 18.2864, learning rate: 0.00000\n",
            "prediction loss: 0.2603, entropy regularization 0.0338\n",
            "Epoch 7495: Training loss 0.0002, Validation loss 18.2865, learning rate: 0.00000\n",
            "prediction loss: 0.2671, entropy regularization 0.0312\n",
            "Epoch 7500: Training loss 2.4786, Validation loss 16.6231, learning rate: 0.00100\n",
            "prediction loss: 0.2673, entropy regularization 0.0377\n",
            "Epoch 7505: Training loss 1.1257, Validation loss 15.7214, learning rate: 0.00100\n",
            "prediction loss: 0.2744, entropy regularization 0.0354\n",
            "Epoch 7510: Training loss 0.9647, Validation loss 16.3954, learning rate: 0.00100\n",
            "prediction loss: 0.2563, entropy regularization 0.0327\n",
            "Epoch 7515: Training loss 0.7367, Validation loss 16.2554, learning rate: 0.00100\n",
            "prediction loss: 0.2713, entropy regularization 0.0397\n",
            "Epoch 7520: Training loss 0.4090, Validation loss 16.8230, learning rate: 0.00100\n",
            "prediction loss: 0.2560, entropy regularization 0.0375\n",
            "Epoch 7525: Training loss 0.2671, Validation loss 16.5853, learning rate: 0.00099\n",
            "prediction loss: 0.2670, entropy regularization 0.0414\n",
            "Epoch 7530: Training loss 0.2445, Validation loss 16.7702, learning rate: 0.00099\n",
            "prediction loss: 0.2682, entropy regularization 0.0329\n",
            "Epoch 7535: Training loss 0.1941, Validation loss 16.5308, learning rate: 0.00099\n",
            "prediction loss: 0.2499, entropy regularization 0.0457\n",
            "Epoch 7540: Training loss 0.1329, Validation loss 17.1000, learning rate: 0.00098\n",
            "prediction loss: 0.2598, entropy regularization 0.0411\n",
            "Epoch 7545: Training loss 0.2230, Validation loss 17.1989, learning rate: 0.00098\n",
            "prediction loss: 0.2679, entropy regularization 0.0340\n",
            "Epoch 7550: Training loss 0.1475, Validation loss 17.0412, learning rate: 0.00097\n",
            "prediction loss: 0.2589, entropy regularization 0.0353\n",
            "Epoch 7555: Training loss 0.0815, Validation loss 16.9203, learning rate: 0.00097\n",
            "prediction loss: 0.2649, entropy regularization 0.0339\n",
            "Epoch 7560: Training loss 0.1146, Validation loss 16.8941, learning rate: 0.00096\n",
            "prediction loss: 0.2630, entropy regularization 0.0379\n",
            "Epoch 7565: Training loss 0.0620, Validation loss 16.9184, learning rate: 0.00096\n",
            "prediction loss: 0.2680, entropy regularization 0.0371\n",
            "Epoch 7570: Training loss 0.0484, Validation loss 17.1653, learning rate: 0.00095\n",
            "prediction loss: 0.2655, entropy regularization 0.0374\n",
            "Epoch 7575: Training loss 0.0470, Validation loss 17.2267, learning rate: 0.00094\n",
            "prediction loss: 0.2563, entropy regularization 0.0415\n",
            "Epoch 7580: Training loss 0.0567, Validation loss 17.2131, learning rate: 0.00094\n",
            "prediction loss: 0.2565, entropy regularization 0.0359\n",
            "Epoch 7585: Training loss 0.0378, Validation loss 17.0955, learning rate: 0.00093\n",
            "prediction loss: 0.2594, entropy regularization 0.0396\n",
            "Epoch 7590: Training loss 0.0560, Validation loss 17.1557, learning rate: 0.00092\n",
            "prediction loss: 0.2621, entropy regularization 0.0376\n",
            "Epoch 7595: Training loss 0.0323, Validation loss 17.2572, learning rate: 0.00091\n",
            "prediction loss: 0.2562, entropy regularization 0.0366\n",
            "Epoch 7600: Training loss 0.0447, Validation loss 17.2318, learning rate: 0.00090\n",
            "prediction loss: 0.2634, entropy regularization 0.0359\n",
            "Epoch 7605: Training loss 0.0394, Validation loss 17.0376, learning rate: 0.00089\n",
            "prediction loss: 0.2578, entropy regularization 0.0371\n",
            "Epoch 7610: Training loss 0.0197, Validation loss 17.0397, learning rate: 0.00088\n",
            "prediction loss: 0.2499, entropy regularization 0.0384\n",
            "Epoch 7615: Training loss 0.0468, Validation loss 17.2091, learning rate: 0.00087\n",
            "prediction loss: 0.2581, entropy regularization 0.0408\n",
            "Epoch 7620: Training loss 0.0176, Validation loss 17.0992, learning rate: 0.00086\n",
            "prediction loss: 0.2630, entropy regularization 0.0352\n",
            "Epoch 7625: Training loss 0.0102, Validation loss 17.1080, learning rate: 0.00085\n",
            "prediction loss: 0.2563, entropy regularization 0.0341\n",
            "Epoch 7630: Training loss 0.0092, Validation loss 17.2039, learning rate: 0.00084\n",
            "prediction loss: 0.2587, entropy regularization 0.0323\n",
            "Epoch 7635: Training loss 0.0103, Validation loss 17.1406, learning rate: 0.00083\n",
            "prediction loss: 0.2676, entropy regularization 0.0411\n",
            "Epoch 7640: Training loss 0.0357, Validation loss 17.1272, learning rate: 0.00082\n",
            "prediction loss: 0.2552, entropy regularization 0.0451\n",
            "Epoch 7645: Training loss 0.0395, Validation loss 17.2372, learning rate: 0.00080\n",
            "prediction loss: 0.2636, entropy regularization 0.0335\n",
            "Epoch 7650: Training loss 0.0146, Validation loss 17.1538, learning rate: 0.00079\n",
            "prediction loss: 0.2569, entropy regularization 0.0370\n",
            "Epoch 7655: Training loss 0.0262, Validation loss 17.2589, learning rate: 0.00078\n",
            "prediction loss: 0.2654, entropy regularization 0.0379\n",
            "Epoch 7660: Training loss 0.0069, Validation loss 17.2986, learning rate: 0.00077\n",
            "prediction loss: 0.2774, entropy regularization 0.0303\n",
            "Epoch 7665: Training loss 0.0046, Validation loss 17.2852, learning rate: 0.00075\n",
            "prediction loss: 0.2490, entropy regularization 0.0275\n",
            "Epoch 7670: Training loss 0.0029, Validation loss 17.1904, learning rate: 0.00074\n",
            "prediction loss: 0.2610, entropy regularization 0.0308\n",
            "Epoch 7675: Training loss 0.0075, Validation loss 17.3008, learning rate: 0.00072\n",
            "prediction loss: 0.2604, entropy regularization 0.0298\n",
            "Epoch 7680: Training loss 0.0038, Validation loss 17.2224, learning rate: 0.00071\n",
            "prediction loss: 0.2559, entropy regularization 0.0390\n",
            "Epoch 7685: Training loss 0.0017, Validation loss 17.2420, learning rate: 0.00070\n",
            "prediction loss: 0.2538, entropy regularization 0.0402\n",
            "Epoch 7690: Training loss 0.0024, Validation loss 17.2056, learning rate: 0.00068\n",
            "prediction loss: 0.2724, entropy regularization 0.0359\n",
            "Epoch 7695: Training loss 0.0017, Validation loss 17.2256, learning rate: 0.00067\n",
            "prediction loss: 0.2652, entropy regularization 0.0343\n",
            "Epoch 7700: Training loss 0.0022, Validation loss 17.2309, learning rate: 0.00065\n",
            "prediction loss: 0.2801, entropy regularization 0.0314\n",
            "Epoch 7705: Training loss 0.0029, Validation loss 17.1686, learning rate: 0.00064\n",
            "prediction loss: 0.2732, entropy regularization 0.0342\n",
            "Epoch 7710: Training loss 0.0041, Validation loss 17.2351, learning rate: 0.00062\n",
            "prediction loss: 0.2471, entropy regularization 0.0390\n",
            "Epoch 7715: Training loss 0.0027, Validation loss 17.2116, learning rate: 0.00061\n",
            "prediction loss: 0.2625, entropy regularization 0.0304\n",
            "Epoch 7720: Training loss 0.0030, Validation loss 17.2562, learning rate: 0.00059\n",
            "prediction loss: 0.2684, entropy regularization 0.0335\n",
            "Epoch 7725: Training loss 0.0052, Validation loss 17.1688, learning rate: 0.00058\n",
            "prediction loss: 0.2586, entropy regularization 0.0404\n",
            "Epoch 7730: Training loss 0.0024, Validation loss 17.2442, learning rate: 0.00056\n",
            "prediction loss: 0.2564, entropy regularization 0.0420\n",
            "Epoch 7735: Training loss 0.0029, Validation loss 17.1792, learning rate: 0.00054\n",
            "prediction loss: 0.2562, entropy regularization 0.0389\n",
            "Epoch 7740: Training loss 0.0019, Validation loss 17.2536, learning rate: 0.00053\n",
            "prediction loss: 0.2697, entropy regularization 0.0388\n",
            "Epoch 7745: Training loss 0.0008, Validation loss 17.1976, learning rate: 0.00051\n",
            "prediction loss: 0.2588, entropy regularization 0.0324\n",
            "Epoch 7750: Training loss 0.0009, Validation loss 17.1965, learning rate: 0.00050\n",
            "prediction loss: 0.2674, entropy regularization 0.0340\n",
            "Epoch 7755: Training loss 0.0009, Validation loss 17.1894, learning rate: 0.00048\n",
            "prediction loss: 0.2620, entropy regularization 0.0366\n",
            "Epoch 7760: Training loss 0.0010, Validation loss 17.2114, learning rate: 0.00047\n",
            "prediction loss: 0.2587, entropy regularization 0.0294\n",
            "Epoch 7765: Training loss 0.0020, Validation loss 17.1933, learning rate: 0.00045\n",
            "prediction loss: 0.2668, entropy regularization 0.0366\n",
            "Epoch 7770: Training loss 0.0041, Validation loss 17.2464, learning rate: 0.00043\n",
            "prediction loss: 0.2470, entropy regularization 0.0366\n",
            "Epoch 7775: Training loss 0.0034, Validation loss 17.1942, learning rate: 0.00042\n",
            "prediction loss: 0.2594, entropy regularization 0.0319\n",
            "Epoch 7780: Training loss 0.0172, Validation loss 17.1582, learning rate: 0.00040\n",
            "prediction loss: 0.2622, entropy regularization 0.0369\n",
            "Epoch 7785: Training loss 0.0108, Validation loss 17.1175, learning rate: 0.00039\n",
            "prediction loss: 0.2674, entropy regularization 0.0343\n",
            "Epoch 7790: Training loss 0.0106, Validation loss 17.1971, learning rate: 0.00037\n",
            "prediction loss: 0.2602, entropy regularization 0.0412\n",
            "Epoch 7795: Training loss 0.0016, Validation loss 17.1807, learning rate: 0.00036\n",
            "prediction loss: 0.2634, entropy regularization 0.0345\n",
            "Epoch 7800: Training loss 0.0007, Validation loss 17.1793, learning rate: 0.00034\n",
            "prediction loss: 0.2717, entropy regularization 0.0360\n",
            "Epoch 7805: Training loss 0.0003, Validation loss 17.1938, learning rate: 0.00033\n",
            "prediction loss: 0.2658, entropy regularization 0.0330\n",
            "Epoch 7810: Training loss 0.0002, Validation loss 17.1815, learning rate: 0.00031\n",
            "prediction loss: 0.2601, entropy regularization 0.0450\n",
            "Epoch 7815: Training loss 0.0003, Validation loss 17.1869, learning rate: 0.00030\n",
            "prediction loss: 0.2713, entropy regularization 0.0305\n",
            "Epoch 7820: Training loss 0.0001, Validation loss 17.1869, learning rate: 0.00028\n",
            "prediction loss: 0.2646, entropy regularization 0.0401\n",
            "Epoch 7825: Training loss 0.0002, Validation loss 17.1947, learning rate: 0.00027\n",
            "prediction loss: 0.2613, entropy regularization 0.0369\n",
            "Epoch 7830: Training loss 0.0001, Validation loss 17.1809, learning rate: 0.00026\n",
            "prediction loss: 0.2552, entropy regularization 0.0368\n",
            "Epoch 7835: Training loss 0.0002, Validation loss 17.1907, learning rate: 0.00024\n",
            "prediction loss: 0.2580, entropy regularization 0.0411\n",
            "Epoch 7840: Training loss 0.0002, Validation loss 17.1969, learning rate: 0.00023\n",
            "prediction loss: 0.2686, entropy regularization 0.0299\n",
            "Epoch 7845: Training loss 0.0001, Validation loss 17.1985, learning rate: 0.00022\n",
            "prediction loss: 0.2728, entropy regularization 0.0354\n",
            "Epoch 7850: Training loss 0.0001, Validation loss 17.1904, learning rate: 0.00020\n",
            "prediction loss: 0.2508, entropy regularization 0.0393\n",
            "Epoch 7855: Training loss 0.0001, Validation loss 17.1960, learning rate: 0.00019\n",
            "prediction loss: 0.2554, entropy regularization 0.0394\n",
            "Epoch 7860: Training loss 0.0001, Validation loss 17.1996, learning rate: 0.00018\n",
            "prediction loss: 0.2782, entropy regularization 0.0351\n",
            "Epoch 7865: Training loss 0.0001, Validation loss 17.1933, learning rate: 0.00017\n",
            "prediction loss: 0.2739, entropy regularization 0.0421\n",
            "Epoch 7870: Training loss 0.0001, Validation loss 17.1896, learning rate: 0.00016\n",
            "prediction loss: 0.2523, entropy regularization 0.0387\n",
            "Epoch 7875: Training loss 0.0001, Validation loss 17.1985, learning rate: 0.00014\n",
            "prediction loss: 0.2636, entropy regularization 0.0345\n",
            "Epoch 7880: Training loss 0.0001, Validation loss 17.1947, learning rate: 0.00013\n",
            "prediction loss: 0.2551, entropy regularization 0.0370\n",
            "Epoch 7885: Training loss 0.0001, Validation loss 17.1892, learning rate: 0.00012\n",
            "prediction loss: 0.2694, entropy regularization 0.0345\n",
            "Epoch 7890: Training loss 0.0001, Validation loss 17.1924, learning rate: 0.00011\n",
            "prediction loss: 0.2680, entropy regularization 0.0344\n",
            "Epoch 7895: Training loss 0.0001, Validation loss 17.1930, learning rate: 0.00010\n",
            "prediction loss: 0.2586, entropy regularization 0.0385\n",
            "Epoch 7900: Training loss 0.0001, Validation loss 17.1928, learning rate: 0.00009\n",
            "prediction loss: 0.2655, entropy regularization 0.0339\n",
            "Epoch 7905: Training loss 0.0001, Validation loss 17.1955, learning rate: 0.00008\n",
            "prediction loss: 0.2523, entropy regularization 0.0348\n",
            "Epoch 7910: Training loss 0.0001, Validation loss 17.1947, learning rate: 0.00008\n",
            "prediction loss: 0.2611, entropy regularization 0.0383\n",
            "Epoch 7915: Training loss 0.0001, Validation loss 17.1940, learning rate: 0.00007\n",
            "prediction loss: 0.2474, entropy regularization 0.0426\n",
            "Epoch 7920: Training loss 0.0001, Validation loss 17.1951, learning rate: 0.00006\n",
            "prediction loss: 0.2545, entropy regularization 0.0349\n",
            "Epoch 7925: Training loss 0.0000, Validation loss 17.1946, learning rate: 0.00005\n",
            "prediction loss: 0.2617, entropy regularization 0.0303\n",
            "Epoch 7930: Training loss 0.0001, Validation loss 17.1948, learning rate: 0.00005\n",
            "prediction loss: 0.2609, entropy regularization 0.0369\n",
            "Epoch 7935: Training loss 0.0000, Validation loss 17.1954, learning rate: 0.00004\n",
            "prediction loss: 0.2722, entropy regularization 0.0396\n",
            "Epoch 7940: Training loss 0.0000, Validation loss 17.1947, learning rate: 0.00003\n",
            "prediction loss: 0.2652, entropy regularization 0.0363\n",
            "Epoch 7945: Training loss 0.0000, Validation loss 17.1934, learning rate: 0.00003\n",
            "prediction loss: 0.2545, entropy regularization 0.0366\n",
            "Epoch 7950: Training loss 0.0000, Validation loss 17.1941, learning rate: 0.00002\n",
            "prediction loss: 0.2648, entropy regularization 0.0352\n",
            "Epoch 7955: Training loss 0.0000, Validation loss 17.1944, learning rate: 0.00002\n",
            "prediction loss: 0.2648, entropy regularization 0.0369\n",
            "Epoch 7960: Training loss 0.0000, Validation loss 17.1944, learning rate: 0.00001\n",
            "prediction loss: 0.2720, entropy regularization 0.0304\n",
            "Epoch 7965: Training loss 0.0000, Validation loss 17.1949, learning rate: 0.00001\n",
            "prediction loss: 0.2758, entropy regularization 0.0361\n",
            "Epoch 7970: Training loss 0.0000, Validation loss 17.1943, learning rate: 0.00001\n",
            "prediction loss: 0.2655, entropy regularization 0.0317\n",
            "Epoch 7975: Training loss 0.0000, Validation loss 17.1945, learning rate: 0.00001\n",
            "prediction loss: 0.2530, entropy regularization 0.0318\n",
            "Epoch 7980: Training loss 0.0000, Validation loss 17.1949, learning rate: 0.00000\n",
            "prediction loss: 0.2685, entropy regularization 0.0342\n",
            "Epoch 7985: Training loss 0.0000, Validation loss 17.1946, learning rate: 0.00000\n",
            "prediction loss: 0.2601, entropy regularization 0.0321\n",
            "Epoch 7990: Training loss 0.0000, Validation loss 17.1944, learning rate: 0.00000\n",
            "prediction loss: 0.2605, entropy regularization 0.0412\n",
            "Epoch 7995: Training loss 0.0000, Validation loss 17.1945, learning rate: 0.00000\n",
            "prediction loss: 0.2536, entropy regularization 0.0406\n",
            "Epoch 8000: Training loss 1.8397, Validation loss 13.9622, learning rate: 0.00100\n",
            "prediction loss: 0.2648, entropy regularization 0.0397\n",
            "Epoch 8005: Training loss 1.0756, Validation loss 16.5883, learning rate: 0.00100\n",
            "prediction loss: 0.2617, entropy regularization 0.0381\n",
            "Epoch 8010: Training loss 2.0524, Validation loss 17.2350, learning rate: 0.00100\n",
            "prediction loss: 0.2624, entropy regularization 0.0124\n",
            "Epoch 8015: Training loss 0.9595, Validation loss 15.6860, learning rate: 0.00100\n",
            "prediction loss: 0.2698, entropy regularization 0.0204\n",
            "Epoch 8020: Training loss 0.6388, Validation loss 15.8706, learning rate: 0.00100\n",
            "prediction loss: 0.2613, entropy regularization 0.0210\n",
            "Epoch 8025: Training loss 0.6084, Validation loss 16.2139, learning rate: 0.00099\n",
            "prediction loss: 0.2582, entropy regularization 0.0152\n",
            "Epoch 8030: Training loss 0.4708, Validation loss 16.3676, learning rate: 0.00099\n",
            "prediction loss: 0.2662, entropy regularization 0.0195\n",
            "Epoch 8035: Training loss 0.5020, Validation loss 15.8476, learning rate: 0.00099\n",
            "prediction loss: 0.2706, entropy regularization 0.0204\n",
            "Epoch 8040: Training loss 0.2814, Validation loss 15.9743, learning rate: 0.00098\n",
            "prediction loss: 0.2556, entropy regularization 0.0222\n",
            "Epoch 8045: Training loss 0.2373, Validation loss 16.0798, learning rate: 0.00098\n",
            "prediction loss: 0.2570, entropy regularization 0.0268\n",
            "Epoch 8050: Training loss 0.1859, Validation loss 16.0123, learning rate: 0.00097\n",
            "prediction loss: 0.2686, entropy regularization 0.0235\n",
            "Epoch 8055: Training loss 0.1534, Validation loss 16.0760, learning rate: 0.00097\n",
            "prediction loss: 0.2566, entropy regularization 0.0177\n",
            "Epoch 8060: Training loss 0.1591, Validation loss 16.0874, learning rate: 0.00096\n",
            "prediction loss: 0.2682, entropy regularization 0.0226\n",
            "Epoch 8065: Training loss 0.0990, Validation loss 16.0566, learning rate: 0.00096\n",
            "prediction loss: 0.2645, entropy regularization 0.0188\n",
            "Epoch 8070: Training loss 0.1065, Validation loss 16.3629, learning rate: 0.00095\n",
            "prediction loss: 0.2663, entropy regularization 0.0151\n",
            "Epoch 8075: Training loss 0.1077, Validation loss 16.0710, learning rate: 0.00094\n",
            "prediction loss: 0.2526, entropy regularization 0.0203\n",
            "Epoch 8080: Training loss 0.0943, Validation loss 16.2736, learning rate: 0.00094\n",
            "prediction loss: 0.2735, entropy regularization 0.0244\n",
            "Epoch 8085: Training loss 0.0571, Validation loss 16.0775, learning rate: 0.00093\n",
            "prediction loss: 0.2561, entropy regularization 0.0206\n",
            "Epoch 8090: Training loss 0.0637, Validation loss 15.9974, learning rate: 0.00092\n",
            "prediction loss: 0.2601, entropy regularization 0.0218\n",
            "Epoch 8095: Training loss 0.0351, Validation loss 15.9500, learning rate: 0.00091\n",
            "prediction loss: 0.2510, entropy regularization 0.0221\n",
            "Epoch 8100: Training loss 0.0877, Validation loss 15.8059, learning rate: 0.00090\n",
            "prediction loss: 0.2653, entropy regularization 0.0148\n",
            "Epoch 8105: Training loss 0.0643, Validation loss 16.0643, learning rate: 0.00089\n",
            "prediction loss: 0.2759, entropy regularization 0.0172\n",
            "Epoch 8110: Training loss 0.0405, Validation loss 16.0976, learning rate: 0.00088\n",
            "prediction loss: 0.2556, entropy regularization 0.0251\n",
            "Epoch 8115: Training loss 0.0404, Validation loss 16.0020, learning rate: 0.00087\n",
            "prediction loss: 0.2604, entropy regularization 0.0223\n",
            "Epoch 8120: Training loss 0.0328, Validation loss 16.0181, learning rate: 0.00086\n",
            "prediction loss: 0.2598, entropy regularization 0.0178\n",
            "Epoch 8125: Training loss 0.0371, Validation loss 15.9312, learning rate: 0.00085\n",
            "prediction loss: 0.2539, entropy regularization 0.0244\n",
            "Epoch 8130: Training loss 0.0422, Validation loss 15.8629, learning rate: 0.00084\n",
            "prediction loss: 0.2534, entropy regularization 0.0180\n",
            "Epoch 8135: Training loss 0.0240, Validation loss 16.0257, learning rate: 0.00083\n",
            "prediction loss: 0.2664, entropy regularization 0.0213\n",
            "Epoch 8140: Training loss 0.0324, Validation loss 15.8615, learning rate: 0.00082\n",
            "prediction loss: 0.2623, entropy regularization 0.0208\n",
            "Epoch 8145: Training loss 0.0164, Validation loss 15.9664, learning rate: 0.00080\n",
            "prediction loss: 0.2558, entropy regularization 0.0235\n",
            "Epoch 8150: Training loss 0.0182, Validation loss 15.8856, learning rate: 0.00079\n",
            "prediction loss: 0.2754, entropy regularization 0.0181\n",
            "Epoch 8155: Training loss 0.0252, Validation loss 15.9821, learning rate: 0.00078\n",
            "prediction loss: 0.2645, entropy regularization 0.0219\n",
            "Epoch 8160: Training loss 0.0219, Validation loss 15.9903, learning rate: 0.00077\n",
            "prediction loss: 0.2684, entropy regularization 0.0175\n",
            "Epoch 8165: Training loss 0.0193, Validation loss 15.9501, learning rate: 0.00075\n",
            "prediction loss: 0.2575, entropy regularization 0.0258\n",
            "Epoch 8170: Training loss 0.0209, Validation loss 16.0185, learning rate: 0.00074\n",
            "prediction loss: 0.2683, entropy regularization 0.0206\n",
            "Epoch 8175: Training loss 0.0135, Validation loss 15.8742, learning rate: 0.00072\n",
            "prediction loss: 0.2623, entropy regularization 0.0158\n",
            "Epoch 8180: Training loss 0.0247, Validation loss 15.9869, learning rate: 0.00071\n",
            "prediction loss: 0.2644, entropy regularization 0.0189\n",
            "Epoch 8185: Training loss 0.0157, Validation loss 15.9731, learning rate: 0.00070\n",
            "prediction loss: 0.2601, entropy regularization 0.0189\n",
            "Epoch 8190: Training loss 0.0100, Validation loss 15.9471, learning rate: 0.00068\n",
            "prediction loss: 0.2530, entropy regularization 0.0193\n",
            "Epoch 8195: Training loss 0.0126, Validation loss 16.0413, learning rate: 0.00067\n",
            "prediction loss: 0.2675, entropy regularization 0.0161\n",
            "Epoch 8200: Training loss 0.0113, Validation loss 15.9341, learning rate: 0.00065\n",
            "prediction loss: 0.2629, entropy regularization 0.0201\n",
            "Epoch 8205: Training loss 0.0131, Validation loss 16.0202, learning rate: 0.00064\n",
            "prediction loss: 0.2564, entropy regularization 0.0215\n",
            "Epoch 8210: Training loss 0.0143, Validation loss 16.0108, learning rate: 0.00062\n",
            "prediction loss: 0.2685, entropy regularization 0.0222\n",
            "Epoch 8215: Training loss 0.0086, Validation loss 16.0024, learning rate: 0.00061\n",
            "prediction loss: 0.2662, entropy regularization 0.0172\n",
            "Epoch 8220: Training loss 0.0073, Validation loss 15.9957, learning rate: 0.00059\n",
            "prediction loss: 0.2522, entropy regularization 0.0246\n",
            "Epoch 8225: Training loss 0.0048, Validation loss 16.0070, learning rate: 0.00058\n",
            "prediction loss: 0.2567, entropy regularization 0.0211\n",
            "Epoch 8230: Training loss 0.0053, Validation loss 16.0494, learning rate: 0.00056\n",
            "prediction loss: 0.2591, entropy regularization 0.0205\n",
            "Epoch 8235: Training loss 0.0068, Validation loss 16.0191, learning rate: 0.00054\n",
            "prediction loss: 0.2809, entropy regularization 0.0166\n",
            "Epoch 8240: Training loss 0.0082, Validation loss 16.0215, learning rate: 0.00053\n",
            "prediction loss: 0.2602, entropy regularization 0.0164\n",
            "Epoch 8245: Training loss 0.0125, Validation loss 16.0755, learning rate: 0.00051\n",
            "prediction loss: 0.2583, entropy regularization 0.0275\n",
            "Epoch 8250: Training loss 0.0078, Validation loss 15.9609, learning rate: 0.00050\n",
            "prediction loss: 0.2513, entropy regularization 0.0145\n",
            "Epoch 8255: Training loss 0.0097, Validation loss 16.0676, learning rate: 0.00048\n",
            "prediction loss: 0.2594, entropy regularization 0.0199\n",
            "Epoch 8260: Training loss 0.0056, Validation loss 16.0083, learning rate: 0.00047\n",
            "prediction loss: 0.2562, entropy regularization 0.0257\n",
            "Epoch 8265: Training loss 0.0039, Validation loss 16.0308, learning rate: 0.00045\n",
            "prediction loss: 0.2610, entropy regularization 0.0205\n",
            "Epoch 8270: Training loss 0.0033, Validation loss 15.9733, learning rate: 0.00043\n",
            "prediction loss: 0.2734, entropy regularization 0.0180\n",
            "Epoch 8275: Training loss 0.0039, Validation loss 15.9982, learning rate: 0.00042\n",
            "prediction loss: 0.2613, entropy regularization 0.0264\n",
            "Epoch 8280: Training loss 0.0059, Validation loss 16.0563, learning rate: 0.00040\n",
            "prediction loss: 0.2617, entropy regularization 0.0190\n",
            "Epoch 8285: Training loss 0.0035, Validation loss 16.0682, learning rate: 0.00039\n",
            "prediction loss: 0.2602, entropy regularization 0.0182\n",
            "Epoch 8290: Training loss 0.0032, Validation loss 16.0171, learning rate: 0.00037\n",
            "prediction loss: 0.2560, entropy regularization 0.0256\n",
            "Epoch 8295: Training loss 0.0026, Validation loss 16.0490, learning rate: 0.00036\n",
            "prediction loss: 0.2575, entropy regularization 0.0226\n",
            "Epoch 8300: Training loss 0.0018, Validation loss 16.0607, learning rate: 0.00034\n",
            "prediction loss: 0.2591, entropy regularization 0.0250\n",
            "Epoch 8305: Training loss 0.0024, Validation loss 16.0281, learning rate: 0.00033\n",
            "prediction loss: 0.2597, entropy regularization 0.0205\n",
            "Epoch 8310: Training loss 0.0019, Validation loss 16.0591, learning rate: 0.00031\n",
            "prediction loss: 0.2689, entropy regularization 0.0186\n",
            "Epoch 8315: Training loss 0.0015, Validation loss 16.0389, learning rate: 0.00030\n",
            "prediction loss: 0.2640, entropy regularization 0.0217\n",
            "Epoch 8320: Training loss 0.0020, Validation loss 16.0324, learning rate: 0.00028\n",
            "prediction loss: 0.2499, entropy regularization 0.0189\n",
            "Epoch 8325: Training loss 0.0011, Validation loss 16.0342, learning rate: 0.00027\n",
            "prediction loss: 0.2611, entropy regularization 0.0166\n",
            "Epoch 8330: Training loss 0.0019, Validation loss 16.0438, learning rate: 0.00026\n",
            "prediction loss: 0.2757, entropy regularization 0.0145\n",
            "Epoch 8335: Training loss 0.0014, Validation loss 16.0320, learning rate: 0.00024\n",
            "prediction loss: 0.2646, entropy regularization 0.0192\n",
            "Epoch 8340: Training loss 0.0011, Validation loss 16.0478, learning rate: 0.00023\n",
            "prediction loss: 0.2668, entropy regularization 0.0196\n",
            "Epoch 8345: Training loss 0.0009, Validation loss 16.0266, learning rate: 0.00022\n",
            "prediction loss: 0.2771, entropy regularization 0.0231\n",
            "Epoch 8350: Training loss 0.0011, Validation loss 16.0356, learning rate: 0.00020\n",
            "prediction loss: 0.2524, entropy regularization 0.0215\n",
            "Epoch 8355: Training loss 0.0009, Validation loss 16.0439, learning rate: 0.00019\n",
            "prediction loss: 0.2668, entropy regularization 0.0134\n",
            "Epoch 8360: Training loss 0.0010, Validation loss 16.0244, learning rate: 0.00018\n",
            "prediction loss: 0.2660, entropy regularization 0.0268\n",
            "Epoch 8365: Training loss 0.0009, Validation loss 16.0437, learning rate: 0.00017\n",
            "prediction loss: 0.2659, entropy regularization 0.0241\n",
            "Epoch 8370: Training loss 0.0008, Validation loss 16.0497, learning rate: 0.00016\n",
            "prediction loss: 0.2658, entropy regularization 0.0269\n",
            "Epoch 8375: Training loss 0.0012, Validation loss 16.0475, learning rate: 0.00014\n",
            "prediction loss: 0.2663, entropy regularization 0.0201\n",
            "Epoch 8380: Training loss 0.0008, Validation loss 16.0296, learning rate: 0.00013\n",
            "prediction loss: 0.2662, entropy regularization 0.0182\n",
            "Epoch 8385: Training loss 0.0007, Validation loss 16.0397, learning rate: 0.00012\n",
            "prediction loss: 0.2533, entropy regularization 0.0220\n",
            "Epoch 8390: Training loss 0.0007, Validation loss 16.0411, learning rate: 0.00011\n",
            "prediction loss: 0.2575, entropy regularization 0.0222\n",
            "Epoch 8395: Training loss 0.0007, Validation loss 16.0370, learning rate: 0.00010\n",
            "prediction loss: 0.2680, entropy regularization 0.0167\n",
            "Epoch 8400: Training loss 0.0006, Validation loss 16.0427, learning rate: 0.00009\n",
            "prediction loss: 0.2742, entropy regularization 0.0234\n",
            "Epoch 8405: Training loss 0.0006, Validation loss 16.0441, learning rate: 0.00008\n",
            "prediction loss: 0.2713, entropy regularization 0.0191\n",
            "Epoch 8410: Training loss 0.0006, Validation loss 16.0412, learning rate: 0.00008\n",
            "prediction loss: 0.2634, entropy regularization 0.0163\n",
            "Epoch 8415: Training loss 0.0006, Validation loss 16.0394, learning rate: 0.00007\n",
            "prediction loss: 0.2548, entropy regularization 0.0189\n",
            "Epoch 8420: Training loss 0.0006, Validation loss 16.0379, learning rate: 0.00006\n",
            "prediction loss: 0.2503, entropy regularization 0.0202\n",
            "Epoch 8425: Training loss 0.0006, Validation loss 16.0408, learning rate: 0.00005\n",
            "prediction loss: 0.2618, entropy regularization 0.0193\n",
            "Epoch 8430: Training loss 0.0005, Validation loss 16.0393, learning rate: 0.00005\n",
            "prediction loss: 0.2780, entropy regularization 0.0128\n",
            "Epoch 8435: Training loss 0.0006, Validation loss 16.0387, learning rate: 0.00004\n",
            "prediction loss: 0.2727, entropy regularization 0.0177\n",
            "Epoch 8440: Training loss 0.0006, Validation loss 16.0376, learning rate: 0.00003\n",
            "prediction loss: 0.2696, entropy regularization 0.0269\n",
            "Epoch 8445: Training loss 0.0005, Validation loss 16.0374, learning rate: 0.00003\n",
            "prediction loss: 0.2636, entropy regularization 0.0202\n",
            "Epoch 8450: Training loss 0.0005, Validation loss 16.0386, learning rate: 0.00002\n",
            "prediction loss: 0.2618, entropy regularization 0.0185\n",
            "Epoch 8455: Training loss 0.0005, Validation loss 16.0363, learning rate: 0.00002\n",
            "prediction loss: 0.2567, entropy regularization 0.0263\n",
            "Epoch 8460: Training loss 0.0005, Validation loss 16.0387, learning rate: 0.00001\n",
            "prediction loss: 0.2603, entropy regularization 0.0271\n",
            "Epoch 8465: Training loss 0.0005, Validation loss 16.0362, learning rate: 0.00001\n",
            "prediction loss: 0.2620, entropy regularization 0.0173\n",
            "Epoch 8470: Training loss 0.0005, Validation loss 16.0366, learning rate: 0.00001\n",
            "prediction loss: 0.2624, entropy regularization 0.0160\n",
            "Epoch 8475: Training loss 0.0005, Validation loss 16.0373, learning rate: 0.00001\n",
            "prediction loss: 0.2570, entropy regularization 0.0216\n",
            "Epoch 8480: Training loss 0.0005, Validation loss 16.0373, learning rate: 0.00000\n",
            "prediction loss: 0.2653, entropy regularization 0.0205\n",
            "Epoch 8485: Training loss 0.0005, Validation loss 16.0374, learning rate: 0.00000\n",
            "prediction loss: 0.2575, entropy regularization 0.0218\n",
            "Epoch 8490: Training loss 0.0005, Validation loss 16.0374, learning rate: 0.00000\n",
            "prediction loss: 0.2613, entropy regularization 0.0225\n",
            "Epoch 8495: Training loss 0.0005, Validation loss 16.0374, learning rate: 0.00000\n",
            "prediction loss: 0.2738, entropy regularization 0.0188\n",
            "Epoch 8500: Training loss 2.1795, Validation loss 14.2731, learning rate: 0.00100\n",
            "prediction loss: 0.2618, entropy regularization 0.0184\n",
            "Epoch 8505: Training loss 0.8945, Validation loss 16.9783, learning rate: 0.00100\n",
            "prediction loss: 0.2592, entropy regularization 0.0163\n",
            "Epoch 8510: Training loss 0.4348, Validation loss 16.1299, learning rate: 0.00100\n",
            "prediction loss: 0.2674, entropy regularization 0.0255\n",
            "Epoch 8515: Training loss 0.2780, Validation loss 16.0286, learning rate: 0.00100\n",
            "prediction loss: 0.2726, entropy regularization 0.0220\n",
            "Epoch 8520: Training loss 0.2611, Validation loss 16.1332, learning rate: 0.00100\n",
            "prediction loss: 0.2541, entropy regularization 0.0238\n",
            "Epoch 8525: Training loss 0.2258, Validation loss 16.0242, learning rate: 0.00099\n",
            "prediction loss: 0.2679, entropy regularization 0.0185\n",
            "Epoch 8530: Training loss 0.1715, Validation loss 16.0247, learning rate: 0.00099\n",
            "prediction loss: 0.2679, entropy regularization 0.0182\n",
            "Epoch 8535: Training loss 0.1399, Validation loss 16.0592, learning rate: 0.00099\n",
            "prediction loss: 0.2480, entropy regularization 0.0267\n",
            "Epoch 8540: Training loss 0.0504, Validation loss 16.1206, learning rate: 0.00098\n",
            "prediction loss: 0.2614, entropy regularization 0.0209\n",
            "Epoch 8545: Training loss 0.0591, Validation loss 16.1512, learning rate: 0.00098\n",
            "prediction loss: 0.2670, entropy regularization 0.0287\n",
            "Epoch 8550: Training loss 0.0549, Validation loss 16.0958, learning rate: 0.00097\n",
            "prediction loss: 0.2518, entropy regularization 0.0206\n",
            "Epoch 8555: Training loss 0.0451, Validation loss 16.0926, learning rate: 0.00097\n",
            "prediction loss: 0.2640, entropy regularization 0.0264\n",
            "Epoch 8560: Training loss 0.0442, Validation loss 16.2204, learning rate: 0.00096\n",
            "prediction loss: 0.2554, entropy regularization 0.0233\n",
            "Epoch 8565: Training loss 0.0315, Validation loss 16.3084, learning rate: 0.00096\n",
            "prediction loss: 0.2771, entropy regularization 0.0252\n",
            "Epoch 8570: Training loss 0.0463, Validation loss 16.0452, learning rate: 0.00095\n",
            "prediction loss: 0.2743, entropy regularization 0.0178\n",
            "Epoch 8575: Training loss 0.1019, Validation loss 16.0162, learning rate: 0.00094\n",
            "prediction loss: 0.2569, entropy regularization 0.0236\n",
            "Epoch 8580: Training loss 0.0254, Validation loss 16.2349, learning rate: 0.00094\n",
            "prediction loss: 0.2681, entropy regularization 0.0189\n",
            "Epoch 8585: Training loss 0.0208, Validation loss 16.2758, learning rate: 0.00093\n",
            "prediction loss: 0.2670, entropy regularization 0.0196\n",
            "Epoch 8590: Training loss 0.0119, Validation loss 16.3182, learning rate: 0.00092\n",
            "prediction loss: 0.2543, entropy regularization 0.0208\n",
            "Epoch 8595: Training loss 0.0118, Validation loss 16.2873, learning rate: 0.00091\n",
            "prediction loss: 0.2603, entropy regularization 0.0192\n",
            "Epoch 8600: Training loss 0.0099, Validation loss 16.3108, learning rate: 0.00090\n",
            "prediction loss: 0.2592, entropy regularization 0.0233\n",
            "Epoch 8605: Training loss 0.0091, Validation loss 16.2150, learning rate: 0.00089\n",
            "prediction loss: 0.2635, entropy regularization 0.0193\n",
            "Epoch 8610: Training loss 0.0076, Validation loss 16.2147, learning rate: 0.00088\n",
            "prediction loss: 0.2523, entropy regularization 0.0195\n",
            "Epoch 8615: Training loss 0.0317, Validation loss 16.3000, learning rate: 0.00087\n",
            "prediction loss: 0.2803, entropy regularization 0.0182\n",
            "Epoch 8620: Training loss 0.0279, Validation loss 16.2117, learning rate: 0.00086\n",
            "prediction loss: 0.2554, entropy regularization 0.0199\n",
            "Epoch 8625: Training loss 0.0199, Validation loss 16.1950, learning rate: 0.00085\n",
            "prediction loss: 0.2543, entropy regularization 0.0204\n",
            "Epoch 8630: Training loss 0.0120, Validation loss 16.1999, learning rate: 0.00084\n",
            "prediction loss: 0.2793, entropy regularization 0.0195\n",
            "Epoch 8635: Training loss 0.0115, Validation loss 16.3106, learning rate: 0.00083\n",
            "prediction loss: 0.2687, entropy regularization 0.0193\n",
            "Epoch 8640: Training loss 0.0144, Validation loss 16.2200, learning rate: 0.00082\n",
            "prediction loss: 0.2562, entropy regularization 0.0183\n",
            "Epoch 8645: Training loss 0.0157, Validation loss 16.1427, learning rate: 0.00080\n",
            "prediction loss: 0.2683, entropy regularization 0.0213\n",
            "Epoch 8650: Training loss 0.0164, Validation loss 16.2806, learning rate: 0.00079\n",
            "prediction loss: 0.2576, entropy regularization 0.0190\n",
            "Epoch 8655: Training loss 0.0091, Validation loss 16.2969, learning rate: 0.00078\n",
            "prediction loss: 0.2674, entropy regularization 0.0238\n",
            "Epoch 8660: Training loss 0.0059, Validation loss 16.3129, learning rate: 0.00077\n",
            "prediction loss: 0.2707, entropy regularization 0.0199\n",
            "Epoch 8665: Training loss 0.0057, Validation loss 16.3302, learning rate: 0.00075\n",
            "prediction loss: 0.2510, entropy regularization 0.0239\n",
            "Epoch 8670: Training loss 0.0184, Validation loss 16.2265, learning rate: 0.00074\n",
            "prediction loss: 0.2606, entropy regularization 0.0245\n",
            "Epoch 8675: Training loss 0.0133, Validation loss 16.2298, learning rate: 0.00072\n",
            "prediction loss: 0.2439, entropy regularization 0.0268\n",
            "Epoch 8680: Training loss 0.0081, Validation loss 16.1464, learning rate: 0.00071\n",
            "prediction loss: 0.2452, entropy regularization 0.0256\n",
            "Epoch 8685: Training loss 0.0091, Validation loss 16.2914, learning rate: 0.00070\n",
            "prediction loss: 0.2597, entropy regularization 0.0152\n",
            "Epoch 8690: Training loss 0.0061, Validation loss 16.1740, learning rate: 0.00068\n",
            "prediction loss: 0.2610, entropy regularization 0.0284\n",
            "Epoch 8695: Training loss 0.0081, Validation loss 16.2991, learning rate: 0.00067\n",
            "prediction loss: 0.2585, entropy regularization 0.0225\n",
            "Epoch 8700: Training loss 0.0093, Validation loss 16.1903, learning rate: 0.00065\n",
            "prediction loss: 0.2506, entropy regularization 0.0227\n",
            "Epoch 8705: Training loss 0.0087, Validation loss 16.1659, learning rate: 0.00064\n",
            "prediction loss: 0.2725, entropy regularization 0.0174\n",
            "Epoch 8710: Training loss 0.0102, Validation loss 16.2759, learning rate: 0.00062\n",
            "prediction loss: 0.2801, entropy regularization 0.0290\n",
            "Epoch 8715: Training loss 0.0054, Validation loss 16.2759, learning rate: 0.00061\n",
            "prediction loss: 0.2582, entropy regularization 0.0255\n",
            "Epoch 8720: Training loss 0.0042, Validation loss 16.2392, learning rate: 0.00059\n",
            "prediction loss: 0.2917, entropy regularization 0.0097\n",
            "Epoch 8725: Training loss 0.0091, Validation loss 16.3131, learning rate: 0.00058\n",
            "prediction loss: 0.2455, entropy regularization 0.0146\n",
            "Epoch 8730: Training loss 0.0022, Validation loss 16.2747, learning rate: 0.00056\n",
            "prediction loss: 0.2692, entropy regularization 0.0214\n",
            "Epoch 8735: Training loss 0.0055, Validation loss 16.3112, learning rate: 0.00054\n",
            "prediction loss: 0.2668, entropy regularization 0.0135\n",
            "Epoch 8740: Training loss 0.0024, Validation loss 16.2075, learning rate: 0.00053\n",
            "prediction loss: 0.2674, entropy regularization 0.0191\n",
            "Epoch 8745: Training loss 0.0045, Validation loss 16.2773, learning rate: 0.00051\n",
            "prediction loss: 0.2619, entropy regularization 0.0169\n",
            "Epoch 8750: Training loss 0.0030, Validation loss 16.2150, learning rate: 0.00050\n",
            "prediction loss: 0.2648, entropy regularization 0.0172\n",
            "Epoch 8755: Training loss 0.0036, Validation loss 16.2880, learning rate: 0.00048\n",
            "prediction loss: 0.2653, entropy regularization 0.0223\n",
            "Epoch 8760: Training loss 0.0024, Validation loss 16.2058, learning rate: 0.00047\n",
            "prediction loss: 0.2679, entropy regularization 0.0161\n",
            "Epoch 8765: Training loss 0.0014, Validation loss 16.2625, learning rate: 0.00045\n",
            "prediction loss: 0.2616, entropy regularization 0.0207\n",
            "Epoch 8770: Training loss 0.0011, Validation loss 16.2775, learning rate: 0.00043\n",
            "prediction loss: 0.2602, entropy regularization 0.0221\n",
            "Epoch 8775: Training loss 0.0011, Validation loss 16.2696, learning rate: 0.00042\n",
            "prediction loss: 0.2569, entropy regularization 0.0267\n",
            "Epoch 8780: Training loss 0.0013, Validation loss 16.2243, learning rate: 0.00040\n",
            "prediction loss: 0.2548, entropy regularization 0.0208\n",
            "Epoch 8785: Training loss 0.0010, Validation loss 16.2477, learning rate: 0.00039\n",
            "prediction loss: 0.2724, entropy regularization 0.0189\n",
            "Epoch 8790: Training loss 0.0009, Validation loss 16.2536, learning rate: 0.00037\n",
            "prediction loss: 0.2641, entropy regularization 0.0141\n",
            "Epoch 8795: Training loss 0.0019, Validation loss 16.2643, learning rate: 0.00036\n",
            "prediction loss: 0.2690, entropy regularization 0.0191\n",
            "Epoch 8800: Training loss 0.0015, Validation loss 16.2360, learning rate: 0.00034\n",
            "prediction loss: 0.2599, entropy regularization 0.0180\n",
            "Epoch 8805: Training loss 0.0014, Validation loss 16.2428, learning rate: 0.00033\n",
            "prediction loss: 0.2785, entropy regularization 0.0120\n",
            "Epoch 8810: Training loss 0.0015, Validation loss 16.2434, learning rate: 0.00031\n",
            "prediction loss: 0.2520, entropy regularization 0.0170\n",
            "Epoch 8815: Training loss 0.0017, Validation loss 16.2408, learning rate: 0.00030\n",
            "prediction loss: 0.2591, entropy regularization 0.0216\n",
            "Epoch 8820: Training loss 0.0009, Validation loss 16.2399, learning rate: 0.00028\n",
            "prediction loss: 0.2630, entropy regularization 0.0184\n",
            "Epoch 8825: Training loss 0.0008, Validation loss 16.2345, learning rate: 0.00027\n",
            "prediction loss: 0.2639, entropy regularization 0.0276\n",
            "Epoch 8830: Training loss 0.0003, Validation loss 16.2483, learning rate: 0.00026\n",
            "prediction loss: 0.2660, entropy regularization 0.0208\n",
            "Epoch 8835: Training loss 0.0004, Validation loss 16.2343, learning rate: 0.00024\n",
            "prediction loss: 0.2643, entropy regularization 0.0171\n",
            "Epoch 8840: Training loss 0.0003, Validation loss 16.2254, learning rate: 0.00023\n",
            "prediction loss: 0.2604, entropy regularization 0.0299\n",
            "Epoch 8845: Training loss 0.0003, Validation loss 16.2508, learning rate: 0.00022\n",
            "prediction loss: 0.2601, entropy regularization 0.0218\n",
            "Epoch 8850: Training loss 0.0005, Validation loss 16.2346, learning rate: 0.00020\n",
            "prediction loss: 0.2441, entropy regularization 0.0250\n",
            "Epoch 8855: Training loss 0.0005, Validation loss 16.2285, learning rate: 0.00019\n",
            "prediction loss: 0.2588, entropy regularization 0.0197\n",
            "Epoch 8860: Training loss 0.0002, Validation loss 16.2314, learning rate: 0.00018\n",
            "prediction loss: 0.2382, entropy regularization 0.0190\n",
            "Epoch 8865: Training loss 0.0003, Validation loss 16.2385, learning rate: 0.00017\n",
            "prediction loss: 0.2685, entropy regularization 0.0259\n",
            "Epoch 8870: Training loss 0.0003, Validation loss 16.2382, learning rate: 0.00016\n",
            "prediction loss: 0.2567, entropy regularization 0.0160\n",
            "Epoch 8875: Training loss 0.0002, Validation loss 16.2322, learning rate: 0.00014\n",
            "prediction loss: 0.2504, entropy regularization 0.0215\n",
            "Epoch 8880: Training loss 0.0002, Validation loss 16.2267, learning rate: 0.00013\n",
            "prediction loss: 0.2580, entropy regularization 0.0230\n",
            "Epoch 8885: Training loss 0.0003, Validation loss 16.2298, learning rate: 0.00012\n",
            "prediction loss: 0.2687, entropy regularization 0.0256\n",
            "Epoch 8890: Training loss 0.0002, Validation loss 16.2292, learning rate: 0.00011\n",
            "prediction loss: 0.2739, entropy regularization 0.0189\n",
            "Epoch 8895: Training loss 0.0002, Validation loss 16.2324, learning rate: 0.00010\n",
            "prediction loss: 0.2602, entropy regularization 0.0244\n",
            "Epoch 8900: Training loss 0.0002, Validation loss 16.2394, learning rate: 0.00009\n",
            "prediction loss: 0.2681, entropy regularization 0.0245\n",
            "Epoch 8905: Training loss 0.0001, Validation loss 16.2336, learning rate: 0.00008\n",
            "prediction loss: 0.2428, entropy regularization 0.0228\n",
            "Epoch 8910: Training loss 0.0001, Validation loss 16.2411, learning rate: 0.00008\n",
            "prediction loss: 0.2613, entropy regularization 0.0226\n",
            "Epoch 8915: Training loss 0.0001, Validation loss 16.2349, learning rate: 0.00007\n",
            "prediction loss: 0.2569, entropy regularization 0.0155\n",
            "Epoch 8920: Training loss 0.0001, Validation loss 16.2334, learning rate: 0.00006\n",
            "prediction loss: 0.2630, entropy regularization 0.0186\n",
            "Epoch 8925: Training loss 0.0001, Validation loss 16.2384, learning rate: 0.00005\n",
            "prediction loss: 0.2644, entropy regularization 0.0220\n",
            "Epoch 8930: Training loss 0.0001, Validation loss 16.2301, learning rate: 0.00005\n",
            "prediction loss: 0.2610, entropy regularization 0.0186\n",
            "Epoch 8935: Training loss 0.0001, Validation loss 16.2339, learning rate: 0.00004\n",
            "prediction loss: 0.2690, entropy regularization 0.0218\n",
            "Epoch 8940: Training loss 0.0001, Validation loss 16.2336, learning rate: 0.00003\n",
            "prediction loss: 0.2612, entropy regularization 0.0169\n",
            "Epoch 8945: Training loss 0.0001, Validation loss 16.2329, learning rate: 0.00003\n",
            "prediction loss: 0.2533, entropy regularization 0.0260\n",
            "Epoch 8950: Training loss 0.0001, Validation loss 16.2333, learning rate: 0.00002\n",
            "prediction loss: 0.2531, entropy regularization 0.0224\n",
            "Epoch 8955: Training loss 0.0001, Validation loss 16.2328, learning rate: 0.00002\n",
            "prediction loss: 0.2612, entropy regularization 0.0191\n",
            "Epoch 8960: Training loss 0.0001, Validation loss 16.2345, learning rate: 0.00001\n",
            "prediction loss: 0.2716, entropy regularization 0.0226\n",
            "Epoch 8965: Training loss 0.0001, Validation loss 16.2338, learning rate: 0.00001\n",
            "prediction loss: 0.2567, entropy regularization 0.0229\n",
            "Epoch 8970: Training loss 0.0001, Validation loss 16.2333, learning rate: 0.00001\n",
            "prediction loss: 0.2468, entropy regularization 0.0226\n",
            "Epoch 8975: Training loss 0.0001, Validation loss 16.2340, learning rate: 0.00001\n",
            "prediction loss: 0.2754, entropy regularization 0.0237\n",
            "Epoch 8980: Training loss 0.0001, Validation loss 16.2338, learning rate: 0.00000\n",
            "prediction loss: 0.2658, entropy regularization 0.0205\n",
            "Epoch 8985: Training loss 0.0001, Validation loss 16.2332, learning rate: 0.00000\n",
            "prediction loss: 0.2571, entropy regularization 0.0175\n",
            "Epoch 8990: Training loss 0.0001, Validation loss 16.2335, learning rate: 0.00000\n",
            "prediction loss: 0.2658, entropy regularization 0.0222\n",
            "Epoch 8995: Training loss 0.0001, Validation loss 16.2333, learning rate: 0.00000\n",
            "prediction loss: 0.2704, entropy regularization 0.0208\n",
            "Epoch 9000: Training loss 1.2890, Validation loss 14.1717, learning rate: 0.00100\n",
            "prediction loss: 0.2556, entropy regularization 0.0197\n",
            "Epoch 9005: Training loss 3.7564, Validation loss 27.8217, learning rate: 0.00100\n",
            "prediction loss: 0.2549, entropy regularization 0.0142\n",
            "Epoch 9010: Training loss 3.1596, Validation loss 24.3381, learning rate: 0.00100\n",
            "prediction loss: 0.2679, entropy regularization 0.0067\n",
            "Epoch 9015: Training loss 2.6328, Validation loss 23.0268, learning rate: 0.00100\n",
            "prediction loss: 0.2462, entropy regularization 0.0088\n",
            "Epoch 9020: Training loss 2.4415, Validation loss 22.7782, learning rate: 0.00100\n",
            "prediction loss: 0.2743, entropy regularization 0.0090\n",
            "Epoch 9025: Training loss 2.2852, Validation loss 22.2018, learning rate: 0.00099\n",
            "prediction loss: 0.2572, entropy regularization 0.0107\n",
            "Epoch 9030: Training loss 2.2055, Validation loss 22.2020, learning rate: 0.00099\n",
            "prediction loss: 0.2629, entropy regularization 0.0138\n",
            "Epoch 9035: Training loss 2.1570, Validation loss 21.9082, learning rate: 0.00099\n",
            "prediction loss: 0.2475, entropy regularization 0.0097\n",
            "Epoch 9040: Training loss 2.1073, Validation loss 21.9364, learning rate: 0.00098\n",
            "prediction loss: 0.2559, entropy regularization 0.0094\n",
            "Epoch 9045: Training loss 2.0376, Validation loss 22.3312, learning rate: 0.00098\n",
            "prediction loss: 0.2538, entropy regularization 0.0142\n",
            "Epoch 9050: Training loss 2.0216, Validation loss 22.1405, learning rate: 0.00097\n",
            "prediction loss: 0.2510, entropy regularization 0.0105\n",
            "Epoch 9055: Training loss 2.1283, Validation loss 21.6253, learning rate: 0.00097\n",
            "prediction loss: 0.2662, entropy regularization 0.0090\n",
            "Epoch 9060: Training loss 1.9504, Validation loss 21.6496, learning rate: 0.00096\n",
            "prediction loss: 0.2577, entropy regularization 0.0086\n",
            "Epoch 9065: Training loss 1.9435, Validation loss 21.9880, learning rate: 0.00096\n",
            "prediction loss: 0.2653, entropy regularization 0.0100\n",
            "Epoch 9070: Training loss 1.9084, Validation loss 22.0873, learning rate: 0.00095\n",
            "prediction loss: 0.2526, entropy regularization 0.0161\n",
            "Epoch 9075: Training loss 1.9329, Validation loss 21.2967, learning rate: 0.00094\n",
            "prediction loss: 0.2644, entropy regularization 0.0084\n",
            "Epoch 9080: Training loss 1.7954, Validation loss 21.8703, learning rate: 0.00094\n",
            "prediction loss: 0.2604, entropy regularization 0.0102\n",
            "Epoch 9085: Training loss 1.7868, Validation loss 22.0327, learning rate: 0.00093\n",
            "prediction loss: 0.2647, entropy regularization 0.0113\n",
            "Epoch 9090: Training loss 1.7439, Validation loss 21.6442, learning rate: 0.00092\n",
            "prediction loss: 0.2617, entropy regularization 0.0177\n",
            "Epoch 9095: Training loss 1.7137, Validation loss 21.5682, learning rate: 0.00091\n",
            "prediction loss: 0.2752, entropy regularization 0.0164\n",
            "Epoch 9100: Training loss 1.6950, Validation loss 21.7567, learning rate: 0.00090\n",
            "prediction loss: 0.2560, entropy regularization 0.0134\n",
            "Epoch 9105: Training loss 1.6607, Validation loss 21.7151, learning rate: 0.00089\n",
            "prediction loss: 0.2547, entropy regularization 0.0099\n",
            "Epoch 9110: Training loss 1.6455, Validation loss 21.8077, learning rate: 0.00088\n",
            "prediction loss: 0.2681, entropy regularization 0.0067\n",
            "Epoch 9115: Training loss 1.6998, Validation loss 21.9860, learning rate: 0.00087\n",
            "prediction loss: 0.2667, entropy regularization 0.0109\n",
            "Epoch 9120: Training loss 1.6519, Validation loss 21.4089, learning rate: 0.00086\n",
            "prediction loss: 0.2691, entropy regularization 0.0104\n",
            "Epoch 9125: Training loss 1.5839, Validation loss 21.5063, learning rate: 0.00085\n",
            "prediction loss: 0.2560, entropy regularization 0.0132\n",
            "Epoch 9130: Training loss 1.6282, Validation loss 21.8686, learning rate: 0.00084\n",
            "prediction loss: 0.2535, entropy regularization 0.0138\n",
            "Epoch 9135: Training loss 1.5575, Validation loss 21.3369, learning rate: 0.00083\n",
            "prediction loss: 0.2594, entropy regularization 0.0096\n",
            "Epoch 9140: Training loss 1.5710, Validation loss 21.5053, learning rate: 0.00082\n",
            "prediction loss: 0.2716, entropy regularization 0.0114\n",
            "Epoch 9145: Training loss 1.4847, Validation loss 21.6188, learning rate: 0.00080\n",
            "prediction loss: 0.2709, entropy regularization 0.0114\n",
            "Epoch 9150: Training loss 1.4763, Validation loss 21.6792, learning rate: 0.00079\n",
            "prediction loss: 0.2569, entropy regularization 0.0144\n",
            "Epoch 9155: Training loss 1.4453, Validation loss 21.3703, learning rate: 0.00078\n",
            "prediction loss: 0.2614, entropy regularization 0.0116\n",
            "Epoch 9160: Training loss 1.4304, Validation loss 21.6362, learning rate: 0.00077\n",
            "prediction loss: 0.2686, entropy regularization 0.0135\n",
            "Epoch 9165: Training loss 1.4313, Validation loss 21.5777, learning rate: 0.00075\n",
            "prediction loss: 0.2642, entropy regularization 0.0133\n",
            "Epoch 9170: Training loss 1.4128, Validation loss 21.5799, learning rate: 0.00074\n",
            "prediction loss: 0.2797, entropy regularization 0.0074\n",
            "Epoch 9175: Training loss 1.4150, Validation loss 21.5578, learning rate: 0.00072\n",
            "prediction loss: 0.2544, entropy regularization 0.0125\n",
            "Epoch 9180: Training loss 1.3755, Validation loss 21.3174, learning rate: 0.00071\n",
            "prediction loss: 0.2660, entropy regularization 0.0099\n",
            "Epoch 9185: Training loss 1.3784, Validation loss 21.6609, learning rate: 0.00070\n",
            "prediction loss: 0.2760, entropy regularization 0.0123\n",
            "Epoch 9190: Training loss 1.3504, Validation loss 21.5867, learning rate: 0.00068\n",
            "prediction loss: 0.2647, entropy regularization 0.0111\n",
            "Epoch 9195: Training loss 1.3202, Validation loss 21.5644, learning rate: 0.00067\n",
            "prediction loss: 0.2669, entropy regularization 0.0100\n",
            "Epoch 9200: Training loss 1.3063, Validation loss 21.4265, learning rate: 0.00065\n",
            "prediction loss: 0.2605, entropy regularization 0.0090\n",
            "Epoch 9205: Training loss 1.3111, Validation loss 21.6425, learning rate: 0.00064\n",
            "prediction loss: 0.2750, entropy regularization 0.0121\n",
            "Epoch 9210: Training loss 1.2919, Validation loss 21.5104, learning rate: 0.00062\n",
            "prediction loss: 0.2544, entropy regularization 0.0056\n",
            "Epoch 9215: Training loss 1.2703, Validation loss 21.3086, learning rate: 0.00061\n",
            "prediction loss: 0.2570, entropy regularization 0.0114\n",
            "Epoch 9220: Training loss 1.2611, Validation loss 21.3371, learning rate: 0.00059\n",
            "prediction loss: 0.2572, entropy regularization 0.0133\n",
            "Epoch 9225: Training loss 1.2932, Validation loss 21.4474, learning rate: 0.00058\n",
            "prediction loss: 0.2631, entropy regularization 0.0109\n",
            "Epoch 9230: Training loss 1.2382, Validation loss 21.3795, learning rate: 0.00056\n",
            "prediction loss: 0.2599, entropy regularization 0.0088\n",
            "Epoch 9235: Training loss 1.2223, Validation loss 21.3996, learning rate: 0.00054\n",
            "prediction loss: 0.2697, entropy regularization 0.0100\n",
            "Epoch 9240: Training loss 1.2307, Validation loss 21.3826, learning rate: 0.00053\n",
            "prediction loss: 0.2574, entropy regularization 0.0099\n",
            "Epoch 9245: Training loss 1.2434, Validation loss 21.4352, learning rate: 0.00051\n",
            "prediction loss: 0.2600, entropy regularization 0.0101\n",
            "Epoch 9250: Training loss 1.1992, Validation loss 21.4355, learning rate: 0.00050\n",
            "prediction loss: 0.2651, entropy regularization 0.0109\n",
            "Epoch 9255: Training loss 1.1844, Validation loss 21.3932, learning rate: 0.00048\n",
            "prediction loss: 0.2780, entropy regularization 0.0085\n",
            "Epoch 9260: Training loss 1.1830, Validation loss 21.4781, learning rate: 0.00047\n",
            "prediction loss: 0.2670, entropy regularization 0.0132\n",
            "Epoch 9265: Training loss 1.1879, Validation loss 21.3087, learning rate: 0.00045\n",
            "prediction loss: 0.2668, entropy regularization 0.0105\n",
            "Epoch 9270: Training loss 1.1859, Validation loss 21.4456, learning rate: 0.00043\n",
            "prediction loss: 0.2569, entropy regularization 0.0115\n",
            "Epoch 9275: Training loss 1.1595, Validation loss 21.5294, learning rate: 0.00042\n",
            "prediction loss: 0.2668, entropy regularization 0.0115\n",
            "Epoch 9280: Training loss 1.1838, Validation loss 21.4439, learning rate: 0.00040\n",
            "prediction loss: 0.2558, entropy regularization 0.0107\n",
            "Epoch 9285: Training loss 1.1478, Validation loss 21.4499, learning rate: 0.00039\n",
            "prediction loss: 0.2617, entropy regularization 0.0124\n",
            "Epoch 9290: Training loss 1.1539, Validation loss 21.4305, learning rate: 0.00037\n",
            "prediction loss: 0.2727, entropy regularization 0.0125\n",
            "Epoch 9295: Training loss 1.1424, Validation loss 21.3793, learning rate: 0.00036\n",
            "prediction loss: 0.2613, entropy regularization 0.0121\n",
            "Epoch 9300: Training loss 1.1335, Validation loss 21.4967, learning rate: 0.00034\n",
            "prediction loss: 0.2675, entropy regularization 0.0094\n",
            "Epoch 9305: Training loss 1.1149, Validation loss 21.5403, learning rate: 0.00033\n",
            "prediction loss: 0.2713, entropy regularization 0.0096\n",
            "Epoch 9310: Training loss 1.1510, Validation loss 21.4000, learning rate: 0.00031\n",
            "prediction loss: 0.2592, entropy regularization 0.0093\n",
            "Epoch 9315: Training loss 1.1509, Validation loss 21.3110, learning rate: 0.00030\n",
            "prediction loss: 0.2505, entropy regularization 0.0099\n",
            "Epoch 9320: Training loss 1.1047, Validation loss 21.5337, learning rate: 0.00028\n",
            "prediction loss: 0.2760, entropy regularization 0.0091\n",
            "Epoch 9325: Training loss 1.0894, Validation loss 21.6033, learning rate: 0.00027\n",
            "prediction loss: 0.2507, entropy regularization 0.0132\n",
            "Epoch 9330: Training loss 1.0986, Validation loss 21.5118, learning rate: 0.00026\n",
            "prediction loss: 0.2548, entropy regularization 0.0117\n",
            "Epoch 9335: Training loss 1.1145, Validation loss 21.6613, learning rate: 0.00024\n",
            "prediction loss: 0.2723, entropy regularization 0.0087\n",
            "Epoch 9340: Training loss 1.0740, Validation loss 21.5441, learning rate: 0.00023\n",
            "prediction loss: 0.2671, entropy regularization 0.0088\n",
            "Epoch 9345: Training loss 1.0763, Validation loss 21.6178, learning rate: 0.00022\n",
            "prediction loss: 0.2563, entropy regularization 0.0122\n",
            "Epoch 9350: Training loss 1.0666, Validation loss 21.6350, learning rate: 0.00020\n",
            "prediction loss: 0.2750, entropy regularization 0.0106\n",
            "Epoch 9355: Training loss 1.0684, Validation loss 21.6510, learning rate: 0.00019\n",
            "prediction loss: 0.2572, entropy regularization 0.0120\n",
            "Epoch 9360: Training loss 1.0657, Validation loss 21.5619, learning rate: 0.00018\n",
            "prediction loss: 0.2616, entropy regularization 0.0094\n",
            "Epoch 9365: Training loss 1.0613, Validation loss 21.6217, learning rate: 0.00017\n",
            "prediction loss: 0.2617, entropy regularization 0.0148\n",
            "Epoch 9370: Training loss 1.0506, Validation loss 21.6035, learning rate: 0.00016\n",
            "prediction loss: 0.2548, entropy regularization 0.0135\n",
            "Epoch 9375: Training loss 1.0455, Validation loss 21.5776, learning rate: 0.00014\n",
            "prediction loss: 0.2563, entropy regularization 0.0096\n",
            "Epoch 9380: Training loss 1.0421, Validation loss 21.6078, learning rate: 0.00013\n",
            "prediction loss: 0.2813, entropy regularization 0.0085\n",
            "Epoch 9385: Training loss 1.0433, Validation loss 21.7737, learning rate: 0.00012\n",
            "prediction loss: 0.2572, entropy regularization 0.0081\n",
            "Epoch 9390: Training loss 1.0351, Validation loss 21.7139, learning rate: 0.00011\n",
            "prediction loss: 0.2748, entropy regularization 0.0111\n",
            "Epoch 9395: Training loss 1.0383, Validation loss 21.6977, learning rate: 0.00010\n",
            "prediction loss: 0.2533, entropy regularization 0.0079\n",
            "Epoch 9400: Training loss 1.0307, Validation loss 21.6794, learning rate: 0.00009\n",
            "prediction loss: 0.2509, entropy regularization 0.0118\n",
            "Epoch 9405: Training loss 1.0297, Validation loss 21.7390, learning rate: 0.00008\n",
            "prediction loss: 0.2693, entropy regularization 0.0134\n",
            "Epoch 9410: Training loss 1.0266, Validation loss 21.7258, learning rate: 0.00008\n",
            "prediction loss: 0.2558, entropy regularization 0.0119\n",
            "Epoch 9415: Training loss 1.0278, Validation loss 21.7048, learning rate: 0.00007\n",
            "prediction loss: 0.2644, entropy regularization 0.0089\n",
            "Epoch 9420: Training loss 1.0268, Validation loss 21.7158, learning rate: 0.00006\n",
            "prediction loss: 0.2700, entropy regularization 0.0126\n",
            "Epoch 9425: Training loss 1.0187, Validation loss 21.7323, learning rate: 0.00005\n",
            "prediction loss: 0.2643, entropy regularization 0.0094\n",
            "Epoch 9430: Training loss 1.0194, Validation loss 21.7707, learning rate: 0.00005\n",
            "prediction loss: 0.2741, entropy regularization 0.0131\n",
            "Epoch 9435: Training loss 1.0163, Validation loss 21.7592, learning rate: 0.00004\n",
            "prediction loss: 0.2522, entropy regularization 0.0105\n",
            "Epoch 9440: Training loss 1.0183, Validation loss 21.7633, learning rate: 0.00003\n",
            "prediction loss: 0.2671, entropy regularization 0.0127\n",
            "Epoch 9445: Training loss 1.0147, Validation loss 21.7494, learning rate: 0.00003\n",
            "prediction loss: 0.2584, entropy regularization 0.0088\n",
            "Epoch 9450: Training loss 1.0158, Validation loss 21.7489, learning rate: 0.00002\n",
            "prediction loss: 0.2543, entropy regularization 0.0106\n",
            "Epoch 9455: Training loss 1.0125, Validation loss 21.7531, learning rate: 0.00002\n",
            "prediction loss: 0.2506, entropy regularization 0.0102\n",
            "Epoch 9460: Training loss 1.0136, Validation loss 21.7661, learning rate: 0.00001\n",
            "prediction loss: 0.2438, entropy regularization 0.0125\n",
            "Epoch 9465: Training loss 1.0136, Validation loss 21.7474, learning rate: 0.00001\n",
            "prediction loss: 0.2652, entropy regularization 0.0050\n",
            "Epoch 9470: Training loss 1.0155, Validation loss 21.7484, learning rate: 0.00001\n",
            "prediction loss: 0.2716, entropy regularization 0.0142\n",
            "Epoch 9475: Training loss 1.0098, Validation loss 21.7552, learning rate: 0.00001\n",
            "prediction loss: 0.2588, entropy regularization 0.0098\n",
            "Epoch 9480: Training loss 1.0149, Validation loss 21.7534, learning rate: 0.00000\n",
            "prediction loss: 0.2516, entropy regularization 0.0099\n",
            "Epoch 9485: Training loss 1.0129, Validation loss 21.7534, learning rate: 0.00000\n",
            "prediction loss: 0.2679, entropy regularization 0.0090\n",
            "Epoch 9490: Training loss 1.0080, Validation loss 21.7526, learning rate: 0.00000\n",
            "prediction loss: 0.2638, entropy regularization 0.0117\n",
            "Epoch 9495: Training loss 1.0133, Validation loss 21.7533, learning rate: 0.00000\n",
            "prediction loss: 0.2748, entropy regularization 0.0135\n",
            "Epoch 9500: Training loss 1.0481, Validation loss 22.1387, learning rate: 0.00100\n",
            "prediction loss: 0.2494, entropy regularization 0.0087\n",
            "Epoch 9505: Training loss 1.2953, Validation loss 22.4308, learning rate: 0.00100\n",
            "prediction loss: 0.2545, entropy regularization 0.0112\n",
            "Epoch 9510: Training loss 1.1195, Validation loss 21.7531, learning rate: 0.00100\n",
            "prediction loss: 0.2763, entropy regularization 0.0133\n",
            "Epoch 9515: Training loss 1.1020, Validation loss 21.2210, learning rate: 0.00100\n",
            "prediction loss: 0.2728, entropy regularization 0.0095\n",
            "Epoch 9520: Training loss 1.0050, Validation loss 21.8194, learning rate: 0.00100\n",
            "prediction loss: 0.2459, entropy regularization 0.0135\n",
            "Epoch 9525: Training loss 1.0074, Validation loss 21.7909, learning rate: 0.00099\n",
            "prediction loss: 0.2594, entropy regularization 0.0087\n",
            "Epoch 9530: Training loss 0.9454, Validation loss 21.7648, learning rate: 0.00099\n",
            "prediction loss: 0.2691, entropy regularization 0.0123\n",
            "Epoch 9535: Training loss 1.0174, Validation loss 21.4055, learning rate: 0.00099\n",
            "prediction loss: 0.2728, entropy regularization 0.0094\n",
            "Epoch 9540: Training loss 0.8736, Validation loss 21.5441, learning rate: 0.00098\n",
            "prediction loss: 0.2637, entropy regularization 0.0151\n",
            "Epoch 9545: Training loss 0.8706, Validation loss 21.6382, learning rate: 0.00098\n",
            "prediction loss: 0.2496, entropy regularization 0.0083\n",
            "Epoch 9550: Training loss 0.8507, Validation loss 21.4273, learning rate: 0.00097\n",
            "prediction loss: 0.2565, entropy regularization 0.0104\n",
            "Epoch 9555: Training loss 0.9179, Validation loss 21.3013, learning rate: 0.00097\n",
            "prediction loss: 0.2626, entropy regularization 0.0133\n",
            "Epoch 9560: Training loss 0.8131, Validation loss 21.3844, learning rate: 0.00096\n",
            "prediction loss: 0.2743, entropy regularization 0.0125\n",
            "Epoch 9565: Training loss 0.8332, Validation loss 21.6414, learning rate: 0.00096\n",
            "prediction loss: 0.2643, entropy regularization 0.0129\n",
            "Epoch 9570: Training loss 0.7599, Validation loss 21.5099, learning rate: 0.00095\n",
            "prediction loss: 0.2590, entropy regularization 0.0121\n",
            "Epoch 9575: Training loss 0.7929, Validation loss 21.4138, learning rate: 0.00094\n",
            "prediction loss: 0.2606, entropy regularization 0.0088\n",
            "Epoch 9580: Training loss 0.7171, Validation loss 21.6704, learning rate: 0.00094\n",
            "prediction loss: 0.2626, entropy regularization 0.0135\n",
            "Epoch 9585: Training loss 0.6822, Validation loss 21.4421, learning rate: 0.00093\n",
            "prediction loss: 0.2676, entropy regularization 0.0088\n",
            "Epoch 9590: Training loss 0.7853, Validation loss 21.4586, learning rate: 0.00092\n",
            "prediction loss: 0.2643, entropy regularization 0.0098\n",
            "Epoch 9595: Training loss 0.6353, Validation loss 21.4251, learning rate: 0.00091\n",
            "prediction loss: 0.2555, entropy regularization 0.0079\n",
            "Epoch 9600: Training loss 0.6323, Validation loss 21.4847, learning rate: 0.00090\n",
            "prediction loss: 0.2548, entropy regularization 0.0122\n",
            "Epoch 9605: Training loss 0.7239, Validation loss 21.7608, learning rate: 0.00089\n",
            "prediction loss: 0.2611, entropy regularization 0.0134\n",
            "Epoch 9610: Training loss 0.6672, Validation loss 21.5627, learning rate: 0.00088\n",
            "prediction loss: 0.2548, entropy regularization 0.0140\n",
            "Epoch 9615: Training loss 0.6102, Validation loss 21.8147, learning rate: 0.00087\n",
            "prediction loss: 0.2641, entropy regularization 0.0116\n",
            "Epoch 9620: Training loss 0.6070, Validation loss 21.6347, learning rate: 0.00086\n",
            "prediction loss: 0.2721, entropy regularization 0.0069\n",
            "Epoch 9625: Training loss 0.6679, Validation loss 21.9514, learning rate: 0.00085\n",
            "prediction loss: 0.2639, entropy regularization 0.0109\n",
            "Epoch 9630: Training loss 0.5569, Validation loss 21.8198, learning rate: 0.00084\n",
            "prediction loss: 0.2591, entropy regularization 0.0125\n",
            "Epoch 9635: Training loss 0.5666, Validation loss 21.8541, learning rate: 0.00083\n",
            "prediction loss: 0.2648, entropy regularization 0.0132\n",
            "Epoch 9640: Training loss 0.5409, Validation loss 21.5029, learning rate: 0.00082\n",
            "prediction loss: 0.2569, entropy regularization 0.0124\n",
            "Epoch 9645: Training loss 0.5214, Validation loss 22.2046, learning rate: 0.00080\n",
            "prediction loss: 0.2650, entropy regularization 0.0113\n",
            "Epoch 9650: Training loss 0.5675, Validation loss 21.9839, learning rate: 0.00079\n",
            "prediction loss: 0.2643, entropy regularization 0.0127\n",
            "Epoch 9655: Training loss 0.4889, Validation loss 22.0789, learning rate: 0.00078\n",
            "prediction loss: 0.2803, entropy regularization 0.0137\n",
            "Epoch 9660: Training loss 0.5242, Validation loss 22.1523, learning rate: 0.00077\n",
            "prediction loss: 0.2553, entropy regularization 0.0093\n",
            "Epoch 9665: Training loss 0.4560, Validation loss 22.3706, learning rate: 0.00075\n",
            "prediction loss: 0.2602, entropy regularization 0.0121\n",
            "Epoch 9670: Training loss 0.5247, Validation loss 22.1506, learning rate: 0.00074\n",
            "prediction loss: 0.2733, entropy regularization 0.0113\n",
            "Epoch 9675: Training loss 0.4397, Validation loss 22.0568, learning rate: 0.00072\n",
            "prediction loss: 0.2638, entropy regularization 0.0104\n",
            "Epoch 9680: Training loss 0.4555, Validation loss 22.1348, learning rate: 0.00071\n",
            "prediction loss: 0.2497, entropy regularization 0.0146\n",
            "Epoch 9685: Training loss 0.4340, Validation loss 22.1104, learning rate: 0.00070\n",
            "prediction loss: 0.2616, entropy regularization 0.0111\n",
            "Epoch 9690: Training loss 0.4124, Validation loss 22.3869, learning rate: 0.00068\n",
            "prediction loss: 0.2732, entropy regularization 0.0113\n",
            "Epoch 9695: Training loss 0.4634, Validation loss 21.7774, learning rate: 0.00067\n",
            "prediction loss: 0.2686, entropy regularization 0.0113\n",
            "Epoch 9700: Training loss 0.4059, Validation loss 21.6714, learning rate: 0.00065\n",
            "prediction loss: 0.2694, entropy regularization 0.0094\n",
            "Epoch 9705: Training loss 0.3921, Validation loss 21.5579, learning rate: 0.00064\n",
            "prediction loss: 0.2603, entropy regularization 0.0086\n",
            "Epoch 9710: Training loss 0.3919, Validation loss 21.6878, learning rate: 0.00062\n",
            "prediction loss: 0.2810, entropy regularization 0.0107\n",
            "Epoch 9715: Training loss 0.3611, Validation loss 21.4915, learning rate: 0.00061\n",
            "prediction loss: 0.2678, entropy regularization 0.0146\n",
            "Epoch 9720: Training loss 0.3972, Validation loss 21.4847, learning rate: 0.00059\n",
            "prediction loss: 0.2532, entropy regularization 0.0125\n",
            "Epoch 9725: Training loss 0.3673, Validation loss 21.5163, learning rate: 0.00058\n",
            "prediction loss: 0.2602, entropy regularization 0.0085\n",
            "Epoch 9730: Training loss 0.3567, Validation loss 21.2655, learning rate: 0.00056\n",
            "prediction loss: 0.2624, entropy regularization 0.0104\n",
            "Epoch 9735: Training loss 0.4408, Validation loss 21.6393, learning rate: 0.00054\n",
            "prediction loss: 0.2659, entropy regularization 0.0125\n",
            "Epoch 9740: Training loss 0.3581, Validation loss 21.1505, learning rate: 0.00053\n",
            "prediction loss: 0.2513, entropy regularization 0.0102\n",
            "Epoch 9745: Training loss 0.3136, Validation loss 21.3543, learning rate: 0.00051\n",
            "prediction loss: 0.2680, entropy regularization 0.0086\n",
            "Epoch 9750: Training loss 0.3713, Validation loss 21.3634, learning rate: 0.00050\n",
            "prediction loss: 0.2723, entropy regularization 0.0138\n",
            "Epoch 9755: Training loss 0.3465, Validation loss 21.3015, learning rate: 0.00048\n",
            "prediction loss: 0.2516, entropy regularization 0.0093\n",
            "Epoch 9760: Training loss 0.3298, Validation loss 21.0445, learning rate: 0.00047\n",
            "prediction loss: 0.2594, entropy regularization 0.0096\n",
            "Epoch 9765: Training loss 0.3026, Validation loss 21.1046, learning rate: 0.00045\n",
            "prediction loss: 0.2775, entropy regularization 0.0088\n",
            "Epoch 9770: Training loss 0.3136, Validation loss 21.2435, learning rate: 0.00043\n",
            "prediction loss: 0.2516, entropy regularization 0.0113\n",
            "Epoch 9775: Training loss 0.2873, Validation loss 20.9401, learning rate: 0.00042\n",
            "prediction loss: 0.2642, entropy regularization 0.0084\n",
            "Epoch 9780: Training loss 0.2774, Validation loss 21.0454, learning rate: 0.00040\n",
            "prediction loss: 0.2541, entropy regularization 0.0123\n",
            "Epoch 9785: Training loss 0.2700, Validation loss 21.0629, learning rate: 0.00039\n",
            "prediction loss: 0.2610, entropy regularization 0.0089\n",
            "Epoch 9790: Training loss 0.2762, Validation loss 21.1081, learning rate: 0.00037\n",
            "prediction loss: 0.2559, entropy regularization 0.0091\n",
            "Epoch 9795: Training loss 0.2732, Validation loss 21.0048, learning rate: 0.00036\n",
            "prediction loss: 0.2630, entropy regularization 0.0120\n",
            "Epoch 9800: Training loss 0.2605, Validation loss 21.0467, learning rate: 0.00034\n",
            "prediction loss: 0.2560, entropy regularization 0.0122\n",
            "Epoch 9805: Training loss 0.2472, Validation loss 20.8993, learning rate: 0.00033\n",
            "prediction loss: 0.2799, entropy regularization 0.0089\n",
            "Epoch 9810: Training loss 0.2440, Validation loss 21.0605, learning rate: 0.00031\n",
            "prediction loss: 0.2571, entropy regularization 0.0123\n",
            "Epoch 9815: Training loss 0.2594, Validation loss 20.9793, learning rate: 0.00030\n",
            "prediction loss: 0.2608, entropy regularization 0.0111\n",
            "Epoch 9820: Training loss 0.2402, Validation loss 20.9097, learning rate: 0.00028\n",
            "prediction loss: 0.2526, entropy regularization 0.0149\n",
            "Epoch 9825: Training loss 0.2334, Validation loss 20.9669, learning rate: 0.00027\n",
            "prediction loss: 0.2611, entropy regularization 0.0067\n",
            "Epoch 9830: Training loss 0.2382, Validation loss 21.0653, learning rate: 0.00026\n",
            "prediction loss: 0.2596, entropy regularization 0.0117\n",
            "Epoch 9835: Training loss 0.2267, Validation loss 20.8224, learning rate: 0.00024\n",
            "prediction loss: 0.2646, entropy regularization 0.0120\n",
            "Epoch 9840: Training loss 0.2229, Validation loss 20.9198, learning rate: 0.00023\n",
            "prediction loss: 0.2657, entropy regularization 0.0115\n",
            "Epoch 9845: Training loss 0.2229, Validation loss 20.8639, learning rate: 0.00022\n",
            "prediction loss: 0.2674, entropy regularization 0.0105\n",
            "Epoch 9850: Training loss 0.2186, Validation loss 20.9003, learning rate: 0.00020\n",
            "prediction loss: 0.2468, entropy regularization 0.0114\n",
            "Epoch 9855: Training loss 0.2213, Validation loss 20.8519, learning rate: 0.00019\n",
            "prediction loss: 0.2574, entropy regularization 0.0079\n",
            "Epoch 9860: Training loss 0.2105, Validation loss 20.8907, learning rate: 0.00018\n",
            "prediction loss: 0.2630, entropy regularization 0.0103\n",
            "Epoch 9865: Training loss 0.2145, Validation loss 20.8763, learning rate: 0.00017\n",
            "prediction loss: 0.2516, entropy regularization 0.0134\n",
            "Epoch 9870: Training loss 0.2081, Validation loss 20.8796, learning rate: 0.00016\n",
            "prediction loss: 0.2695, entropy regularization 0.0076\n",
            "Epoch 9875: Training loss 0.2102, Validation loss 20.9359, learning rate: 0.00014\n",
            "prediction loss: 0.2587, entropy regularization 0.0075\n",
            "Epoch 9880: Training loss 0.2040, Validation loss 20.8677, learning rate: 0.00013\n",
            "prediction loss: 0.2537, entropy regularization 0.0076\n",
            "Epoch 9885: Training loss 0.2020, Validation loss 20.8646, learning rate: 0.00012\n",
            "prediction loss: 0.2348, entropy regularization 0.0109\n",
            "Epoch 9890: Training loss 0.1989, Validation loss 20.8821, learning rate: 0.00011\n",
            "prediction loss: 0.2670, entropy regularization 0.0117\n",
            "Epoch 9895: Training loss 0.1977, Validation loss 20.8421, learning rate: 0.00010\n",
            "prediction loss: 0.2624, entropy regularization 0.0159\n",
            "Epoch 9900: Training loss 0.2018, Validation loss 20.9182, learning rate: 0.00009\n",
            "prediction loss: 0.2714, entropy regularization 0.0083\n",
            "Epoch 9905: Training loss 0.1940, Validation loss 20.8714, learning rate: 0.00008\n",
            "prediction loss: 0.2634, entropy regularization 0.0142\n",
            "Epoch 9910: Training loss 0.1937, Validation loss 20.8694, learning rate: 0.00008\n",
            "prediction loss: 0.2420, entropy regularization 0.0069\n",
            "Epoch 9915: Training loss 0.1919, Validation loss 20.8797, learning rate: 0.00007\n",
            "prediction loss: 0.2620, entropy regularization 0.0103\n",
            "Epoch 9920: Training loss 0.1921, Validation loss 20.8486, learning rate: 0.00006\n",
            "prediction loss: 0.2702, entropy regularization 0.0128\n",
            "Epoch 9925: Training loss 0.1886, Validation loss 20.8862, learning rate: 0.00005\n",
            "prediction loss: 0.2574, entropy regularization 0.0092\n",
            "Epoch 9930: Training loss 0.1908, Validation loss 20.8600, learning rate: 0.00005\n",
            "prediction loss: 0.2746, entropy regularization 0.0118\n",
            "Epoch 9935: Training loss 0.1915, Validation loss 20.8458, learning rate: 0.00004\n",
            "prediction loss: 0.2757, entropy regularization 0.0137\n",
            "Epoch 9940: Training loss 0.1896, Validation loss 20.8674, learning rate: 0.00003\n",
            "prediction loss: 0.2675, entropy regularization 0.0099\n",
            "Epoch 9945: Training loss 0.1881, Validation loss 20.8566, learning rate: 0.00003\n",
            "prediction loss: 0.2505, entropy regularization 0.0127\n",
            "Epoch 9950: Training loss 0.1883, Validation loss 20.8571, learning rate: 0.00002\n",
            "prediction loss: 0.2653, entropy regularization 0.0116\n",
            "Epoch 9955: Training loss 0.1871, Validation loss 20.8543, learning rate: 0.00002\n",
            "prediction loss: 0.2624, entropy regularization 0.0105\n",
            "Epoch 9960: Training loss 0.1877, Validation loss 20.8626, learning rate: 0.00001\n",
            "prediction loss: 0.2593, entropy regularization 0.0078\n",
            "Epoch 9965: Training loss 0.1846, Validation loss 20.8473, learning rate: 0.00001\n",
            "prediction loss: 0.2600, entropy regularization 0.0136\n",
            "Epoch 9970: Training loss 0.1862, Validation loss 20.8552, learning rate: 0.00001\n",
            "prediction loss: 0.2604, entropy regularization 0.0143\n",
            "Epoch 9975: Training loss 0.1852, Validation loss 20.8545, learning rate: 0.00001\n",
            "prediction loss: 0.2623, entropy regularization 0.0156\n",
            "Epoch 9980: Training loss 0.1846, Validation loss 20.8522, learning rate: 0.00000\n",
            "prediction loss: 0.2685, entropy regularization 0.0110\n",
            "Epoch 9985: Training loss 0.1847, Validation loss 20.8513, learning rate: 0.00000\n",
            "prediction loss: 0.2591, entropy regularization 0.0088\n",
            "Epoch 9990: Training loss 0.1847, Validation loss 20.8510, learning rate: 0.00000\n",
            "prediction loss: 0.2562, entropy regularization 0.0113\n",
            "Epoch 9995: Training loss 0.1849, Validation loss 20.8509, learning rate: 0.00000\n",
            "prediction loss: 0.2645, entropy regularization 0.0087\n",
            "Training took 1.52 hours\n",
            "Minimum Training Loss 0.0000 in epoch 6497\n",
            "Minimum Validation Loss 12.9307 in epoch 2000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Training\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "import time\n",
        "start = time.perf_counter()\n",
        "\n",
        "model = Diff_CG_Classifier().to(device)\n",
        "\n",
        "b_size = 64\n",
        "train_dataloader = DenseDataLoader(training_dataset, batch_size=b_size, shuffle=True) #DenseDataLoader(training_dataset, batch_size=b_size, shuffle=True) #\n",
        "val_dataloader = DenseDataLoader(val_dataset, batch_size=b_size) #DenseDataLoader(val_dataset, batch_size=b_size) #\n",
        "\n",
        "opt = th.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = th.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=500)#, T_mult=2)\n",
        "model.train()\n",
        "\n",
        "epochs = 10000\n",
        "\n",
        "#training setup\n",
        "epoch_losses = []\n",
        "val_losses = []\n",
        "learning_rates = []\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    learning_rates.append(scheduler.get_last_lr()[0])\n",
        "    for iter, data in enumerate(train_dataloader):\n",
        "        data = data.to(device)\n",
        "        opt.zero_grad()\n",
        "        pred, l, e = model(data) #, l, e\n",
        "        loss = F.smooth_l1_loss(pred, data.y, reduction='mean') #(th.reshape(pred, (-1,)), data.y, reduction='mean')\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        epoch_loss += loss.detach().item()\n",
        "\n",
        "    #apply lr changes according to scheme\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss /= (iter + 1)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "\n",
        "    #val setup\n",
        "    val_loss = 0\n",
        "    for i, v_data in enumerate(val_dataloader):\n",
        "        v_data = v_data.to(device)\n",
        "        val_pred, _, _ = model(v_data)\n",
        "        v_loss = F.smooth_l1_loss(val_pred, v_data.y, reduction='mean') #(th.reshape(val_pred, (-1,)), v_data.y, reduction='mean')\n",
        "        val_loss += v_loss.detach().item()\n",
        "\n",
        "    val_loss /= (i + 1)\n",
        "    \n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    \n",
        "    th.save(model.state_dict(), \"pyg_model_data/model_epoch\" + str(epoch) + \".pth\")\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch {}: Training loss {:.4f}, Validation loss {:.4f}, learning rate: {:.5f}\".format(epoch, epoch_loss, val_loss, scheduler.get_last_lr()[0]))\n",
        "        print(\"prediction loss: {:.4f}, entropy regularization {:.4f}\".format(l, e))\n",
        "        \n",
        "end = time.perf_counter()\n",
        "\n",
        "print(\"Training took {:.2f} hours\".format((end - start)/60/60))\n",
        "print(\"Minimum Training Loss {:.4f} in epoch {}\".format(min(epoch_losses), epoch_losses.index(min(epoch_losses))))\n",
        "print(\"Minimum Validation Loss {:.4f} in epoch {}\".format(min(val_losses), val_losses.index(min(val_losses))))\n",
        "\n",
        "#plot the training run\n",
        "figure, ax = plt.subplots(layout='constrained', figsize=(20, 6))\n",
        "ax.plot(epoch_losses)\n",
        "ax.plot(val_losses, 'r')\n",
        "plt.title(\"Training Loss\")\n",
        "ax.set_ybound(lower=0, upper=20)\n",
        "plt.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "2cbc0e79",
      "metadata": {},
      "outputs": [],
      "source": [
        "#store training run data\n",
        "\n",
        "file = \"pyg_loss_data_2022-02-17.txt\"\n",
        "\n",
        "with open(\"data/\" + file, \"w\") as fh:\n",
        "    fh.write(str(epoch_losses) + \"\\n\")\n",
        "    fh.write(str(val_losses) + \"\\n\")\n",
        "    fh.write(str(learning_rates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa41972f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum Training Loss 0.0002 in epoch 999\n",
            "Minimum Validation Loss 13.1550 in epoch 607\n"
          ]
        }
      ],
      "source": [
        "#get training run data\n",
        "\n",
        "file = \"pyg_loss_data_2022-02-15.txt\"\n",
        "\n",
        "file_lines = []\n",
        "with open(\"data/\" + file, \"r\") as fh:\n",
        "    for line in fh.readlines():\n",
        "        file_lines.append(line.rstrip(\"]\\n\").lstrip(\"[\").split(\",\"))\n",
        "\n",
        "epoch_losses = [float(a) for a in file_lines[0]]\n",
        "val_losses = [float(b) for b in file_lines[1]]\n",
        "learning_rates = [float(c) for c in file_lines[2]]\n",
        "\n",
        "print(\"Minimum Training Loss {:.4f} in epoch {}\".format(min(epoch_losses), epoch_losses.index(min(epoch_losses))))\n",
        "print(\"Minimum Validation Loss {:.4f} in epoch {}\".format(min(val_losses), val_losses.index(min(val_losses))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "ed5b41a5-5213-49df-bd67-9984f67183f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ed5b41a5-5213-49df-bd67-9984f67183f5",
        "outputId": "4a0594fa-255d-4bf4-fb4b-55f761a3b36c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot the training run\n",
        "fig, ax1 = plt.subplots(layout='constrained', figsize=(20, 6))\n",
        "ax1.secondary_yaxis('left')\n",
        "ax1.plot(epoch_losses)\n",
        "ax1.plot(val_losses, 'r')\n",
        "ax2 = ax1.twinx()\n",
        "ax2.secondary_yaxis('right')\n",
        "ax2.plot(learning_rates, 'g')\n",
        "plt.title(\"Training Loss\")\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"RMSD loss\")\n",
        "ax2.set_ylabel(\"Learning rate\")\n",
        "ax1.set_ybound(lower=0, upper=20)\n",
        "plt.axvline(x = 600, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 96, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 145, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 190, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 250, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 321, c = 'black', ls = ':')\n",
        "#plt.axvline(x = 404, c = 'black', ls = ':')\n",
        "plt.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "AArBQDKxIIBf",
      "metadata": {
        "id": "AArBQDKxIIBf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#Test Data\n",
        "test_dir = \"data/test_set\"\n",
        "test_rmsd = \"data/test_rmsd_list.txt\"\n",
        "\n",
        "test_dataset = CGDataset(test_dir, test_rmsd, transform=T.ToDense(64))\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "ec282f99",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#5S rRNA and tRNA Test Data (previous training data)\n",
        "st_test_dir = \"data/old_training_set\"\n",
        "st_test_rmsd = \"data/old_train_rmsd_list.txt\"\n",
        "\n",
        "st_test_dataset = CGDataset(st_test_dir, st_test_rmsd, transform=T.ToDense(64))\n",
        "\n",
        "st_test_dataloader = DataLoader(st_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "eUo0_OJpxrV4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "eUo0_OJpxrV4",
        "outputId": "6bde702c-94a8-45dc-a654-8776f0b9a111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Test Set\n",
            "tensor([23.4710], device='cuda:0') tensor([[23.3951]], device='cuda:0') 0.07589530944824219\n",
            "tensor([0.], device='cuda:0') tensor([[103.0402]], device='cuda:0') 103.04022979736328\n",
            "Mean Test loss: \t 17.7584\n",
            "Std. Dev. of Test loss:  18.8861\n",
            "Min loss: \t\t 0.0759\n",
            "First Quantile: \t 6.1646\n",
            "Median: \t\t 11.1980\n",
            "Third Quantile: \t 20.5713\n",
            "Max Loss: \t\t 103.0402\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5S rRNA and tRNA Test Set\n",
            "tensor([19.2860], device='cuda:0') tensor([[19.3007]], device='cuda:0') 0.014734268188476562\n",
            "tensor([0.], device='cuda:0') tensor([[114.8037]], device='cuda:0') 114.80374908447266\n",
            "Mean Test loss: \t 8.8823\n",
            "Std. Dev. of Test loss:  15.8764\n",
            "Min loss: \t\t 0.0147\n",
            "First Quantile: \t 1.8366\n",
            "Median: \t\t 3.9895\n",
            "Third Quantile: \t 7.1819\n",
            "Max Loss: \t\t 114.8037\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Test\n",
        "import math\n",
        "\n",
        "if \"model\" not in globals():\n",
        "    model = Diff_CG_Classifier(num_features=3)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.load_state_dict(th.load(\"pyg_model_data/model_epoch5400.pth\"))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with th.no_grad():\n",
        "    for loader in [test_dataloader, st_test_dataloader]:\n",
        "        max_label = 0\n",
        "        max_loss = 0\n",
        "        max_pred = 0\n",
        "        min_label = math.inf\n",
        "        min_loss = math.inf\n",
        "        min_pred = math.inf\n",
        "        test_losses = []\n",
        "        for test_graph in loader:\n",
        "            test_graph = test_graph.to(device)\n",
        "            test_pred, _, _ = model(test_graph)\n",
        "            test_loss = F.l1_loss(th.reshape(test_pred, (-1,)), test_graph.y).item() #smooth_l1_loss #(test_pred, test_graph.y).item() #\n",
        "            test_losses.append(test_loss)\n",
        "            if test_loss > max_loss:\n",
        "                max_loss = test_loss\n",
        "                max_label = test_graph.y\n",
        "                max_pred = test_pred\n",
        "            if test_loss < min_loss:\n",
        "                min_loss = test_loss\n",
        "                min_label = test_graph.y\n",
        "                min_pred = test_pred\n",
        "            if test_pred < 0:\n",
        "                print(test_graph.y, test_pred)\n",
        "\n",
        "        if loader == test_dataloader:\n",
        "            print(\"Normal Test Set\")\n",
        "        elif loader == st_test_dataloader:\n",
        "            print(\"5S rRNA and tRNA Test Set\")\n",
        "        print(min_label, min_pred, min_loss)\n",
        "        print(max_label, max_pred, max_loss)\n",
        "        test_mean = np.mean(test_losses)\n",
        "        test_std = np.std(test_losses)\n",
        "        test_fq = np.quantile(test_losses, q = 0.25)\n",
        "        test_median = np.median(test_losses)\n",
        "        test_tq = np.quantile(test_losses, q = 0.75)\n",
        "        print(\"Mean Test loss: \\t {:.4f}\".format(test_mean))\n",
        "        print(\"Std. Dev. of Test loss:  {:.4f}\".format(test_std))\n",
        "        print(\"Min loss: \\t\\t {:.4f}\".format(min(test_losses)))\n",
        "        print(\"First Quantile: \\t {:.4f}\".format(test_fq))\n",
        "        print(\"Median: \\t\\t {:.4f}\".format(test_median))\n",
        "        print(\"Third Quantile: \\t {:.4f}\".format(test_tq))\n",
        "        print(\"Max Loss: \\t\\t {:.4f}\".format(max(test_losses)))\n",
        "\n",
        "        #print(sorted(test_losses)[-5:])\n",
        "\n",
        "        fig, axs = plt.subplots(layout='constrained', figsize=(8, 6))\n",
        "        axs.plot(sorted(test_losses))\n",
        "        #plt.title(\"Sorted Test Losses\")\n",
        "        if loader == test_dataloader:\n",
        "            plt.title(\"Sorted Test Losses, Normal Test Set\")\n",
        "        elif loader == st_test_dataloader:\n",
        "            plt.title(\"Sorted Test Losses, 5S and tRNA Test Set\")\n",
        "        plt.ylabel(\"RMSD Loss\")\n",
        "        plt.xlabel(\"Structures\")\n",
        "        plt.axhline(y = test_fq, color = 'r')\n",
        "        plt.axhline(y = test_median, color = 'r')\n",
        "        plt.axhline(y = test_tq, color = 'r')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1a1064-da56-4fab-9ce5-fc0aa0952ef0",
      "metadata": {
        "id": "fb1a1064-da56-4fab-9ce5-fc0aa0952ef0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "3d_classifier_PyG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
    "outputId": "1f82f46b-4bc1-4923-f4b0-e78024ee5894"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "[13:33:55] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#!pip install dgl\n",
    "#!DGLBACKEND=pytorch\n",
    "#!export $DGLBACKEND\n",
    "#import os\n",
    "#os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "#print(os.environ[\"DGLBACKEND\"])\n",
    "import dgl\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import torch as th\n",
    "\n",
    "#!pip install forgi\n",
    "import forgi\n",
    "import forgi.graph.bulge_graph as fgb\n",
    "import forgi.threedee as ft\n",
    "import forgi.threedee.model.coarse_grain as ftmc\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_MuRd2MIU0bz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_MuRd2MIU0bz",
    "outputId": "7c8d9f48-f053-4bbe-9939-1db458bbf3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(th.__version__)\n",
    "print(th.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n2IxR1AxZdYn",
   "metadata": {
    "id": "n2IxR1AxZdYn"
   },
   "source": [
    "\n",
    "Ideas: \n",
    "*   load coarse grain representation with forgi,\n",
    "*   use forgi to form a graph with nodes labeled as s/i/o/.. and twist, length, angle,...\n",
    "*   use that graph to feed into model\n",
    "*   use dgl.save_graph() to store a graph, so the structure can be used for several steps?\n",
    "*   use forgi.threedee.model.coarse_grain.CoarseGrainRNA.rotate() to rotate cg RNAs and see if the classification changes\n",
    "\n",
    "TODO:\n",
    "*  automate linking of labels to cg structures!\n",
    "*  future --> find where ernwin writes/stores output of structure for each n steps\n",
    "*  finetune the model\n",
    "*  make larger batch of training data for testing\n",
    "*  include logger (maybe wandb?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "81afa4b6-ee92-4662-826b-de338ca595cf",
   "metadata": {
    "id": "81afa4b6-ee92-4662-826b-de338ca595cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Graph Building\n",
    "\n",
    "#load coarse grain file\n",
    "def load_cg_file(file): \n",
    "    cg = ftmc.CoarseGrainRNA.from_bg_file(file) \n",
    "    c_dict = dict(cg.coords)\n",
    "    t_dict = dict(cg.twists)\n",
    "    coord_dict = {}\n",
    "    twist_dict = {}\n",
    "    for e in c_dict:\n",
    "        a = th.from_numpy(c_dict[e][0])\n",
    "        b = th.from_numpy(c_dict[e][1])\n",
    "        coord_dict[e] = a, b\n",
    "        if e in t_dict:\n",
    "            c = th.from_numpy(t_dict[e][0])\n",
    "            d = th.from_numpy(t_dict[e][1])\n",
    "            twist_dict[e] = c, d\n",
    "        \n",
    "    # Get elements and neighbours:\n",
    "    connections = {}\n",
    "    for elem in cg.sorted_element_iterator():\n",
    "        neighbours = cg.connections(elem)\n",
    "        if elem not in connections:\n",
    "            connections[elem] = cg.connections(elem)\n",
    "    return coord_dict, twist_dict, connections\n",
    "\n",
    "def build_dgl_graph(coord_dict, twist_dict, connections):\n",
    "    #dictionary to convert type\n",
    "    type_transl = {\n",
    "        \"h\": [1, 0, 0, 0, 0, 0],\n",
    "        \"i\": [0, 1, 0, 0, 0, 0],\n",
    "        \"m\": [0, 0, 1, 0, 0, 0],\n",
    "        \"s\": [0, 0, 0, 1, 0, 0],\n",
    "        \"f\": [0, 0, 0, 0, 1, 0],\n",
    "        \"t\": [0, 0, 0, 0, 0, 1]\n",
    "    } \n",
    "\n",
    "    #encode nodes numerically for dgl graph\n",
    "    num_graph = {}\n",
    "    elem_count = {}\n",
    "    for num, n in enumerate(sorted(connections)):\n",
    "        num_graph[n] = num\n",
    "        if n[0] not in elem_count:\n",
    "            elem_count[n[0]] = 1\n",
    "        else:\n",
    "            elem_count[n[0]] += 1\n",
    "\n",
    "    #build graph and edges\n",
    "    u = []\n",
    "    v = []\n",
    "    for node in connections:\n",
    "        for c in connections[node]:\n",
    "            u.append(num_graph[node])\n",
    "            v.append(num_graph[c])\n",
    "\n",
    "    graph = dgl.graph((th.tensor(u), th.tensor(v)))\n",
    "\n",
    "    #initialise node attributes\n",
    "    graph.ndata[\"type\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32)\n",
    "    graph.ndata[\"coord\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32) #seperate coords into 2 sets of 3, so that the information of start and end is added?\n",
    "    graph.ndata[\"twist\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32)\n",
    "\n",
    "    for elem in connections:\n",
    "        graph.ndata[\"type\"][num_graph[elem]] = th.tensor(type_transl[elem[0]], dtype=th.float32) \n",
    "        graph.ndata[\"coord\"][num_graph[elem]] = th.tensor(np.concatenate(coord_dict[elem]), dtype=th.float32)\n",
    "        if elem in twist_dict:\n",
    "            graph.ndata[\"twist\"][num_graph[elem]] = th.tensor(np.concatenate(twist_dict[elem]), dtype=th.float32)\n",
    "  \n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ZU_znRFH141n",
   "metadata": {
    "id": "ZU_znRFH141n"
   },
   "outputs": [],
   "source": [
    "#Graph Dataset Class\n",
    "#TODO: adapt, so it can stand alone\n",
    "#      link labels to files!!!!\n",
    "\n",
    "import os\n",
    "\n",
    "from dgl.data import DGLDataset\n",
    "class CGDataset(DGLDataset):\n",
    "    def __init__(self, directory):\n",
    "        self.file_path = directory\n",
    "        super(CGDataset, self).__init__(name=\"cgRNA\")#, raw_dir=directory)\n",
    "        \n",
    "        \n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        self.labels = [12.722, 4.891, 22.918, 12.147] #get this right and link to files\n",
    "        \n",
    "        files = []\n",
    "        filenames = next(os.walk(self.file_path), (None, None, []))[2]\n",
    "\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".cg\"):\n",
    "                files.append(file)\n",
    "\n",
    "        for struc in files:\n",
    "            coord_dict, twist_dict, connections = load_cg_file(os.path.join(training_dir, struc))\n",
    "            graph = build_dgl_graph(coord_dict, twist_dict, connections)\n",
    "            self.graphs.append(build_dgl_graph(coord_dict, twist_dict, connections))\n",
    "\n",
    "        self.labels = th.tensor(self.labels)\n",
    "  \n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "BWwHPYKZuq1b",
   "metadata": {
    "id": "BWwHPYKZuq1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph(num_nodes=14, num_edges=26,\n",
      "      ndata_schemes={'twist': Scheme(shape=(6,), dtype=torch.float32), 'coord': Scheme(shape=(6,), dtype=torch.float32), 'type': Scheme(shape=(6,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=15, num_edges=30,\n",
      "      ndata_schemes={'twist': Scheme(shape=(6,), dtype=torch.float32), 'coord': Scheme(shape=(6,), dtype=torch.float32), 'type': Scheme(shape=(6,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=4, num_edges=6,\n",
      "      ndata_schemes={'twist': Scheme(shape=(6,), dtype=torch.float32), 'coord': Scheme(shape=(6,), dtype=torch.float32), 'type': Scheme(shape=(6,), dtype=torch.float32)}\n",
      "      edata_schemes={})]\n",
      "{'rmsd': tensor([12.7220,  4.8910, 22.9180, 12.1470])}\n"
     ]
    }
   ],
   "source": [
    "#Save/Load Training Data\n",
    "#TODO: make a function to save the data\n",
    "#import os\n",
    "\n",
    "#training_dir = \"./training_set\"\n",
    "\n",
    "#g_list = []\n",
    "#glabels ={\"rmsd\": th.tensor([12.722, 4.891, 22.918, 12.147])} #done with: compare_RNA.py data/6CU1.pdb /home/mescalin/mgeyer/3d_classifier/6cu1.cg\n",
    "\n",
    "#files = []\n",
    "#filenames = next(os.walk(training_dir), (None, None, []))[2]\n",
    "\n",
    "#for file in filenames:\n",
    "#    if file.endswith(\".cg\"):\n",
    "#        files.append(file)\n",
    "\n",
    "#for struc in files:\n",
    "#    coord_dict, twist_dict, connections = load_cg_file(os.path.join(training_dir, struc))\n",
    "#    graph = build_dgl_graph(coord_dict, twist_dict, connections)\n",
    "#    g_list.append(graph)\n",
    "\n",
    "# save_graphs, label is rmsd\n",
    "dgl.save_graphs(training_dir + \"/training_cg_graphs.dgl\", g_list, labels=glabels)\n",
    "gs, ls = dgl.load_graphs(training_dir + \"/training_cg_graphs.dgl\")\n",
    "print(gs)\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "j4O333bvAQ1V",
   "metadata": {
    "id": "j4O333bvAQ1V"
   },
   "outputs": [],
   "source": [
    "#Dataloading\n",
    "import dgl.dataloading as dtl\n",
    "\n",
    "b_size = 2\n",
    "\n",
    "training_dir = \"./training_set\"\n",
    "\n",
    "training_dataset = CGDataset(training_dir)\n",
    "#dataset.process(training_dir)\n",
    "#graph, label = dataset[0]\n",
    "#print(graph, label)\n",
    "\n",
    "#add randomisation as in Defining Data Loader from https://docs.dgl.ai/tutorials/blitz/5_graph_classification.html\n",
    "train_dataloader = dtl.pytorch.GraphDataLoader(training_dataset, batch_size=b_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fec1a7b3-8adc-45a3-83ab-7cb02f31a4af",
   "metadata": {
    "id": "fec1a7b3-8adc-45a3-83ab-7cb02f31a4af"
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "from dgl.nn import GraphConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# feed the 3 different node attributes one after the other though the first layer? like in https://discuss.dgl.ai/t/getting-started-with-multiple-node-features-in-homogenous-graph/919/2\n",
    "# condense the 3 node attributes down to 1? see point above\n",
    "\n",
    "\n",
    "#Coarse Grain RNA Classifier Model\n",
    "class CG_Classifier(th.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_features):\n",
    "        super(CG_Classifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = GraphConv(in_dim, hidden_dim, activation=F.relu)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim, activation=F.relu)\n",
    "        \n",
    "        self.max_pool = dgl.nn.MaxPooling()\n",
    "        \n",
    "        self.dense1 = th.nn.Linear(hidden_dim*num_features, 256)\n",
    "        self.dense2 = th.nn.Linear(256, 256)\n",
    "        self.dense3 = th.nn.Linear(256, 256)\n",
    "        self.classify = th.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, g):#, n_types, n_coord, n_twist):\n",
    "        nt = g.ndata[\"type\"]\n",
    "        nc = g.ndata[\"coord\"]\n",
    "        nw = g.ndata[\"twist\"]\n",
    "        \n",
    "        nt = self.conv1(g, nt)\n",
    "        nt = self.max_pool(g, nt)\n",
    "        nt = self.conv2(g, nt)\n",
    "        nt = self.max_pool(g, nt)\n",
    "        \n",
    "        nc = self.conv1(g, nc)\n",
    "        nc = self.max_pool(g, nc)\n",
    "        nc = self.conv2(g, nc)\n",
    "        nc = self.max_pool(g, nc)\n",
    "        \n",
    "        nw = self.conv1(g, nw)\n",
    "        nw = self.max_pool(g, nw)\n",
    "        nw = self.conv2(g, nw)\n",
    "        nw = self.max_pool(g, nw)\n",
    "\n",
    "        #use pooling to have still a graph representation, after 2 layers of seperate conv\n",
    "        #--> let conv run over the pooled graph\n",
    "\n",
    "        tcw = th.cat((nt, nc, nw), 1)\n",
    "\n",
    "        #is the mean the right approach?\n",
    "        tcw_mean = tcw.mean(dim=0)\n",
    "        tcw_mean = self.dense1(tcw_mean)\n",
    "        tcw_mean = self.dense2(tcw_mean)\n",
    "        tcw_mean = self.dense3(tcw_mean)\n",
    "        \n",
    "        return self.classify(tcw_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2943be90-6647-4c26-b967-a2563a142877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "2943be90-6647-4c26-b967-a2563a142877",
    "outputId": "2ab8dac7-191d-4af1-86c7-9f0bc45aa800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28490/1663031686.py:32: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  batch_loss += F.smooth_l1_loss(prediction, batch_labels[i]) #F.cross_entropy(prediction, label) #th.abs((prediction - label))\n",
      "/tmp/ipykernel_28490/1663031686.py:47: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  val_loss = F.smooth_l1_loss(val_pred, val_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss 12.7493, Validation loss 3057.8567\n",
      "Epoch 5: Training loss 10522.7754, Validation loss 5095.5474\n",
      "Epoch 10: Training loss 31.3140, Validation loss 938.7620\n",
      "Epoch 15: Training loss 143.6006, Validation loss 19.8089\n",
      "Epoch 20: Training loss 41.9005, Validation loss 75.7576\n",
      "Epoch 25: Training loss 54.7204, Validation loss 70.3297\n",
      "Epoch 30: Training loss 40.8427, Validation loss 87.8752\n",
      "Epoch 35: Training loss 64.3743, Validation loss 27.8713\n",
      "Epoch 40: Training loss 5.1311, Validation loss 9.8563\n",
      "Epoch 45: Training loss 7.6676, Validation loss 9.4366\n",
      "Epoch 50: Training loss 5.0654, Validation loss 0.1854\n",
      "Epoch 55: Training loss 11.3703, Validation loss 7.5836\n",
      "Epoch 60: Training loss 31.7135, Validation loss 33.0669\n",
      "Epoch 65: Training loss 31.0185, Validation loss 8.0553\n",
      "Epoch 70: Training loss 22.3534, Validation loss 29.1071\n",
      "Epoch 75: Training loss 17.1818, Validation loss 2.0576\n",
      "Epoch 80: Training loss 9.3804, Validation loss 11.4534\n",
      "Epoch 85: Training loss 5.7738, Validation loss 0.3604\n",
      "Epoch 90: Training loss 5.4601, Validation loss 1.5716\n",
      "Epoch 95: Training loss 7.7270, Validation loss 3.6875\n",
      "Epoch 100: Training loss 4.3981, Validation loss 9.3750\n",
      "Epoch 105: Training loss 5.8251, Validation loss 14.5287\n",
      "Epoch 110: Training loss 5.3542, Validation loss 9.9509\n",
      "Epoch 115: Training loss 4.5956, Validation loss 11.1212\n",
      "Epoch 120: Training loss 5.1290, Validation loss 12.0081\n",
      "Epoch 125: Training loss 6.2871, Validation loss 12.2256\n",
      "Epoch 130: Training loss 5.3633, Validation loss 22.2410\n",
      "Epoch 135: Training loss 9.5550, Validation loss 11.1698\n",
      "Epoch 140: Training loss 6.3974, Validation loss 11.3543\n",
      "Epoch 145: Training loss 4.5582, Validation loss 9.8969\n",
      "Epoch 149: Training loss 5.4689, Validation loss 9.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.draw()>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training\n",
    "#TODO: figure out the loss function\n",
    "#       build a deeper neural network and how to pool\n",
    "#       tinker with hyperparameters\n",
    "\n",
    "model = CG_Classifier(\n",
    "    in_dim=6, #num of pos in type, twist, coord\n",
    "    hidden_dim=12,\n",
    "    num_features=3 #len(graph.ndata)\n",
    ")\n",
    "\n",
    "opt = th.optim.Adam(model.parameters(), lr=0.1)\n",
    "model.train()\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "#temp val setup --> use dataloader for larger set\n",
    "val_losses = []\n",
    "val_label = th.tensor(0.934)\n",
    "vcoord_dict, vtwist_dict, vconnections = load_cg_file(\"1ehz.cg\")\n",
    "val_graph = build_dgl_graph(vcoord_dict, vtwist_dict, vconnections)\n",
    "\n",
    "#training setup\n",
    "epoch_losses = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for iter, (batch, batch_labels) in enumerate(train_dataloader):\n",
    "        batch_loss = th.tensor(0.0, dtype=th.float32)\n",
    "        for i, batched_g in enumerate(dgl.unbatch(batch)): #use another method? see https://docs.dgl.ai/guide/training-graph.html#computation-on-a-batched-graph\n",
    "            prediction = model(batched_g)\n",
    "            batch_loss += F.smooth_l1_loss(prediction, batch_labels[i]) #F.cross_entropy(prediction, label) #th.abs((prediction - label))\n",
    "        \n",
    "        #using the mean of all losses of a single batch for backpropagation\n",
    "        loss = batch_loss/b_size\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "\n",
    "    epoch_loss /= (iter + 1)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "\n",
    "    #val setup\n",
    "    val_pred = model(val_graph)\n",
    "    val_loss = F.smooth_l1_loss(val_pred, val_label)\n",
    "    val_losses.append(val_loss.detach().item())\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == epochs-1:\n",
    "        print(\"Epoch {}: Training loss {:.4f}, Validation loss {:.4f}\".format(epoch, epoch_loss, val_loss))\n",
    "\n",
    "#plot the training run\n",
    "plt.plot(epoch_losses)\n",
    "plt.plot(val_losses, 'r')\n",
    "plt.ylim(ymax=5000, ymin=0)\n",
    "plt.draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eUo0_OJpxrV4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUo0_OJpxrV4",
    "outputId": "f8108cc1-47dc-4eb4-d405-3bdd8d05b45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted RMSD of 1EHZ (3rd best cg with ernwin): 11.8644; true RMSD: 0.9340; loss: 10.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28490/716465133.py:13: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.smooth_l1_loss(pred, test_label)\n"
     ]
    }
   ],
   "source": [
    "#Test with 1ehz.cg\n",
    "\n",
    "test_label = th.tensor(0.934)\n",
    "tcoord_dict, ttwist_dict, tconnections = load_cg_file(\"1ehz.cg\")\n",
    "test_graph = build_dgl_graph(tcoord_dict, ttwist_dict, tconnections)\n",
    "\n",
    "\n",
    "#tn_types = test_graph.ndata[\"type\"]\n",
    "#tn_coord = test_graph.ndata[\"coord\"]\n",
    "#tn_twist = test_graph.ndata[\"twist\"]\n",
    "\n",
    "pred = model(test_graph)#, tn_types, tn_coord, tn_twist)\n",
    "loss = F.smooth_l1_loss(pred, test_label)\n",
    "print(\"Predicted RMSD of 1EHZ (3rd best cg with ernwin): {:.4f}; true RMSD: {:.4f}; loss: {:.4f}\".format(float(pred), float(test_label), float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a1064-da56-4fab-9ce5-fc0aa0952ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3d_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

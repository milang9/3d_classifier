{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "3d_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
        "outputId": "1f82f46b-4bc1-4923-f4b0-e78024ee5894"
      },
      "source": [
        "!pip install dgl\n",
        "#!DGLBACKEND=pytorch\n",
        "#!export $DGLBACKEND\n",
        "#import os\n",
        "#os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "#print(os.environ[\"DGLBACKEND\"])\n",
        "import dgl\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import torch as th\n",
        "\n",
        "!pip install forgi\n",
        "import forgi\n",
        "import forgi.graph.bulge_graph as fgb\n",
        "import forgi.threedee as ft\n",
        "import forgi.threedee.model.coarse_grain as ftmc\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx"
      ],
      "id": "a683650d-9deb-45f7-8d82-17d0203ec8f9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.6.1\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting forgi\n",
            "  Downloading forgi-2.0.2.tar.gz (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 61 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from forgi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from forgi) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.7/dist-packages (from forgi) (1.1.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from forgi) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from forgi) (2.6.3)\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4 in /usr/local/lib/python3.7/dist-packages (from forgi) (1.4.4)\n",
            "Collecting logging_exceptions>=0.1.8\n",
            "  Downloading logging_exceptions-0.1.8-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20->forgi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20->forgi) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20->forgi) (1.15.0)\n",
            "Building wheels for collected packages: forgi\n",
            "  Building wheel for forgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for forgi: filename=forgi-2.0.2-cp37-cp37m-linux_x86_64.whl size=27429375 sha256=6e7b3c6224eefa296eded0bf7857bd6f374460bd47bf8f6c5073a0cce7f4e203\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/5d/b2/aa4d2d9454b124485448d838d5d02bce20f5546aa9b9d40b55\n",
            "Successfully built forgi\n",
            "Installing collected packages: logging-exceptions, biopython, forgi\n",
            "Successfully installed biopython-1.79 forgi-2.0.2 logging-exceptions-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_MuRd2MIU0bz",
        "outputId": "7c8d9f48-f053-4bbe-9939-1db458bbf3b3"
      },
      "source": [
        "th.__version__"
      ],
      "id": "_MuRd2MIU0bz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2IxR1AxZdYn"
      },
      "source": [
        "\n",
        "Ideas: \n",
        "*   load coarse grain representation with forgi,\n",
        "*   use forgi to form a graph with nodes labeled as s/i/o/.. and twist, length, angle,...\n",
        "*   use that graph to feed into model\n",
        "*   use dgl.save_graph() to store a graph, so the structure can be used for several steps?\n",
        "*   use forgi.threedee.model.coarse_grain.CoarseGrainRNA.rotate() to rotate cg RNAs and see if the classification changes\n",
        "\n",
        "TODO:\n",
        "*  build dataloader\n",
        "*      build model\n",
        "*      simulate batches to train (while testing)\n",
        "*    future --> find where ernwin writes/stores output of structure for each n steps\n",
        "\n"
      ],
      "id": "n2IxR1AxZdYn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81afa4b6-ee92-4662-826b-de338ca595cf",
        "tags": []
      },
      "source": [
        "#Graph Building\n",
        "\n",
        "#load coarse grain file\n",
        "def load_cg_file(file): \n",
        "    cg = ftmc.CoarseGrainRNA.from_bg_file(file) \n",
        "    c_dict = dict(cg.coords)\n",
        "    t_dict = dict(cg.twists)\n",
        "    coord_dict = {}\n",
        "    twist_dict = {}\n",
        "    for e in c_dict:\n",
        "        a = th.from_numpy(c_dict[e][0])\n",
        "        b = th.from_numpy(c_dict[e][1])\n",
        "        coord_dict[e] = a, b\n",
        "        if e in t_dict:\n",
        "            c = th.from_numpy(t_dict[e][0])\n",
        "            d = th.from_numpy(t_dict[e][1])\n",
        "            twist_dict[e] = c, d\n",
        "        \n",
        "    # Get elements and neighbours:\n",
        "    connections = {}\n",
        "    for elem in cg.sorted_element_iterator():\n",
        "        neighbours = cg.connections(elem)\n",
        "        if elem not in connections:\n",
        "            connections[elem] = cg.connections(elem)\n",
        "    return coord_dict, twist_dict, connections\n",
        "\n",
        "def build_dgl_graph(coord_dict, twist_dict, connections):\n",
        "    #dictionary to convert type\n",
        "    type_transl = {\n",
        "        \"h\": [1, 0, 0, 0, 0, 0],\n",
        "        \"i\": [0, 1, 0, 0, 0, 0],\n",
        "        \"m\": [0, 0, 1, 0, 0, 0],\n",
        "        \"s\": [0, 0, 0, 1, 0, 0],\n",
        "        \"f\": [0, 0, 0, 0, 1, 0],\n",
        "        \"t\": [0, 0, 0, 0, 0, 1]\n",
        "    } \n",
        "\n",
        "    #encode nodes numerically for dgl graph\n",
        "    num_graph = {}\n",
        "    elem_count = {}\n",
        "    for num, n in enumerate(sorted(connections)):\n",
        "        num_graph[n] = num\n",
        "        if n[0] not in elem_count:\n",
        "            elem_count[n[0]] = 1\n",
        "        else:\n",
        "            elem_count[n[0]] += 1\n",
        "\n",
        "    #build graph and edges\n",
        "    u = []\n",
        "    v = []\n",
        "    for node in connections:\n",
        "        for c in connections[node]:\n",
        "            u.append(num_graph[node])\n",
        "            v.append(num_graph[c])\n",
        "\n",
        "    graph = dgl.graph((th.tensor(u), th.tensor(v)))\n",
        "\n",
        "    #initialise node attributes\n",
        "    graph.ndata[\"type\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32)\n",
        "    graph.ndata[\"coord\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32) #seperate coords into 2 sets of 3, so that the information of start and end is added?\n",
        "    graph.ndata[\"twist\"] = th.zeros(graph.num_nodes(), 6, dtype=th.float32)\n",
        "\n",
        "    for elem in connections:\n",
        "        graph.ndata[\"type\"][num_graph[elem]] = th.tensor(type_transl[elem[0]], dtype=th.float32) \n",
        "        graph.ndata[\"coord\"][num_graph[elem]] = th.tensor(np.concatenate(coord_dict[elem]), dtype=th.float32)\n",
        "        if elem in twist_dict:\n",
        "            graph.ndata[\"twist\"][num_graph[elem]] = th.tensor(np.concatenate(twist_dict[elem]), dtype=th.float32)\n",
        "  \n",
        "    return graph\n",
        "\n"
      ],
      "id": "81afa4b6-ee92-4662-826b-de338ca595cf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU_znRFH141n"
      },
      "source": [
        "#Graph Dataset Class\n",
        "#TODO: adapt, so it can stand alone\n",
        "\n",
        "from dgl.data import DGLDataset\n",
        "class CGDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=\"cgRNA\")\n",
        "  \n",
        "    def process(self):\n",
        "        self.graphs = []\n",
        "        self.labels = [12.722, 4.891, 22.918]\n",
        "\n",
        "        for struc in [\"6cu1.cg\", \"2mis.cg\", \"1p5p.cg\"]:\n",
        "            coord_dict, twist_dict, connections = load_cg_file(struc)\n",
        "            self.graphs.append(build_dgl_graph(coord_dict, twist_dict, connections))\n",
        "\n",
        "        self.labels = th.tensor(self.labels)\n",
        "  \n",
        "    def __getitem__(self, i):\n",
        "        return self.graphs[i], self.labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n"
      ],
      "id": "ZU_znRFH141n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWwHPYKZuq1b"
      },
      "source": [
        "g_list = []\n",
        "glabels ={\"rmsd\": th.tensor([12.722, 4.891, 22.918])} #done with: compare_RNA.py data/6CU1.pdb /home/mescalin/mgeyer/3d_classifier/6cu1.cg\n",
        "\n",
        "for struc in [\"6cu1.cg\", \"2mis.cg\", \"1p5p.cg\"]:\n",
        "    coord_dict, twist_dict, connections = load_cg_file(struc)\n",
        "    graph = build_dgl_graph(coord_dict, twist_dict, connections)\n",
        "    g_list.append(graph)\n",
        "    #print(\"type\")\n",
        "    #print(graph.ndata[\"type\"])\n",
        "    #print(\"coord\")\n",
        "    #print(graph.ndata[\"coord\"])\n",
        "    #print(\"twist\")\n",
        "    #print(graph.ndata[\"twist\"])\n",
        "    \n",
        "#print(\"graphs\")\n",
        "#print(g_list)\n",
        "\n",
        "# save_graphs, label is rmsd\n",
        "dgl.save_graphs(\"cg_graphs.dgl\", g_list, labels=glabels)\n",
        "gs, ls = dgl.load_graphs(\"cg_graphs.dgl\")\n",
        "#print(gs)\n",
        "#print(ls)"
      ],
      "id": "BWwHPYKZuq1b",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4O333bvAQ1V"
      },
      "source": [
        "#Dataloading\n",
        "import dgl.dataloading as dtl\n",
        "\n",
        "dataset = CGDataset()\n",
        "#graph, label = dataset[0]\n",
        "#print(graph, label)\n",
        "\n",
        "\n",
        "dataloader = dtl.pytorch.GraphDataLoader(dataset, batch_size=1, shuffle=True) #add randomisation as in Defining Data Loader from https://docs.dgl.ai/tutorials/blitz/5_graph_classification.html\n",
        "\n"
      ],
      "id": "j4O333bvAQ1V",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fec1a7b3-8adc-45a3-83ab-7cb02f31a4af"
      },
      "source": [
        "#Model\n",
        "from dgl.nn import GraphConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# feed the 3 different node attributes one after the other though the first layer? like in https://discuss.dgl.ai/t/getting-started-with-multiple-node-features-in-homogenous-graph/919/2\n",
        "# condense the 3 node attributes down to 1? see point above\n",
        "\n",
        "\n",
        "#Coarse Grain RNA Classifier Model\n",
        "class CG_Classifier(th.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_features):\n",
        "        super(CG_Classifier, self).__init__()\n",
        "        \n",
        "        #self._in_src_feats, self._in_dst_feats = expand_as_pair(in_dim)\n",
        "        \n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim, activation=F.relu)\n",
        "        self.conv2 = GraphConv(hidden_dim, hidden_dim, activation=F.relu)\n",
        "        \n",
        "        #add pooling layer\n",
        "        \n",
        "        self.classify = th.nn.Linear(hidden_dim*num_features, 1)\n",
        "\n",
        "    def forward(self, g, n_types, n_coord, n_twist):\n",
        "        \n",
        "        nt = n_types\n",
        "        nt = self.conv1(g, nt)\n",
        "        nt = self.conv2(g, nt)\n",
        "        g.ndata['nt'] = nt\n",
        "        nt = dgl.mean_nodes(g, 'nt')\n",
        "\n",
        "        nc = n_coord\n",
        "        nc = self.conv1(g, nc)\n",
        "        nc = self.conv2(g, nc)\n",
        "        g.ndata['nc'] = nc\n",
        "        nc = dgl.mean_nodes(g, 'nc')\n",
        "        \n",
        "        nw = n_twist\n",
        "        nw = self.conv1(g, nw)\n",
        "        nw = self.conv2(g, nw)\n",
        "        g.ndata['nw'] = nw\n",
        "        nw = dgl.mean_nodes(g, 'nw')\n",
        "\n",
        "        tcw = th.cat((nt, nc, nw), 1)\n",
        "        tcw_mean = tcw.mean(dim=0)\n",
        "        return self.classify(tcw_mean)\n",
        "    "
      ],
      "id": "fec1a7b3-8adc-45a3-83ab-7cb02f31a4af",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2943be90-6647-4c26-b967-a2563a142877",
        "outputId": "847b75a2-94b1-4df1-ce0f-3a59c6ee1d2a"
      },
      "source": [
        "#Training\n",
        "#TODO: figure out the loss function\n",
        "#       build a deeper neural network and how to pool\n",
        "#       tinker with hyperparameters\n",
        "\n",
        "model = CG_Classifier(\n",
        "    in_dim=6, #num of pos in type, twist, coord\n",
        "    hidden_dim=10,\n",
        "    num_features=3 #len(graph.ndata)\n",
        ")\n",
        "\n",
        "opt = th.optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss =0\n",
        "    for iter, (batched_g, label) in enumerate(dataloader): #dataloader:#\n",
        "        n_types = batched_g.ndata[\"type\"]\n",
        "        n_coord = batched_g.ndata[\"coord\"]\n",
        "        n_twist = batched_g.ndata[\"twist\"]\n",
        "\n",
        "        prediction = model(batched_g, n_types, n_coord, n_twist)\n",
        "        loss = F.smooth_l1_loss(prediction, label) #F.cross_entropy(prediction, label) #th.abs((prediction - label))\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        epoch_loss += loss.detach().item()\n",
        "    epoch_loss /= (iter + 1)\n",
        "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "    epoch_losses.append(epoch_loss)"
      ],
      "id": "2943be90-6647-4c26-b967-a2563a142877",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss 11.7034\n",
            "Epoch 1, loss 9.8520\n",
            "Epoch 2, loss 7.8677\n",
            "Epoch 3, loss 6.4726\n",
            "Epoch 4, loss 5.3082\n",
            "Epoch 5, loss 5.1310\n",
            "Epoch 6, loss 4.8233\n",
            "Epoch 7, loss 3.9776\n",
            "Epoch 8, loss 3.7649\n",
            "Epoch 9, loss 3.0484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUo0_OJpxrV4",
        "outputId": "9619be92-0d36-4442-cf36-47d51d4f29f3"
      },
      "source": [
        "#Test with 1ehz.cg\n",
        "test_label = th.tensor(0.934)\n",
        "tcoord_dict, ttwist_dict, tconnections = load_cg_file(\"1ehz.cg\")\n",
        "test_graph = build_dgl_graph(tcoord_dict, ttwist_dict, tconnections)\n",
        "\n",
        "\n",
        "tn_types = test_graph.ndata[\"type\"]\n",
        "tn_coord = test_graph.ndata[\"coord\"]\n",
        "tn_twist = test_graph.ndata[\"twist\"]\n",
        "\n",
        "pred = model(test_graph, tn_types, tn_coord, tn_twist)\n",
        "loss = F.smooth_l1_loss(pred, test_label)\n",
        "print(\"Predicted RMSD of 1EHZ (3rd best cg with ernwin): {:.4f}; true RMSD: {:.4f}; loss: {:.4f}\".format(float(pred), float(test_label), float(loss)))"
      ],
      "id": "eUo0_OJpxrV4",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted RMSD of 1EHZ (3rd best cg with ernwin): 6.7715; true RMSD: 0.9340; loss: 5.3375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    }
  ]
}